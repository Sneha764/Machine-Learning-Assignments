{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1bf461f",
   "metadata": {},
   "source": [
    "## GPT2 training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d347cb41-62b9-4e4e-a63e-bcb4ac8417f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for Linear Regression...\n",
      "Running GridSearchCV for Polynomial Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "20 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1101, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "         ^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 163. GiB for an array with shape (288, 76088705) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1101, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "         ^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 164. GiB for an array with shape (289, 76088705) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1101, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "         ^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 30.8 TiB for an array with shape (288, 14685120065) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1101, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "         ^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 30.9 TiB for an array with shape (289, 14685120065) and data type float64\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [-1.93581466e+23             nan             nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for Lasso Regression...\n",
      "Running GridSearchCV for Logistic Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for Bayesian Linear Regression...\n",
      "Running GridSearchCV for Support Vector Regression...\n",
      "Running GridSearchCV for Decision Tree Regression...\n",
      "Running GridSearchCV for Gaussian Process Regression...\n",
      "Running GridSearchCV for Random Forest Regression...\n",
      "Running GridSearchCV for KNN Regression...\n",
      "                         Model  \\\n",
      "3          Logistic Regression   \n",
      "6     Decision Tree Regression   \n",
      "9               KNN Regression   \n",
      "7  Gaussian Process Regression   \n",
      "0            Linear Regression   \n",
      "1        Polynomial Regression   \n",
      "8     Random Forest Regression   \n",
      "4   Bayesian Linear Regression   \n",
      "2             Lasso Regression   \n",
      "5    Support Vector Regression   \n",
      "\n",
      "                                         Best Params   Accuracy  \n",
      "3                       {'C': 10, 'solver': 'lbfgs'}  98.753894  \n",
      "6          {'max_depth': 20, 'min_samples_split': 5}  90.342679  \n",
      "9          {'n_neighbors': 7, 'weights': 'distance'}  86.292835  \n",
      "7                                    {'alpha': 0.01}  65.109034  \n",
      "0                                                 {}  64.174455  \n",
      "1                                {'poly__degree': 2}  57.943925  \n",
      "8  {'max_depth': 10, 'min_samples_split': 5, 'n_e...  27.102804  \n",
      "4              {'alpha_1': 1e-06, 'alpha_2': 0.0001}  17.133956  \n",
      "2                                    {'alpha': 0.01}  15.887850  \n",
      "5                          {'C': 10, 'epsilon': 0.5}   4.049844  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Lasso, BayesianRidge, LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "def load_data(url):\n",
    "    \"\"\"\n",
    "    Load dataset from the given URL.\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(url)\n",
    "    X = data.drop(columns=['output']).values\n",
    "    y = data['output'].values\n",
    "    return X, y\n",
    "\n",
    "def initialize_models():\n",
    "    \"\"\"\n",
    "    Initialize regression models.\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    models = {\n",
    "        \"Linear Regression\": LinearRegression(),\n",
    "        \"Polynomial Regression\": Pipeline([('scaler', StandardScaler()), \n",
    "                                          ('poly', PolynomialFeatures(degree=2)), \n",
    "                                          ('linear', LinearRegression())]),\n",
    "        \"Lasso Regression\": Lasso(),\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "        \"Bayesian Linear Regression\": BayesianRidge(),\n",
    "        \"Support Vector Regression\": SVR(),\n",
    "        \"Decision Tree Regression\": DecisionTreeRegressor(),\n",
    "        \"Gaussian Process Regression\": GaussianProcessRegressor(),\n",
    "        \"Random Forest Regression\": RandomForestRegressor(),\n",
    "        \"KNN Regression\": KNeighborsRegressor()\n",
    "    }\n",
    "    return models\n",
    "\n",
    "def initialize_param_grids():\n",
    "    \"\"\"\n",
    "    Initialize hyperparameter grids for GridSearchCV.\n",
    "    \"\"\"\n",
    "    param_grids = {\n",
    "        \"Linear Regression\": {},\n",
    "        \"Polynomial Regression\": {'poly__degree': [2, 3, 4]},\n",
    "        \"Lasso Regression\": {'alpha': [0.01, 0.1, 1, 10]},\n",
    "        \"Logistic Regression\": {'C': [0.1, 1, 10], 'solver': ['lbfgs', 'liblinear']},\n",
    "        \"Bayesian Linear Regression\": {'alpha_1': [1e-6, 1e-5, 1e-4], 'alpha_2': [1e-6, 1e-5, 1e-4]},\n",
    "        \"Support Vector Regression\": {'C': [0.1, 1, 10], 'epsilon': [0.01, 0.1, 0.5]},\n",
    "        \"Decision Tree Regression\": {'max_depth': [None, 10, 20, 30], 'min_samples_split': [2, 5, 10]},\n",
    "        \"Gaussian Process Regression\": {'alpha': [1e-2, 1e-3, 1e-4]},\n",
    "        \"Random Forest Regression\": {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20], 'min_samples_split': [2, 5, 10]},\n",
    "        \"KNN Regression\": {'n_neighbors': [3, 5, 7], 'weights': ['uniform', 'distance']}\n",
    "    }\n",
    "    return param_grids\n",
    "\n",
    "def run_grid_search(models, param_grids, X, y, threshold=0.1):\n",
    "    \"\"\"\n",
    "    Run GridSearchCV for each model and return the results.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"Running GridSearchCV for {model_name}...\")\n",
    "\n",
    "        grid_search = GridSearchCV(model, param_grids.get(model_name, {}), cv=10, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "        grid_search.fit(X, y)\n",
    "\n",
    "        best_model = grid_search.best_estimator_\n",
    "        y_pred = best_model.predict(X)\n",
    "\n",
    "        # Calculate accuracy based on threshold\n",
    "        correct_predictions = np.abs(y_pred - y) <= threshold * np.abs(y)\n",
    "        accuracy = np.mean(correct_predictions) * 100  # Percentage of correct predictions\n",
    "\n",
    "        # Append results\n",
    "        results.append({\n",
    "            'Model': model_name,\n",
    "            'Best Params': grid_search.best_params_,\n",
    "            'Accuracy': accuracy\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to load data, initialize models, run GridSearchCV, and display results.\n",
    "    \"\"\"\n",
    "    # Load data\n",
    "    url = 'gpt2_embeddings_input_output_custom_columns'\n",
    "    X, y = load_data(url)\n",
    "\n",
    "    # Initialize models and parameter grids\n",
    "    models = initialize_models()\n",
    "    param_grids = initialize_param_grids()\n",
    "\n",
    "    # Run GridSearchCV and collect results\n",
    "    results = run_grid_search(models, param_grids, X, y)\n",
    "\n",
    "    # Convert results to a DataFrame and display sorted results\n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(results_df.sort_values(by=\"Accuracy\", ascending=False))\n",
    "\n",
    "# Call main to execute the workflow\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07386b97-00d3-47ec-b66b-66a116a7691c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Linear Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\AppData\\Local\\Temp\\ipykernel_12184\\1494525476.py:29: RuntimeWarning: divide by zero encountered in divide\n",
      "  mape = np.mean(np.abs((y - y_pred) / y)) * 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Polynomial Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "20 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1101, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "         ^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 163. GiB for an array with shape (288, 76088705) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1101, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "         ^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 164. GiB for an array with shape (289, 76088705) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1101, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "         ^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 30.8 TiB for an array with shape (288, 14685120065) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1101, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "         ^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 30.9 TiB for an array with shape (289, 14685120065) and data type float64\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [-1.93581466e+23             nan             nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jyoshitha\\AppData\\Local\\Temp\\ipykernel_12184\\1494525476.py:29: RuntimeWarning: divide by zero encountered in divide\n",
      "  mape = np.mean(np.abs((y - y_pred) / y)) * 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Lasso Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\AppData\\Local\\Temp\\ipykernel_12184\\1494525476.py:29: RuntimeWarning: divide by zero encountered in divide\n",
      "  mape = np.mean(np.abs((y - y_pred) / y)) * 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Logistic Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Jyoshitha\\AppData\\Local\\Temp\\ipykernel_12184\\1494525476.py:29: RuntimeWarning: invalid value encountered in divide\n",
      "  mape = np.mean(np.abs((y - y_pred) / y)) * 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Bayesian Linear Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\AppData\\Local\\Temp\\ipykernel_12184\\1494525476.py:29: RuntimeWarning: divide by zero encountered in divide\n",
      "  mape = np.mean(np.abs((y - y_pred) / y)) * 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Support Vector Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\AppData\\Local\\Temp\\ipykernel_12184\\1494525476.py:29: RuntimeWarning: divide by zero encountered in divide\n",
      "  mape = np.mean(np.abs((y - y_pred) / y)) * 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Decision Tree Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\AppData\\Local\\Temp\\ipykernel_12184\\1494525476.py:29: RuntimeWarning: divide by zero encountered in divide\n",
      "  mape = np.mean(np.abs((y - y_pred) / y)) * 100\n",
      "C:\\Users\\Jyoshitha\\AppData\\Local\\Temp\\ipykernel_12184\\1494525476.py:29: RuntimeWarning: invalid value encountered in divide\n",
      "  mape = np.mean(np.abs((y - y_pred) / y)) * 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Gaussian Process Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\AppData\\Local\\Temp\\ipykernel_12184\\1494525476.py:29: RuntimeWarning: divide by zero encountered in divide\n",
      "  mape = np.mean(np.abs((y - y_pred) / y)) * 100\n",
      "C:\\Users\\Jyoshitha\\AppData\\Local\\Temp\\ipykernel_12184\\1494525476.py:29: RuntimeWarning: invalid value encountered in divide\n",
      "  mape = np.mean(np.abs((y - y_pred) / y)) * 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Random Forest Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\AppData\\Local\\Temp\\ipykernel_12184\\1494525476.py:29: RuntimeWarning: divide by zero encountered in divide\n",
      "  mape = np.mean(np.abs((y - y_pred) / y)) * 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating KNN Regression...\n",
      "                         Model  \\\n",
      "3          Logistic Regression   \n",
      "9               KNN Regression   \n",
      "6     Decision Tree Regression   \n",
      "7  Gaussian Process Regression   \n",
      "0            Linear Regression   \n",
      "1        Polynomial Regression   \n",
      "8     Random Forest Regression   \n",
      "4   Bayesian Linear Regression   \n",
      "2             Lasso Regression   \n",
      "5    Support Vector Regression   \n",
      "\n",
      "                                         Best Params   Accuracy      RMSE  \\\n",
      "3                       {'C': 10, 'solver': 'lbfgs'}  98.753894  0.176501   \n",
      "9          {'n_neighbors': 7, 'weights': 'distance'}  86.292835  0.078934   \n",
      "6          {'max_depth': 10, 'min_samples_split': 5}  67.912773  0.241037   \n",
      "7                                    {'alpha': 0.01}  65.109034  0.083274   \n",
      "0                                                 {}  64.174455  0.078934   \n",
      "1                                {'poly__degree': 2}  57.943925  0.822433   \n",
      "8  {'max_depth': None, 'min_samples_split': 2, 'n...  25.856698  0.630346   \n",
      "4              {'alpha_1': 1e-06, 'alpha_2': 0.0001}  17.133956  0.949668   \n",
      "2                                    {'alpha': 0.01}  15.887850  0.962521   \n",
      "5                          {'C': 10, 'epsilon': 0.5}   4.049844  1.834722   \n",
      "\n",
      "        R^2       MAE  MAPE  \n",
      "3  0.992332  0.018692   NaN  \n",
      "9  0.998466  0.006232   NaN  \n",
      "6  0.985699  0.109968   NaN  \n",
      "7  0.998293  0.025025   NaN  \n",
      "0  0.998466  0.006259   inf  \n",
      "1  0.833510  0.175422   inf  \n",
      "8  0.902198  0.509989   inf  \n",
      "4  0.778011  0.750133   inf  \n",
      "2  0.771961  0.769212   inf  \n",
      "5  0.171432  1.545058   inf  \n",
      "\n",
      "Summary of Metrics:\n",
      "Mean RMSE: 0.585836902424554\n",
      "Std Dev RMSE: 0.5426646573914159\n",
      "Mean R^2: 0.8430369274324858\n",
      "Std Dev R^2: 0.2406215678638904\n",
      "Mean MAE: 0.39159906193332816\n",
      "Std Dev MAE: 0.4808432683659046\n",
      "Mean MAPE: nan\n",
      "Std Dev MAPE: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\AppData\\Local\\Temp\\ipykernel_12184\\1494525476.py:29: RuntimeWarning: divide by zero encountered in divide\n",
      "  mape = np.mean(np.abs((y - y_pred) / y)) * 100\n",
      "C:\\Users\\Jyoshitha\\AppData\\Local\\Temp\\ipykernel_12184\\1494525476.py:29: RuntimeWarning: invalid value encountered in divide\n",
      "  mape = np.mean(np.abs((y - y_pred) / y)) * 100\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_model_performance(models, param_grids, X, y, threshold=0.1):\n",
    "    \"\"\"\n",
    "    Evaluate models using GridSearchCV and calculate various metrics like RMSE, R^2, MAE, MAPE, and accuracy.\n",
    "    \"\"\"\n",
    "    additional_results = []\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"Evaluating {model_name}...\")\n",
    "\n",
    "        # Apply GridSearchCV with 10-fold cross-validation\n",
    "        grid_search = GridSearchCV(model, param_grids.get(model_name, {}), cv=10, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "        grid_search.fit(X, y)\n",
    "        \n",
    "        # Get the best model and make predictions\n",
    "        best_model = grid_search.best_estimator_\n",
    "        y_pred = best_model.predict(X)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "        r2 = r2_score(y, y_pred)\n",
    "        mae = mean_absolute_error(y, y_pred)\n",
    "        mape = np.mean(np.abs((y - y_pred) / y)) * 100\n",
    "        \n",
    "        # Calculate accuracy based on threshold (±10% of the actual value)\n",
    "        correct_predictions = np.abs(y_pred - y) <= threshold * np.abs(y)\n",
    "        accuracy = np.mean(correct_predictions) * 100  # Percentage of correct predictions\n",
    "\n",
    "        # Store the results\n",
    "        additional_results.append({\n",
    "            'Model': model_name,\n",
    "            'Best Params': grid_search.best_params_,\n",
    "            'Accuracy': accuracy,\n",
    "            'RMSE': rmse,\n",
    "            'R^2': r2,\n",
    "            'MAE': mae,\n",
    "            'MAPE': mape\n",
    "        })\n",
    "\n",
    "    return additional_results\n",
    "\n",
    "\n",
    "def summarize_metrics(additional_results):\n",
    "    \"\"\"\n",
    "    Calculate and print the summary of metrics like mean and standard deviation.\n",
    "    \"\"\"\n",
    "    metrics_summary = {\n",
    "        'Mean RMSE': np.mean([result['RMSE'] for result in additional_results]),\n",
    "        'Std Dev RMSE': np.std([result['RMSE'] for result in additional_results]),\n",
    "        'Mean R^2': np.mean([result['R^2'] for result in additional_results]),\n",
    "        'Std Dev R^2': np.std([result['R^2'] for result in additional_results]),\n",
    "        'Mean MAE': np.mean([result['MAE'] for result in additional_results]),\n",
    "        'Std Dev MAE': np.std([result['MAE'] for result in additional_results]),\n",
    "        'Mean MAPE': np.mean([result['MAPE'] for result in additional_results]),\n",
    "        'Std Dev MAPE': np.std([result['MAPE'] for result in additional_results]),\n",
    "    }\n",
    "\n",
    "    print(\"\\nSummary of Metrics:\")\n",
    "    for metric, value in metrics_summary.items():\n",
    "        print(f\"{metric}: {value}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to evaluate models, print results, and display the summary of metrics.\n",
    "    \"\"\"\n",
    "    # Assuming 'models', 'param_grids', 'X', 'y' are already defined\n",
    "    \n",
    "    # Evaluate models and get the results\n",
    "    additional_results = evaluate_model_performance(models, param_grids, X, y)\n",
    "\n",
    "    # Convert results to DataFrame for display\n",
    "    additional_results_df = pd.DataFrame(additional_results)\n",
    "\n",
    "    # Print individual model results sorted by accuracy\n",
    "    print(additional_results_df.sort_values(by=\"Accuracy\", ascending=False))\n",
    "\n",
    "    # Summarize and print the metrics\n",
    "    summarize_metrics(additional_results)\n",
    "\n",
    "\n",
    "# Call main function to run the code\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f0f13a",
   "metadata": {},
   "source": [
    "## GPT2 tetsing Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19da9285-8ca4-44fe-aa3b-5fb3d417c134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Linear Regression\n",
      "Predicted Marks: [-9.02109172  3.97427566  5.19716771  3.40920753  3.73993152]\n",
      "Actual Marks: [0 4 2 1 5]\n",
      "----------------------------------------\n",
      "Model: Polynomial Regression (Degree 2)\n",
      "Predicted Marks: [-4.40951141  3.50546143  5.25976675  3.98902191  2.72837765]\n",
      "Actual Marks: [0 4 2 1 5]\n",
      "----------------------------------------\n",
      "Model: Lasso Regression\n",
      "Predicted Marks: [2.69582647 2.87930595 2.68850737 1.49693401 3.74163735]\n",
      "Actual Marks: [0 4 2 1 5]\n",
      "----------------------------------------\n",
      "Model: Logistic Regression (used for binary targets)\n",
      "Predicted Marks: [1 5 1 0 5]\n",
      "Actual Marks: [0 4 2 1 5]\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Bayesian Linear Regression\n",
      "Predicted Marks: [2.31159477 3.48581566 2.23789143 1.12024983 4.12170988]\n",
      "Actual Marks: [0 4 2 1 5]\n",
      "----------------------------------------\n",
      "Model: Support Vector Regression\n",
      "Predicted Marks: [2.18245617 2.46824315 2.7105891  1.48971462 2.88688946]\n",
      "Actual Marks: [0 4 2 1 5]\n",
      "----------------------------------------\n",
      "Model: Decision Tree Regression\n",
      "Predicted Marks: [1. 5. 2. 2. 2.]\n",
      "Actual Marks: [0 4 2 1 5]\n",
      "----------------------------------------\n",
      "Model: Gaussian Process Regression\n",
      "Predicted Marks: [4.60639633e-105 1.29752176e-003 3.99446846e-015 0.00000000e+000\n",
      " 2.20763019e-042]\n",
      "Actual Marks: [0 4 2 1 5]\n",
      "----------------------------------------\n",
      "Model: Random Forest Regression\n",
      "Predicted Marks: [0.98 4.1  1.92 0.84 3.74]\n",
      "Actual Marks: [0 4 2 1 5]\n",
      "----------------------------------------\n",
      "Model: KNN Regression\n",
      "Predicted Marks: [2.4 3.4 2.8 0.4 2.8]\n",
      "Actual Marks: [0 4 2 1 5]\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso, LogisticRegression, BayesianRidge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load and preprocess data\n",
    "def load_and_preprocess_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    X = data.iloc[:, :-1]  # Features\n",
    "    y = data.iloc[:, -1]   # Target\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define models\n",
    "def define_models():\n",
    "    return {\n",
    "        \"Linear Regression\": LinearRegression(),\n",
    "        \"Polynomial Regression (Degree 2)\": make_pipeline(PolynomialFeatures(degree=2), LinearRegression()),\n",
    "        \"Lasso Regression\": Lasso(),\n",
    "        \"Logistic Regression (used for binary targets)\": LogisticRegression(),\n",
    "        \"Bayesian Linear Regression\": BayesianRidge(),\n",
    "        \"Support Vector Regression\": SVR(),\n",
    "        \"Decision Tree Regression\": DecisionTreeRegressor(),\n",
    "        \"Gaussian Process Regression\": GaussianProcessRegressor(),\n",
    "        \"Random Forest Regression\": RandomForestRegressor(),\n",
    "        \"KNN Regression\": KNeighborsRegressor()\n",
    "    }\n",
    "\n",
    "# Train and evaluate models\n",
    "def train_and_evaluate_models(models, X_train, X_test, y_train, y_test):\n",
    "    for model_name, model in models.items():\n",
    "        try:\n",
    "            # Fit the model\n",
    "            model.fit(X_train, y_train)\n",
    "            # Predict on the test set\n",
    "            y_pred = model.predict(X_test)\n",
    "            \n",
    "            # Calculate Mean Squared Error\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            \n",
    "            # Print results\n",
    "            print(f\"Model: {model_name}\")\n",
    "            print(f\"Predicted Marks: {y_pred[:5]}\")  # Print first 5 predictions\n",
    "            print(f\"Actual Marks: {y_test[:5].values}\")  # Print first 5 actual values\n",
    "            print(f\"Mean Squared Error: {mse}\")  # Print MSE for the model\n",
    "            print(\"-\" * 40)\n",
    "        except Exception as e:\n",
    "            print(f\"Model: {model_name} - Error: {str(e)}\")\n",
    "            print(\"-\" * 40)\n",
    "\n",
    "# Main function to execute the workflow\n",
    "def main():\n",
    "    file_path = \"Q1_gpt2.csv\"  # Specify your dataset path\n",
    "    X_train, X_test, y_train, y_test = load_and_preprocess_data(file_path)\n",
    "    models = define_models()\n",
    "    train_and_evaluate_models(models, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986bbc46",
   "metadata": {},
   "source": [
    "## GPT2 tetsing Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d9b846-8baf-4fee-aa56-422e18c54597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Linear Regression\n",
      "Predicted Marks: [2.11834685 0.42194213 2.11834685 0.39638417 5.        ]\n",
      "Actual Marks: [4. 0. 4. 0. 5.]\n",
      "----------------------------------------\n",
      "Model: Polynomial Regression (Degree 2)\n",
      "Predicted Marks: [2.40540706 0.20690958 2.40540706 0.39260843 5.        ]\n",
      "Actual Marks: [4. 0. 4. 0. 5.]\n",
      "----------------------------------------\n",
      "Model: Lasso Regression\n",
      "Predicted Marks: [2.31823172 0.28457469 2.31823172 1.61368492 4.53090613]\n",
      "Actual Marks: [4. 0. 4. 0. 5.]\n",
      "----------------------------------------\n",
      "Model: Logistic Regression (used for binary targets)\n",
      "Predicted Marks: [0. 0. 0. 0. 5.]\n",
      "Actual Marks: [4. 0. 4. 0. 5.]\n",
      "----------------------------------------\n",
      "Model: Bayesian Linear Regression\n",
      "Predicted Marks: [2.11834682 0.42194212 2.11834682 0.39638423 4.99999992]\n",
      "Actual Marks: [4. 0. 4. 0. 5.]\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Support Vector Regression\n",
      "Predicted Marks: [1.85976259 1.79568274 1.85976259 1.89435007 1.98567768]\n",
      "Actual Marks: [4. 0. 4. 0. 5.]\n",
      "----------------------------------------\n",
      "Model: Decision Tree Regression\n",
      "Predicted Marks: [1. 2. 1. 5. 5.]\n",
      "Actual Marks: [4. 0. 4. 0. 5.]\n",
      "----------------------------------------\n",
      "Model: Gaussian Process Regression\n",
      "Predicted Marks: [1.00640397e-54 9.75237075e-94 1.00640397e-54 1.74700958e-54\n",
      " 5.00000000e+00]\n",
      "Actual Marks: [4. 0. 4. 0. 5.]\n",
      "----------------------------------------\n",
      "Model: Random Forest Regression\n",
      "Predicted Marks: [1.22 1.25 1.22 1.12 5.  ]\n",
      "Actual Marks: [4. 0. 4. 0. 5.]\n",
      "----------------------------------------\n",
      "Model: KNN Regression\n",
      "Predicted Marks: [3.4 1.4 3.4 0.4 5. ]\n",
      "Actual Marks: [4. 0. 4. 0. 5.]\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso, LogisticRegression, BayesianRidge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Function to load dataset\n",
    "def load_data(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "# Function to handle missing values\n",
    "def handle_missing_values(data):\n",
    "    data = data.dropna(subset=[data.columns[-1]])  # Drop rows where the target is NaN\n",
    "    return data\n",
    "\n",
    "# Function to split dataset into features and target\n",
    "def split_data(data):\n",
    "    X = data.iloc[:, :-1]  # Features\n",
    "    y = data.iloc[:, -1]   # Target\n",
    "    return X, y\n",
    "\n",
    "# Function to split the dataset into training and test sets\n",
    "def train_test_split_data(X, y, test_size=0.2, random_state=42):\n",
    "    return train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "# Function to define models\n",
    "def define_models():\n",
    "    models = {\n",
    "        \"Linear Regression\": LinearRegression(),\n",
    "        \"Polynomial Regression (Degree 2)\": make_pipeline(PolynomialFeatures(degree=2), LinearRegression()),\n",
    "        \"Lasso Regression\": Lasso(),\n",
    "        \"Logistic Regression (used for binary targets)\": LogisticRegression(),\n",
    "        \"Bayesian Linear Regression\": BayesianRidge(),\n",
    "        \"Support Vector Regression\": SVR(),\n",
    "        \"Decision Tree Regression\": DecisionTreeRegressor(),\n",
    "        \"Gaussian Process Regression\": GaussianProcessRegressor(),\n",
    "        \"Random Forest Regression\": RandomForestRegressor(),\n",
    "        \"KNN Regression\": KNeighborsRegressor()\n",
    "    }\n",
    "    return models\n",
    "\n",
    "# Function to train and evaluate models\n",
    "def train_and_evaluate_models(models, X_train, y_train, X_test, y_test):\n",
    "    for model_name, model in models.items():\n",
    "        try:\n",
    "            # Fit the model\n",
    "            model.fit(X_train, y_train)\n",
    "            # Predict on the test set\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            # Print results\n",
    "            print(f\"Model: {model_name}\")\n",
    "            print(f\"Predicted Marks: {y_pred[:5]}\")  # Print first 5 predictions\n",
    "            print(f\"Actual Marks: {y_test[:5].values}\")  # Print first 5 actual values\n",
    "            print(\"-\" * 40)\n",
    "        except Exception as e:\n",
    "            print(f\"Model: {model_name} - Error: {str(e)}\")\n",
    "            print(\"-\" * 40)\n",
    "\n",
    "# Main function to execute the workflow\n",
    "def main(file_path):\n",
    "    # Load dataset\n",
    "    data = load_data(file_path)\n",
    "    \n",
    "    # Handle missing values\n",
    "    data = handle_missing_values(data)\n",
    "    \n",
    "    # Split into features and target\n",
    "    X, y = split_data(data)\n",
    "    \n",
    "    # Split dataset into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split_data(X, y)\n",
    "    \n",
    "    # Define models\n",
    "    models = define_models()\n",
    "    \n",
    "    # Train and evaluate models\n",
    "    train_and_evaluate_models(models, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Run the workflow\n",
    "main(\"Q2_gpt2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d133869a",
   "metadata": {},
   "source": [
    "## GPT2 tetsing Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd781291-576c-4fe5-a841-a75be12b195d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Linear Regression\n",
      "Predicted Marks: [3, 2, 0, 2, 2]\n",
      "Actual Marks: [1, 1, 1, 5, 0]\n",
      "----------------------------------------\n",
      "Model: Polynomial Regression (Degree 2)\n",
      "Predicted Marks: [3, 2, 0, 2, 2]\n",
      "Actual Marks: [1, 1, 1, 5, 0]\n",
      "----------------------------------------\n",
      "Model: Lasso Regression\n",
      "Predicted Marks: [2, 2, 1, 2, 2]\n",
      "Actual Marks: [1, 1, 1, 5, 0]\n",
      "----------------------------------------\n",
      "Model: Logistic Regression (used for binary targets)\n",
      "Predicted Marks: [4, 1, 1, 1, 3]\n",
      "Actual Marks: [1, 1, 1, 5, 0]\n",
      "----------------------------------------\n",
      "Model: Bayesian Linear Regression\n",
      "Predicted Marks: [3, 2, 0, 2, 2]\n",
      "Actual Marks: [1, 1, 1, 5, 0]\n",
      "----------------------------------------\n",
      "Model: Support Vector Regression\n",
      "Predicted Marks: [2, 2, 1, 2, 2]\n",
      "Actual Marks: [1, 1, 1, 5, 0]\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Decision Tree Regression\n",
      "Predicted Marks: [0, 4, 1, 4, 3]\n",
      "Actual Marks: [1, 1, 1, 5, 0]\n",
      "----------------------------------------\n",
      "Model: Gaussian Process Regression\n",
      "Predicted Marks: [0, 0, 0, 0, 0]\n",
      "Actual Marks: [1, 1, 1, 5, 0]\n",
      "----------------------------------------\n",
      "Model: Random Forest Regression\n",
      "Predicted Marks: [2, 2, 1, 2, 2]\n",
      "Actual Marks: [1, 1, 1, 5, 0]\n",
      "----------------------------------------\n",
      "Model: KNN Regression\n",
      "Predicted Marks: [1, 1, 0, 1, 1]\n",
      "Actual Marks: [1, 1, 1, 5, 0]\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso, LogisticRegression, BayesianRidge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Function to load dataset\n",
    "def load_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    return data\n",
    "\n",
    "# Function to handle missing values\n",
    "def handle_missing_values(data):\n",
    "    # Drop rows with NaN in the target column or fill them with the mean value\n",
    "    data = data.dropna(subset=[data.columns[-1]])  # Drop rows where the target is NaN\n",
    "    # Alternatively: data[data.columns[-1]].fillna(data[data.columns[-1]].mean(), inplace=True)\n",
    "    return data\n",
    "\n",
    "# Function to split dataset into features and target\n",
    "def split_data(data):\n",
    "    X = data.iloc[:, :-1]  # Features\n",
    "    y = data.iloc[:, -1]   # Target\n",
    "    return X, y\n",
    "\n",
    "# Function to split data into training and test sets\n",
    "def train_test_split_data(X, y, test_size=0.2, random_state=42):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Function to define models\n",
    "def define_models():\n",
    "    models = {\n",
    "        \"Linear Regression\": LinearRegression(),\n",
    "        \"Polynomial Regression (Degree 2)\": make_pipeline(PolynomialFeatures(degree=2), LinearRegression()),\n",
    "        \"Lasso Regression\": Lasso(),\n",
    "        \"Logistic Regression (used for binary targets)\": LogisticRegression(),\n",
    "        \"Bayesian Linear Regression\": BayesianRidge(),\n",
    "        \"Support Vector Regression\": SVR(),\n",
    "        \"Decision Tree Regression\": DecisionTreeRegressor(),\n",
    "        \"Gaussian Process Regression\": GaussianProcessRegressor(),\n",
    "        \"Random Forest Regression\": RandomForestRegressor(),\n",
    "        \"KNN Regression\": KNeighborsRegressor()\n",
    "    }\n",
    "    return models\n",
    "\n",
    "# Function to train and evaluate models\n",
    "def train_and_evaluate_models(models, X_train, y_train, X_test, y_test):\n",
    "    for model_name, model in models.items():\n",
    "        try:\n",
    "            # Fit the model\n",
    "            model.fit(X_train, y_train)\n",
    "            # Predict on the test set\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            # Convert predictions and actual values to integers\n",
    "            y_pred_int = y_pred.astype(int)\n",
    "            y_test_int = y_test.astype(int)\n",
    "\n",
    "            # Print results\n",
    "            print(f\"Model: {model_name}\")\n",
    "            print(f\"Predicted Marks: {list(y_pred_int[:5])}\")  # Print first 5 predictions as integers\n",
    "            print(f\"Actual Marks: {list(y_test_int[:5].values)}\")  # Print first 5 actual values as integers\n",
    "            print(\"-\" * 40)\n",
    "        except Exception as e:\n",
    "            print(f\"Model: {model_name} - Error: {str(e)}\")\n",
    "            print(\"-\" * 40)\n",
    "\n",
    "# Main function to execute the workflow\n",
    "def main(file_path):\n",
    "    # Load dataset\n",
    "    data = load_data(file_path)\n",
    "    \n",
    "    # Handle missing values\n",
    "    data = handle_missing_values(data)\n",
    "    \n",
    "    # Split into features and target\n",
    "    X, y = split_data(data)\n",
    "    \n",
    "    # Split dataset into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split_data(X, y)\n",
    "    \n",
    "    # Define models\n",
    "    models = define_models()\n",
    "    \n",
    "    # Train and evaluate models\n",
    "    train_and_evaluate_models(models, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Run the workflow\n",
    "main(\"Q3_roberta.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
