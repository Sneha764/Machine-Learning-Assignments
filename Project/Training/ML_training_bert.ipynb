{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eff1d62e",
   "metadata": {},
   "source": [
    "## Bert Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e072b45-8735-41ac-9322-5ee1e34f7e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for Linear Regression...\n",
      "Running GridSearchCV for Polynomial Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "20 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1101, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "         ^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 163. GiB for an array with shape (288, 76088705) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1101, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "         ^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 164. GiB for an array with shape (289, 76088705) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1101, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "         ^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 30.8 TiB for an array with shape (288, 14685120065) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1101, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "         ^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 30.9 TiB for an array with shape (289, 14685120065) and data type float64\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [-1.80412682e+23             nan             nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for Lasso Regression...\n",
      "Running GridSearchCV for Logistic Regression...\n",
      "Running GridSearchCV for Bayesian Linear Regression...\n",
      "Running GridSearchCV for Support Vector Regression...\n",
      "Running GridSearchCV for Decision Tree Regression...\n",
      "Running GridSearchCV for Gaussian Process Regression...\n",
      "Running GridSearchCV for Random Forest Regression...\n",
      "Running GridSearchCV for KNN Regression...\n",
      "                         Model  \\\n",
      "3          Logistic Regression   \n",
      "9               KNN Regression   \n",
      "6     Decision Tree Regression   \n",
      "0            Linear Regression   \n",
      "7  Gaussian Process Regression   \n",
      "1        Polynomial Regression   \n",
      "8     Random Forest Regression   \n",
      "4   Bayesian Linear Regression   \n",
      "5    Support Vector Regression   \n",
      "2             Lasso Regression   \n",
      "\n",
      "                                         Best Params   Accuracy  \n",
      "3                    {'C': 1, 'solver': 'liblinear'}  97.819315  \n",
      "9          {'n_neighbors': 7, 'weights': 'distance'}  84.112150  \n",
      "6       {'max_depth': None, 'min_samples_split': 10}  73.520249  \n",
      "0                                                 {}  63.239875  \n",
      "7                                  {'alpha': 0.0001}  62.928349  \n",
      "1                                {'poly__degree': 2}  53.271028  \n",
      "8  {'max_depth': None, 'min_samples_split': 2, 'n...  29.283489  \n",
      "4              {'alpha_1': 1e-06, 'alpha_2': 0.0001}  17.133956  \n",
      "5                          {'C': 10, 'epsilon': 0.5}  15.887850  \n",
      "2                                     {'alpha': 0.1}   4.984424  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Lasso, BayesianRidge, LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Function to load data\n",
    "def load_data(url):\n",
    "    data = pd.read_csv(url)\n",
    "    X = data.drop(columns=['output']).values\n",
    "    y = data['output'].values\n",
    "    return X, y\n",
    "\n",
    "# Function to define models and hyperparameter grids\n",
    "def define_models():\n",
    "    models = {\n",
    "        \"Linear Regression\": LinearRegression(),\n",
    "        \"Polynomial Regression\": Pipeline([('scaler', StandardScaler()), \n",
    "                                          ('poly', PolynomialFeatures(degree=2)), \n",
    "                                          ('linear', LinearRegression())]),\n",
    "        \"Lasso Regression\": Lasso(),\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "        \"Bayesian Linear Regression\": BayesianRidge(),\n",
    "        \"Support Vector Regression\": SVR(),\n",
    "        \"Decision Tree Regression\": DecisionTreeRegressor(),\n",
    "        \"Gaussian Process Regression\": GaussianProcessRegressor(),\n",
    "        \"Random Forest Regression\": RandomForestRegressor(),\n",
    "        \"KNN Regression\": KNeighborsRegressor()\n",
    "    }\n",
    "\n",
    "    param_grids = {\n",
    "        \"Linear Regression\": {},\n",
    "        \"Polynomial Regression\": {'poly__degree': [2, 3, 4]},\n",
    "        \"Lasso Regression\": {'alpha': [0.01, 0.1, 1, 10]},\n",
    "        \"Logistic Regression\": {'C': [0.1, 1, 10], 'solver': ['lbfgs', 'liblinear']},\n",
    "        \"Bayesian Linear Regression\": {'alpha_1': [1e-6, 1e-5, 1e-4], 'alpha_2': [1e-6, 1e-5, 1e-4]},\n",
    "        \"Support Vector Regression\": {'C': [0.1, 1, 10], 'epsilon': [0.01, 0.1, 0.5]},\n",
    "        \"Decision Tree Regression\": {'max_depth': [None, 10, 20, 30], 'min_samples_split': [2, 5, 10]},\n",
    "        \"Gaussian Process Regression\": {'alpha': [1e-2, 1e-3, 1e-4]},\n",
    "        \"Random Forest Regression\": {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20], 'min_samples_split': [2, 5, 10]},\n",
    "        \"KNN Regression\": {'n_neighbors': [3, 5, 7], 'weights': ['uniform', 'distance']}\n",
    "    }\n",
    "\n",
    "    return models, param_grids\n",
    "\n",
    "# Function to perform GridSearchCV and return best model\n",
    "def perform_grid_search(models, param_grids, X, y):\n",
    "    results = []\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"Running GridSearchCV for {model_name}...\")\n",
    "        grid_search = GridSearchCV(model, param_grids.get(model_name, {}), cv=10, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "        grid_search.fit(X, y)\n",
    "        \n",
    "        best_model = grid_search.best_estimator_\n",
    "        y_pred = best_model.predict(X)\n",
    "        \n",
    "        # Calculate accuracy based on threshold (±10%)\n",
    "        threshold = 0.1\n",
    "        correct_predictions = np.abs(y_pred - y) <= threshold * np.abs(y)\n",
    "        accuracy = np.mean(correct_predictions) * 100  # Percentage of correct predictions\n",
    "        \n",
    "        results.append({\n",
    "            'Model': model_name,\n",
    "            'Best Params': grid_search.best_params_,\n",
    "            'Accuracy': accuracy\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# Function to display results\n",
    "def display_results(results):\n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(results_df.sort_values(by=\"Accuracy\", ascending=False))\n",
    "\n",
    "# Main function to run the entire process\n",
    "def main(url):\n",
    "    X, y = load_data(url)\n",
    "    models, param_grids = define_models()\n",
    "    results = perform_grid_search(models, param_grids, X, y)\n",
    "    display_results(results)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    url = 'bert_embeddings_input_output_custom_columns.csv'  # replace with your actual file URL\n",
    "    main(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58a74ff-2d48-4872-accc-384c76e4879e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Linear Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\AppData\\Local\\Temp\\ipykernel_11048\\1494525476.py:29: RuntimeWarning: divide by zero encountered in divide\n",
      "  mape = np.mean(np.abs((y - y_pred) / y)) * 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Polynomial Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "20 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1101, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "         ^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 163. GiB for an array with shape (288, 76088705) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1101, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "         ^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 164. GiB for an array with shape (289, 76088705) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1101, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "         ^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 30.8 TiB for an array with shape (288, 14685120065) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1101, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "         ^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 30.9 TiB for an array with shape (289, 14685120065) and data type float64\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [-1.80412682e+23             nan             nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jyoshitha\\AppData\\Local\\Temp\\ipykernel_11048\\1494525476.py:29: RuntimeWarning: divide by zero encountered in divide\n",
      "  mape = np.mean(np.abs((y - y_pred) / y)) * 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Lasso Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\AppData\\Local\\Temp\\ipykernel_11048\\1494525476.py:29: RuntimeWarning: divide by zero encountered in divide\n",
      "  mape = np.mean(np.abs((y - y_pred) / y)) * 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Logistic Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\AppData\\Local\\Temp\\ipykernel_11048\\1494525476.py:29: RuntimeWarning: divide by zero encountered in divide\n",
      "  mape = np.mean(np.abs((y - y_pred) / y)) * 100\n",
      "C:\\Users\\Jyoshitha\\AppData\\Local\\Temp\\ipykernel_11048\\1494525476.py:29: RuntimeWarning: invalid value encountered in divide\n",
      "  mape = np.mean(np.abs((y - y_pred) / y)) * 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Bayesian Linear Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\AppData\\Local\\Temp\\ipykernel_11048\\1494525476.py:29: RuntimeWarning: divide by zero encountered in divide\n",
      "  mape = np.mean(np.abs((y - y_pred) / y)) * 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Support Vector Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\AppData\\Local\\Temp\\ipykernel_11048\\1494525476.py:29: RuntimeWarning: divide by zero encountered in divide\n",
      "  mape = np.mean(np.abs((y - y_pred) / y)) * 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Decision Tree Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\AppData\\Local\\Temp\\ipykernel_11048\\1494525476.py:29: RuntimeWarning: divide by zero encountered in divide\n",
      "  mape = np.mean(np.abs((y - y_pred) / y)) * 100\n",
      "C:\\Users\\Jyoshitha\\AppData\\Local\\Temp\\ipykernel_11048\\1494525476.py:29: RuntimeWarning: invalid value encountered in divide\n",
      "  mape = np.mean(np.abs((y - y_pred) / y)) * 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Gaussian Process Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\AppData\\Local\\Temp\\ipykernel_11048\\1494525476.py:29: RuntimeWarning: divide by zero encountered in divide\n",
      "  mape = np.mean(np.abs((y - y_pred) / y)) * 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Random Forest Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\AppData\\Local\\Temp\\ipykernel_11048\\1494525476.py:29: RuntimeWarning: divide by zero encountered in divide\n",
      "  mape = np.mean(np.abs((y - y_pred) / y)) * 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating KNN Regression...\n",
      "                         Model  \\\n",
      "3          Logistic Regression   \n",
      "9               KNN Regression   \n",
      "0            Linear Regression   \n",
      "6     Decision Tree Regression   \n",
      "7  Gaussian Process Regression   \n",
      "1        Polynomial Regression   \n",
      "8     Random Forest Regression   \n",
      "4   Bayesian Linear Regression   \n",
      "5    Support Vector Regression   \n",
      "2             Lasso Regression   \n",
      "\n",
      "                                         Best Params   Accuracy      RMSE  \\\n",
      "3                    {'C': 1, 'solver': 'liblinear'}  97.819315  0.255774   \n",
      "9          {'n_neighbors': 7, 'weights': 'distance'}  84.112150  0.096674   \n",
      "0                                                 {}  63.239875  0.096674   \n",
      "6         {'max_depth': 10, 'min_samples_split': 10}  62.928349  0.473911   \n",
      "7                                  {'alpha': 0.0001}  62.928349  0.096674   \n",
      "1                                {'poly__degree': 2}  53.271028  0.456946   \n",
      "8  {'max_depth': 20, 'min_samples_split': 5, 'n_e...  28.660436  0.604564   \n",
      "4              {'alpha_1': 1e-06, 'alpha_2': 0.0001}  17.133956  0.844545   \n",
      "5                          {'C': 10, 'epsilon': 0.5}  15.887850  0.592932   \n",
      "2                                     {'alpha': 0.1}   4.984424  1.849400   \n",
      "\n",
      "        R^2       MAE  MAPE  \n",
      "3  0.983897  0.034268   NaN  \n",
      "9  0.997700  0.012461   NaN  \n",
      "0  0.997700  0.012693   inf  \n",
      "6  0.944718  0.241285   NaN  \n",
      "7  0.997700  0.012630   inf  \n",
      "1  0.948605  0.179806   inf  \n",
      "8  0.910035  0.492597   inf  \n",
      "4  0.824437  0.666949   inf  \n",
      "5  0.913464  0.505849   inf  \n",
      "2  0.158121  1.650523   inf  \n",
      "\n",
      "Summary of Metrics:\n",
      "Mean RMSE: 0.5368094059441109\n",
      "Std Dev RMSE: 0.49958058234756725\n",
      "Mean R^2: 0.8676376480558927\n",
      "Std Dev R^2: 0.24206185167330152\n",
      "Mean MAE: 0.3809059947827077\n",
      "Std Dev MAE: 0.4805087008989057\n",
      "Mean MAPE: nan\n",
      "Std Dev MAPE: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\AppData\\Local\\Temp\\ipykernel_11048\\1494525476.py:29: RuntimeWarning: divide by zero encountered in divide\n",
      "  mape = np.mean(np.abs((y - y_pred) / y)) * 100\n",
      "C:\\Users\\Jyoshitha\\AppData\\Local\\Temp\\ipykernel_11048\\1494525476.py:29: RuntimeWarning: invalid value encountered in divide\n",
      "  mape = np.mean(np.abs((y - y_pred) / y)) * 100\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Function to load data\n",
    "def load_data(url):\n",
    "    data = pd.read_csv(url)\n",
    "    X = data.drop(columns=['output']).values\n",
    "    y = data['output'].values\n",
    "    return X, y\n",
    "\n",
    "# Function to define models and hyperparameter grids\n",
    "def define_models():\n",
    "    models = {\n",
    "        \"Linear Regression\": LinearRegression(),\n",
    "        \"Polynomial Regression\": Pipeline([('scaler', StandardScaler()), \n",
    "                                          ('poly', PolynomialFeatures(degree=2)), \n",
    "                                          ('linear', LinearRegression())]),\n",
    "        \"Lasso Regression\": Lasso(),\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "        \"Bayesian Linear Regression\": BayesianRidge(),\n",
    "        \"Support Vector Regression\": SVR(),\n",
    "        \"Decision Tree Regression\": DecisionTreeRegressor(),\n",
    "        \"Gaussian Process Regression\": GaussianProcessRegressor(),\n",
    "        \"Random Forest Regression\": RandomForestRegressor(),\n",
    "        \"KNN Regression\": KNeighborsRegressor()\n",
    "    }\n",
    "\n",
    "    param_grids = {\n",
    "        \"Linear Regression\": {},\n",
    "        \"Polynomial Regression\": {'poly__degree': [2, 3, 4]},\n",
    "        \"Lasso Regression\": {'alpha': [0.01, 0.1, 1, 10]},\n",
    "        \"Logistic Regression\": {'C': [0.1, 1, 10], 'solver': ['lbfgs', 'liblinear']},\n",
    "        \"Bayesian Linear Regression\": {'alpha_1': [1e-6, 1e-5, 1e-4], 'alpha_2': [1e-6, 1e-5, 1e-4]},\n",
    "        \"Support Vector Regression\": {'C': [0.1, 1, 10], 'epsilon': [0.01, 0.1, 0.5]},\n",
    "        \"Decision Tree Regression\": {'max_depth': [None, 10, 20, 30], 'min_samples_split': [2, 5, 10]},\n",
    "        \"Gaussian Process Regression\": {'alpha': [1e-2, 1e-3, 1e-4]},\n",
    "        \"Random Forest Regression\": {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20], 'min_samples_split': [2, 5, 10]},\n",
    "        \"KNN Regression\": {'n_neighbors': [3, 5, 7], 'weights': ['uniform', 'distance']}\n",
    "    }\n",
    "\n",
    "    return models, param_grids\n",
    "\n",
    "# Function to evaluate models with additional metrics (RMSE, R^2, MAE, MAPE)\n",
    "def evaluate_models(models, param_grids, X, y, threshold=0.1):\n",
    "    additional_results = []\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"Evaluating {model_name}...\")\n",
    "\n",
    "        # Apply GridSearchCV with 10-fold cross-validation\n",
    "        grid_search = GridSearchCV(model, param_grids.get(model_name, {}), cv=10, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "        grid_search.fit(X, y)\n",
    "        \n",
    "        # Get the best model and make predictions\n",
    "        best_model = grid_search.best_estimator_\n",
    "        y_pred = best_model.predict(X)\n",
    "        \n",
    "        # Calculate RMSE\n",
    "        rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "        \n",
    "        # Calculate R^2\n",
    "        r2 = r2_score(y, y_pred)\n",
    "        \n",
    "        # Calculate MAE\n",
    "        mae = mean_absolute_error(y, y_pred)\n",
    "        \n",
    "        # Calculate MAPE (Mean Absolute Percentage Error)\n",
    "        mape = np.mean(np.abs((y - y_pred) / y)) * 100\n",
    "        \n",
    "        # Calculate accuracy based on threshold (±10%)\n",
    "        correct_predictions = np.abs(y_pred - y) <= threshold * np.abs(y)\n",
    "        accuracy = np.mean(correct_predictions) * 100  # Percentage of correct predictions\n",
    "\n",
    "        # Store the results\n",
    "        additional_results.append({\n",
    "            'Model': model_name,\n",
    "            'Best Params': grid_search.best_params_,\n",
    "            'Accuracy': accuracy,\n",
    "            'RMSE': rmse,\n",
    "            'R^2': r2,\n",
    "            'MAE': mae,\n",
    "            'MAPE': mape\n",
    "        })\n",
    "    \n",
    "    return additional_results\n",
    "\n",
    "# Function to display results sorted by accuracy and print summary\n",
    "def display_results_and_summary(results):\n",
    "    additional_results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Calculate the mean and standard deviation for each metric\n",
    "    metrics_summary = {\n",
    "        'Mean RMSE': np.mean([result['RMSE'] for result in results]),\n",
    "        'Std Dev RMSE': np.std([result['RMSE'] for result in results]),\n",
    "        'Mean R^2': np.mean([result['R^2'] for result in results]),\n",
    "        'Std Dev R^2': np.std([result['R^2'] for result in results]),\n",
    "        'Mean MAE': np.mean([result['MAE'] for result in results]),\n",
    "        'Std Dev MAE': np.std([result['MAE'] for result in results]),\n",
    "        'Mean MAPE': np.mean([result['MAPE'] for result in results]),\n",
    "        'Std Dev MAPE': np.std([result['MAPE'] for result in results]),\n",
    "    }\n",
    "\n",
    "    # Print individual model results sorted by accuracy\n",
    "    print(additional_results_df.sort_values(by=\"Accuracy\", ascending=False))\n",
    "\n",
    "    # Print summary of metrics\n",
    "    print(\"\\nSummary of Metrics:\")\n",
    "    for metric, value in metrics_summary.items():\n",
    "        print(f\"{metric}: {value}\")\n",
    "\n",
    "# Main function to run the entire process\n",
    "def main(url):\n",
    "    X, y = load_data(url)\n",
    "    models, param_grids = define_models()\n",
    "    results = evaluate_models(models, param_grids, X, y)\n",
    "    display_results_and_summary(results)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    url = 'bert_embeddings_input_output_custom_columns.csv'  # replace with your actual file URL\n",
    "    main(url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6043b74c",
   "metadata": {},
   "source": [
    "## Bert Testing Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee924012-2ad0-424b-a8be-050c35f12fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Linear Regression\n",
      "Predicted Marks: [1.63950232 3.91859908 2.29691113 2.01460243 3.86849459]\n",
      "Actual Marks: [0 4 2 1 5]\n",
      "----------------------------------------\n",
      "Model: Polynomial Regression (Degree 2)\n",
      "Predicted Marks: [1.31369907 4.23004346 2.07053043 1.20378361 3.88707994]\n",
      "Actual Marks: [0 4 2 1 5]\n",
      "----------------------------------------\n",
      "Model: Lasso Regression\n",
      "Predicted Marks: [2.20434655 2.51420874 2.45811418 2.33772177 2.50542081]\n",
      "Actual Marks: [0 4 2 1 5]\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression (used for binary targets)\n",
      "Predicted Marks: [0 5 1 0 5]\n",
      "Actual Marks: [0 4 2 1 5]\n",
      "----------------------------------------\n",
      "Model: Bayesian Linear Regression\n",
      "Predicted Marks: [1.19738859 3.9980072  2.16936771 1.73858151 4.37723246]\n",
      "Actual Marks: [0 4 2 1 5]\n",
      "----------------------------------------\n",
      "Model: Support Vector Regression\n",
      "Predicted Marks: [0.6227684  3.62052061 2.36500661 0.68830648 3.45888562]\n",
      "Actual Marks: [0 4 2 1 5]\n",
      "----------------------------------------\n",
      "Model: Decision Tree Regression\n",
      "Predicted Marks: [0. 5. 0. 0. 5.]\n",
      "Actual Marks: [0 4 2 1 5]\n",
      "----------------------------------------\n",
      "Model: Gaussian Process Regression\n",
      "Predicted Marks: [2.17721570e-16 6.62087253e-01 6.19336461e-02 5.41587320e-08\n",
      " 2.05435023e-01]\n",
      "Actual Marks: [0 4 2 1 5]\n",
      "----------------------------------------\n",
      "Model: Random Forest Regression\n",
      "Predicted Marks: [1.3  3.28 1.78 0.4  4.26]\n",
      "Actual Marks: [0 4 2 1 5]\n",
      "----------------------------------------\n",
      "Model: KNN Regression\n",
      "Predicted Marks: [0.2 4.6 2.6 0.8 4.8]\n",
      "Actual Marks: [0 4 2 1 5]\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso, LogisticRegression, BayesianRidge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Function to load and split the data\n",
    "def load_and_split_data(url, test_size=0.2, random_state=42):\n",
    "    data = pd.read_csv(url)\n",
    "    X = data.iloc[:, :-1]  # Features\n",
    "    y = data.iloc[:, -1]   # Target\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Function to define models\n",
    "def define_models():\n",
    "    models = {\n",
    "        \"Linear Regression\": LinearRegression(),\n",
    "        \"Polynomial Regression (Degree 2)\": make_pipeline(PolynomialFeatures(degree=2), LinearRegression()),\n",
    "        \"Lasso Regression\": Lasso(),\n",
    "        \"Logistic Regression (used for binary targets)\": LogisticRegression(),\n",
    "        \"Bayesian Linear Regression\": BayesianRidge(),\n",
    "        \"Support Vector Regression\": SVR(),\n",
    "        \"Decision Tree Regression\": DecisionTreeRegressor(),\n",
    "        \"Gaussian Process Regression\": GaussianProcessRegressor(),\n",
    "        \"Random Forest Regression\": RandomForestRegressor(),\n",
    "        \"KNN Regression\": KNeighborsRegressor()\n",
    "    }\n",
    "    return models\n",
    "\n",
    "# Function to train and evaluate models\n",
    "def train_and_evaluate_models(models, X_train, X_test, y_train, y_test):\n",
    "    for model_name, model in models.items():\n",
    "        try:\n",
    "            # Fit the model\n",
    "            model.fit(X_train, y_train)\n",
    "            # Predict on the test set\n",
    "            y_pred = model.predict(X_test)\n",
    "            \n",
    "            # Print results\n",
    "            print(f\"Model: {model_name}\")\n",
    "            print(f\"Predicted Marks: {y_pred[:5]}\")  # Print first 5 predictions\n",
    "            print(f\"Actual Marks: {y_test[:5].values}\")  # Print first 5 actual values\n",
    "            print(\"-\" * 40)\n",
    "        except Exception as e:\n",
    "            print(f\"Model: {model_name} - Error: {str(e)}\")\n",
    "            print(\"-\" * 40)\n",
    "\n",
    "# Main function to run the entire process\n",
    "def main(url):\n",
    "    # Load and split the data\n",
    "    X_train, X_test, y_train, y_test = load_and_split_data(url)\n",
    "    \n",
    "    # Define models\n",
    "    models = define_models()\n",
    "    \n",
    "    # Train and evaluate models\n",
    "    train_and_evaluate_models(models, X_train, X_test, y_train, y_test)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    url = \"Q1_bert.csv\"  # replace with your actual file URL\n",
    "    main(url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1d20ec",
   "metadata": {},
   "source": [
    "## Bert Testing Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46f03ae-1699-43bf-8771-7abead35993c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Linear Regression\n",
      "Predicted Marks: [2.55356843 1.54077868 2.55356843 1.7254718  5.        ]\n",
      "Actual Marks: [4. 0. 4. 0. 5.]\n",
      "----------------------------------------\n",
      "Model: Polynomial Regression (Degree 2)\n",
      "Predicted Marks: [2.25677647 1.36314363 2.25677647 1.70913599 5.        ]\n",
      "Actual Marks: [4. 0. 4. 0. 5.]\n",
      "----------------------------------------\n",
      "Model: Lasso Regression\n",
      "Predicted Marks: [2.38095238 2.38095238 2.38095238 2.38095238 2.38095238]\n",
      "Actual Marks: [4. 0. 4. 0. 5.]\n",
      "----------------------------------------\n",
      "Model: Logistic Regression (used for binary targets)\n",
      "Predicted Marks: [5. 0. 5. 2. 5.]\n",
      "Actual Marks: [4. 0. 4. 0. 5.]\n",
      "----------------------------------------\n",
      "Model: Bayesian Linear Regression\n",
      "Predicted Marks: [2.54233147 1.53974658 2.54233147 1.77237055 4.99999994]\n",
      "Actual Marks: [4. 0. 4. 0. 5.]\n",
      "----------------------------------------\n",
      "Model: Support Vector Regression\n",
      "Predicted Marks: [2.67813639 1.44656791 2.67813639 1.63145921 4.90017929]\n",
      "Actual Marks: [4. 0. 4. 0. 5.]\n",
      "----------------------------------------\n",
      "Model: Decision Tree Regression\n",
      "Predicted Marks: [2. 2. 2. 2. 5.]\n",
      "Actual Marks: [4. 0. 4. 0. 5.]\n",
      "----------------------------------------\n",
      "Model: Gaussian Process Regression\n",
      "Predicted Marks: [1.56602188e-04 1.05595714e-09 1.56602188e-04 1.31899573e-13\n",
      " 5.00000000e+00]\n",
      "Actual Marks: [4. 0. 4. 0. 5.]\n",
      "----------------------------------------\n",
      "Model: Random Forest Regression\n",
      "Predicted Marks: [1.77 1.59 1.77 1.55 5.  ]\n",
      "Actual Marks: [4. 0. 4. 0. 5.]\n",
      "----------------------------------------\n",
      "Model: KNN Regression\n",
      "Predicted Marks: [4.4 1.2 4.4 2.6 5. ]\n",
      "Actual Marks: [4. 0. 4. 0. 5.]\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso, LogisticRegression, BayesianRidge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Function to load and preprocess the data\n",
    "def load_and_preprocess_data(url):\n",
    "    # Load dataset\n",
    "    data = pd.read_csv(url)\n",
    "\n",
    "    # Handle missing values (drop rows where the target is NaN)\n",
    "    data = data.dropna(subset=[data.columns[-1]])\n",
    "\n",
    "    # Split into features and target\n",
    "    X = data.iloc[:, :-1]  # Features\n",
    "    y = data.iloc[:, -1]   # Target\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Function to split the data into training and testing sets\n",
    "def split_data(X, y, test_size=0.2, random_state=42):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Function to define the models\n",
    "def define_models():\n",
    "    models = {\n",
    "        \"Linear Regression\": LinearRegression(),\n",
    "        \"Polynomial Regression (Degree 2)\": make_pipeline(PolynomialFeatures(degree=2), LinearRegression()),\n",
    "        \"Lasso Regression\": Lasso(),\n",
    "        \"Logistic Regression (used for binary targets)\": LogisticRegression(),\n",
    "        \"Bayesian Linear Regression\": BayesianRidge(),\n",
    "        \"Support Vector Regression\": SVR(),\n",
    "        \"Decision Tree Regression\": DecisionTreeRegressor(),\n",
    "        \"Gaussian Process Regression\": GaussianProcessRegressor(),\n",
    "        \"Random Forest Regression\": RandomForestRegressor(),\n",
    "        \"KNN Regression\": KNeighborsRegressor()\n",
    "    }\n",
    "    return models\n",
    "\n",
    "# Function to train and evaluate the models\n",
    "def train_and_evaluate_models(models, X_train, X_test, y_train, y_test):\n",
    "    for model_name, model in models.items():\n",
    "        try:\n",
    "            # Fit the model\n",
    "            model.fit(X_train, y_train)\n",
    "            # Predict on the test set\n",
    "            y_pred = model.predict(X_test)\n",
    "            \n",
    "            # Print results\n",
    "            print(f\"Model: {model_name}\")\n",
    "            print(f\"Predicted Marks: {y_pred[:5]}\")  # Print first 5 predictions\n",
    "            print(f\"Actual Marks: {y_test[:5].values}\")  # Print first 5 actual values\n",
    "            print(\"-\" * 40)\n",
    "        except Exception as e:\n",
    "            print(f\"Model: {model_name} - Error: {str(e)}\")\n",
    "            print(\"-\" * 40)\n",
    "\n",
    "# Main function to execute the whole process\n",
    "def main(url):\n",
    "    # Load and preprocess the data\n",
    "    X, y = load_and_preprocess_data(url)\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = split_data(X, y)\n",
    "    \n",
    "    # Define models\n",
    "    models = define_models()\n",
    "    \n",
    "    # Train and evaluate models\n",
    "    train_and_evaluate_models(models, X_train, X_test, y_train, y_test)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    url = \"Q2_bert.csv\"  # replace with your actual file URL\n",
    "    main(url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc63caec",
   "metadata": {},
   "source": [
    "## Bert testing Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12b062f-1a60-4ffb-9132-5d3628783d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Linear Regression\n",
      "Predicted Marks: [1, 3, 0, 4, 1]\n",
      "Actual Marks: [1, 1, 1, 5, 0]\n",
      "----------------------------------------\n",
      "Model: Polynomial Regression (Degree 2)\n",
      "Predicted Marks: [1, 3, 0, 4, 1]\n",
      "Actual Marks: [1, 1, 1, 5, 0]\n",
      "----------------------------------------\n",
      "Model: Lasso Regression\n",
      "Predicted Marks: [2, 2, 2, 2, 2]\n",
      "Actual Marks: [1, 1, 1, 5, 0]\n",
      "----------------------------------------\n",
      "Model: Logistic Regression (used for binary targets)\n",
      "Predicted Marks: [1, 4, 1, 4, 1]\n",
      "Actual Marks: [1, 1, 1, 5, 0]\n",
      "----------------------------------------\n",
      "Model: Bayesian Linear Regression\n",
      "Predicted Marks: [1, 3, 0, 3, 1]\n",
      "Actual Marks: [1, 1, 1, 5, 0]\n",
      "----------------------------------------\n",
      "Model: Support Vector Regression\n",
      "Predicted Marks: [1, 2, 1, 2, 1]\n",
      "Actual Marks: [1, 1, 1, 5, 0]\n",
      "----------------------------------------\n",
      "Model: Decision Tree Regression\n",
      "Predicted Marks: [5, 1, 1, 4, 1]\n",
      "Actual Marks: [1, 1, 1, 5, 0]\n",
      "----------------------------------------\n",
      "Model: Gaussian Process Regression\n",
      "Predicted Marks: [0, 0, 0, 3, 0]\n",
      "Actual Marks: [1, 1, 1, 5, 0]\n",
      "----------------------------------------\n",
      "Model: Random Forest Regression\n",
      "Predicted Marks: [1, 2, 1, 3, 1]\n",
      "Actual Marks: [1, 1, 1, 5, 0]\n",
      "----------------------------------------\n",
      "Model: KNN Regression\n",
      "Predicted Marks: [0, 1, 1, 1, 1]\n",
      "Actual Marks: [1, 1, 1, 5, 0]\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso, LogisticRegression, BayesianRidge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Function to load and preprocess the data\n",
    "def load_and_preprocess_data(url):\n",
    "    # Load dataset\n",
    "    data = pd.read_csv(url)\n",
    "\n",
    "    # Handle missing values (drop rows where the target is NaN)\n",
    "    data = data.dropna(subset=[data.columns[-1]])\n",
    "\n",
    "    # Split into features and target\n",
    "    X = data.iloc[:, :-1]  # Features\n",
    "    y = data.iloc[:, -1]   # Target\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Function to split the data into training and testing sets\n",
    "def split_data(X, y, test_size=0.2, random_state=42):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Function to define the models\n",
    "def define_models():\n",
    "    models = {\n",
    "        \"Linear Regression\": LinearRegression(),\n",
    "        \"Polynomial Regression (Degree 2)\": make_pipeline(PolynomialFeatures(degree=2), LinearRegression()),\n",
    "        \"Lasso Regression\": Lasso(),\n",
    "        \"Logistic Regression (used for binary targets)\": LogisticRegression(),\n",
    "        \"Bayesian Linear Regression\": BayesianRidge(),\n",
    "        \"Support Vector Regression\": SVR(),\n",
    "        \"Decision Tree Regression\": DecisionTreeRegressor(),\n",
    "        \"Gaussian Process Regression\": GaussianProcessRegressor(),\n",
    "        \"Random Forest Regression\": RandomForestRegressor(),\n",
    "        \"KNN Regression\": KNeighborsRegressor()\n",
    "    }\n",
    "    return models\n",
    "\n",
    "# Function to train and evaluate the models\n",
    "def train_and_evaluate_models(models, X_train, X_test, y_train, y_test):\n",
    "    for model_name, model in models.items():\n",
    "        try:\n",
    "            # Fit the model\n",
    "            model.fit(X_train, y_train)\n",
    "            # Predict on the test set\n",
    "            y_pred = model.predict(X_test)\n",
    "            \n",
    "            # Convert predictions and actual values to integers\n",
    "            y_pred_int = y_pred.astype(int)\n",
    "            y_test_int = y_test.astype(int)\n",
    "            \n",
    "            # Print results\n",
    "            print(f\"Model: {model_name}\")\n",
    "            print(f\"Predicted Marks: {list(y_pred_int[:5])}\")  # Print first 5 predictions as integers\n",
    "            print(f\"Actual Marks: {list(y_test_int[:5].values)}\")  # Print first 5 actual values as integers\n",
    "            print(\"-\" * 40)\n",
    "        except Exception as e:\n",
    "            print(f\"Model: {model_name} - Error: {str(e)}\")\n",
    "            print(\"-\" * 40)\n",
    "\n",
    "# Main function to execute the whole process\n",
    "def main(url):\n",
    "    # Load and preprocess the data\n",
    "    X, y = load_and_preprocess_data(url)\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = split_data(X, y)\n",
    "    \n",
    "    # Define models\n",
    "    models = define_models()\n",
    "    \n",
    "    # Train and evaluate models\n",
    "    train_and_evaluate_models(models, X_train, X_test, y_train, y_test)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    url = \"Q3_bert.csv\"  # replace with your actual file URL\n",
    "    main(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24482cd-d8e9-4bb2-979d-95bb61f6b577",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
