{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09f44bcb-8fec-44af-8186-8df211ce140c",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors (KNN) Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50800594-fffd-457e-80db-9989728cfdb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 80 candidates, totalling 800 fits\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=1, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=1, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=1, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=uniform; total time=   0.5s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=uniform; total time=   0.5s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=uniform; total time=   0.5s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=uniform; total time=   0.5s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance; total time=   0.5s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=uniform; total time=   0.5s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=distance; total time=   0.5s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=distance; total time=   0.5s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=1, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=1, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=1, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=1, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=1, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=1, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=1, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=1, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=1, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=1, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=1, weights=distance; total time=   0.5s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=2, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=2, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=2, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=2, weights=distance; total time=   0.0s\n",
      "Best Parameters: {'algorithm': 'kd_tree', 'n_neighbors': 5, 'p': 1, 'weights': 'distance'}\n",
      "R Score: 0.4944857294258852\n",
      "RMSE: 0.8800130681679734\n",
      "MAE: 0.5960922897977456\n",
      "Mean of Output: 3.4022140221402215\n",
      "Standard Deviation of Output: 1.2377200077817099\n",
      "Cross-Validation Scores: [2.28899527 1.28169165 0.93687969 0.72664419 0.79756431 0.7450616\n",
      " 0.79558042 0.60472224 1.03976588 1.52945724]\n",
      "Cross-Validation Mean: 1.0746362492291592\n",
      "Cross-Validation Std Dev: 0.48474455477224043\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Function to load dataset\n",
    "def load_data(file_path, target_column):\n",
    "    \"\"\"\n",
    "    Load dataset and separate features and target column.\n",
    "    \n",
    "    Parameters:\n",
    "        file_path (str): Path to the dataset file.\n",
    "        target_column (str): Name of the target column.\n",
    "\n",
    "    Returns:\n",
    "        X, y (DataFrame, Series): Features and target data.\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(file_path)\n",
    "    X = data.drop(columns=[target_column])\n",
    "    y = data[target_column]\n",
    "    return X, y\n",
    "\n",
    "# Function to perform grid search for best model\n",
    "def grid_search_knn(X_train, y_train, param_grid):\n",
    "    \"\"\"\n",
    "    Perform GridSearchCV for KNN model hyperparameter tuning.\n",
    "\n",
    "    Parameters:\n",
    "        X_train (DataFrame): Training features.\n",
    "        y_train (Series): Training target.\n",
    "        param_grid (dict): Hyperparameter grid for tuning.\n",
    "\n",
    "    Returns:\n",
    "        GridSearchCV: Best KNN model found from grid search.\n",
    "    \"\"\"\n",
    "    knn = KNeighborsRegressor()\n",
    "    grid_search = GridSearchCV(estimator=knn, param_grid=param_grid, cv=10, scoring='neg_mean_squared_error', verbose=2)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return grid_search\n",
    "\n",
    "# Function to evaluate model performance\n",
    "def evaluate_model(y_test, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate performance metrics for the model.\n",
    "\n",
    "    Parameters:\n",
    "        y_test (array): True target values.\n",
    "        y_pred (array): Predicted target values.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing R, RMSE, MAE, mean, and std dev.\n",
    "    \"\"\"\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    output_mean = np.mean(y_test)\n",
    "    output_std_dev = np.std(y_test)\n",
    "    return {\n",
    "        \"R Score\": r2, \n",
    "        \"RMSE\": rmse,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd63671e-29ae-4643-a9b8-8eb9478a406b",
   "metadata": {},
   "source": [
    "# Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfa1720-a86a-412e-af16-8baa8bf4fb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=2; total time= 1.1min\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=2; total time= 1.0min\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=2; total time= 1.1min\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=2; total time= 1.1min\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=2; total time=  52.0s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=2; total time=  52.3s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=2; total time=  51.2s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=2; total time=  46.6s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=2; total time=  56.4s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=2; total time=  46.6s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=3; total time=   0.0s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=3; total time=   0.0s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=3; total time=   0.0s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=3; total time=   0.0s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=3; total time=   0.0s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=3; total time=   0.0s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=3; total time=   0.0s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=3; total time=   0.0s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=3; total time=   0.0s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=3; total time=   0.0s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=4; total time=   0.5s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=4; total time=   0.5s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=4; total time=   0.5s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=4; total time=   0.5s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=4; total time=   0.5s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=4; total time=   0.5s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=4; total time=   0.5s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=4; total time=   0.5s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=4; total time=   0.5s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=4; total time=   0.5s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=2; total time=  51.7s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=2; total time=  51.9s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=2; total time=  51.7s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=2; total time=  52.0s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=2; total time=  47.4s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=2; total time=  46.6s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=2; total time=  46.6s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=2; total time=  45.9s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=2; total time=  45.9s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=2; total time=  51.5s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=3; total time=   0.0s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=3; total time=   0.0s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=3; total time=   0.0s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=3; total time=   0.0s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=3; total time=   0.0s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=3; total time=   0.0s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=3; total time=   0.0s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=3; total time=   0.0s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=3; total time=   0.0s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=3; total time=   0.0s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=4; total time=   0.5s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=4; total time=   0.5s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=4; total time=   0.5s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=4; total time=   0.5s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=4; total time=   0.5s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=4; total time=   0.5s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=4; total time=   0.5s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=4; total time=   0.5s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=4; total time=   0.5s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=4; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "40 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1101, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "         ^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 553. GiB for an array with shape (975, 76088705) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1101, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "         ^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 553. GiB for an array with shape (976, 76088705) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1101, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "         ^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 104. TiB for an array with shape (975, 14685120065) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1101, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "         ^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 104. TiB for an array with shape (976, 14685120065) and data type float64\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [-7.43161443e+22             nan             nan -8.18724935e+22\n",
      "             nan             nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'linear__fit_intercept': True, 'poly__degree': 2}\n",
      "R Score: -1.379757815705473e+22\n",
      "RMSE: 145386420065.53198\n",
      "MAE: 79075578033.52428\n",
      "Mean of Output: 3.4022140221402215\n",
      "Standard Deviation of Output: 1.2377200077817099\n",
      "Cross-Validation Scores: [1.97831501e+12 3.23862638e+11 3.59077655e+11 3.68109949e+11\n",
      " 1.93279233e+11 3.07736375e+11 1.24655787e+11 4.48964590e+11\n",
      " 3.08282727e+11 3.00107986e+11]\n",
      "Cross-Validation Mean: 471239195383.9152\n",
      "Cross-Validation Std Dev: 509574827739.6164\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, KFold, cross_val_score\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Function to load and prepare the dataset\n",
    "def load_and_prepare_data(file_path, target_column):\n",
    "    \"\"\"\n",
    "    Load dataset and separate features and target column.\n",
    "    \n",
    "    Parameters:\n",
    "        file_path (str): Path to the dataset file.\n",
    "        target_column (str): Name of the target column.\n",
    "\n",
    "    Returns:\n",
    "        X (DataFrame): Feature data.\n",
    "        y (Series): Target data.\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(file_path)\n",
    "    X = data.drop(columns=[target_column])\n",
    "    y = data[target_column]\n",
    "    return X, y\n",
    "\n",
    "# Function to create a pipeline with PolynomialFeatures and LinearRegression\n",
    "def create_pipeline():\n",
    "    \"\"\"\n",
    "    Create a pipeline for scaling, polynomial feature transformation, and linear regression.\n",
    "    \n",
    "    Returns:\n",
    "        Pipeline: A scikit-learn pipeline.\n",
    "    \"\"\"\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),  # Standardize features\n",
    "        ('poly', PolynomialFeatures()),  # Polynomial features transformation\n",
    "        ('linear', LinearRegression())  # Linear regression model\n",
    "    ])\n",
    "    return pipeline\n",
    "\n",
    "# Function for hyperparameter tuning using GridSearchCV\n",
    "def perform_grid_search(pipeline, X_train, y_train, param_grid, cv):\n",
    "    \"\"\"\n",
    "    Perform GridSearchCV to find the best model and parameters.\n",
    "    \n",
    "    Parameters:\n",
    "        pipeline (Pipeline): The pipeline to be used for grid search.\n",
    "        X_train (DataFrame): Training features.\n",
    "        y_train (Series): Training target.\n",
    "        param_grid (dict): Hyperparameter grid for tuning.\n",
    "        cv (KFold): Cross-validation strategy.\n",
    "        \n",
    "    Returns:\n",
    "        GridSearchCV: The best model from grid search.\n",
    "    \"\"\"\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=cv, scoring='neg_mean_squared_error', verbose=2)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return grid_search\n",
    "\n",
    "# Function to evaluate the model on the test set\n",
    "def evaluate_model(y_test, y_pred):\n",
    "    \"\"\"\n",
    "    Evaluate model performance using R, RMSE, MAE, and output statistics.\n",
    "    \n",
    "    Parameters:\n",
    "        y_test (array): True target values.\n",
    "        y_pred (array): Predicted target values.\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing evaluation metrics.\n",
    "    \"\"\"\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    output_mean = np.mean(y_test)\n",
    "    output_std_dev = np.std(y_test)\n",
    "    \n",
    "    return {\n",
    "        \"R Score\": r2, \n",
    "        \"RMSE\": rmse, \n",
    "        \"MAE\": mae, \n",
    "        \"Mean of Output\": output_mean, \n",
    "        \"Standard Deviation of Output\": output_std_dev\n",
    "    }\n",
    "\n",
    "# Function for cross-validation\n",
    "def cross_validate_model(best_model, X, y, cv):\n",
    "    \"\"\"\n",
    "    Perform cross-validation on the best model and return cross-validation scores.\n",
    "    \n",
    "    Parameters:\n",
    "        best_model (estimator): The best model from grid search.\n",
    "        X (DataFrame): Feature data.\n",
    "        y (Series): Target data.\n",
    "        cv (KFold): Cross-validation strategy.\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing cross-validation scores and statistics.\n",
    "    \"\"\"\n",
    "    cv_scores = cross_val_score(best_model, X, y, cv=cv, scoring='neg_mean_squared_error')\n",
    "    cv_scores = np.sqrt(-cv_scores)  # Convert to positive RMSE values\n",
    "    cv_mean = np.mean(cv_scores)\n",
    "    cv_std_dev = np.std(cv_scores)\n",
    "    \n",
    "    return {\n",
    "        \"Cross-Validation Scores\": cv_scores,\n",
    "        \"Cross-Validation Mean\": cv_mean,\n",
    "        \"Cross-Validation Std Dev\": cv_std_dev\n",
    "    }\n",
    "\n",
    "# Function to print results\n",
    "def print_results(grid_search, evaluation_metrics, cross_validation_results):\n",
    "    \"\"\"\n",
    "    Print the results of grid search, evaluation metrics, and cross-validation.\n",
    "    \n",
    "    Parameters:\n",
    "        grid_search (GridSearchCV): The grid search results.\n",
    "        evaluation_metrics (dict): Dictionary containing evaluation metrics.\n",
    "        cross_validation_results (dict): Dictionary containing cross-validation results.\n",
    "    \"\"\"\n",
    "    print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "    for metric, value in evaluation_metrics.items():\n",
    "        print(f\"{metric}: {value}\")\n",
    "    for metric, value in cross_validation_results.items():\n",
    "        print(f\"{metric}: {value}\")\n",
    "\n",
    "# Main function to run the pipeline\n",
    "def main():\n",
    "    # Load the dataset\n",
    "    file_path = 'gpt2_test_2.csv'\n",
    "    target_column = 'output'\n",
    "    X, y = load_and_prepare_data(file_path, target_column)\n",
    "\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Create pipeline\n",
    "    pipeline = create_pipeline()\n",
    "\n",
    "    # Define parameter grid for grid search\n",
    "    param_grid = {\n",
    "        'poly__degree': [2, 3, 4],  # Testing various degrees of polynomial features\n",
    "        'linear__fit_intercept': [True, False]  # Fit intercept or not\n",
    "    }\n",
    "\n",
    "    # Set up cross-validation\n",
    "    cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "    # Perform grid search\n",
    "    grid_search = perform_grid_search(pipeline, X_train, y_train, param_grid, cv)\n",
    "\n",
    "    # Get the best model\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    evaluation_metrics = evaluate_model(y_test, y_pred)\n",
    "\n",
    "    # Perform cross-validation\n",
    "    cross_validation_results = cross_validate_model(best_model, X, y, cv)\n",
    "\n",
    "    # Print all results\n",
    "    print_results(grid_search, evaluation_metrics, cross_validation_results)\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea1506a-5107-479b-87b0-a665ac32caf8",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a816964-4517-49e6-8569-a44ab9303d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "R Score: 0.28220215451345676\n",
      "RMSE: 1.0486329178077347\n",
      "MAE: 0.5977859778597786\n",
      "Mean of Output: 3.4022140221402215\n",
      "Standard Deviation of Output: 1.2377200077817099\n",
      "Cross-Validation Scores: [1.03161048 0.98614252 0.98614252 1.0794154  1.04527154 0.89235436\n",
      " 0.9953596  0.81649658 1.01835015 0.94770678]\n",
      "Cross-Validation Mean: 0.9798849937880721\n",
      "Cross-Validation Std Dev: 0.07351693517584089\n",
      "Standard Deviation of Predictions: 1.214498723175727\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Function to load and prepare data\n",
    "def load_and_prepare_data(file_path, target_column):\n",
    "    \"\"\"\n",
    "    Load dataset and separate features and target column.\n",
    "    \n",
    "    Parameters:\n",
    "        file_path (str): Path to the dataset file.\n",
    "        target_column (str): The target column name in the dataset.\n",
    "\n",
    "    Returns:\n",
    "        X (DataFrame): Feature data.\n",
    "        y (Series): Target data.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "    return X, y\n",
    "\n",
    "# Function to standardize features\n",
    "def standardize_features(X):\n",
    "    \"\"\"\n",
    "    Standardize features by applying StandardScaler.\n",
    "    \n",
    "    Parameters:\n",
    "        X (DataFrame): Feature data.\n",
    "\n",
    "    Returns:\n",
    "        X_scaled (array): Scaled feature data.\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    return X_scaled\n",
    "\n",
    "# Function to perform grid search for hyperparameter tuning\n",
    "def perform_grid_search(model, param_grid, X_train, y_train):\n",
    "    \"\"\"\n",
    "    Perform GridSearchCV to find the best model and hyperparameters.\n",
    "    \n",
    "    Parameters:\n",
    "        model (estimator): Model to tune.\n",
    "        param_grid (dict): Hyperparameter grid for tuning.\n",
    "        X_train (DataFrame): Training feature data.\n",
    "        y_train (Series): Training target data.\n",
    "        \n",
    "    Returns:\n",
    "        grid_search (GridSearchCV): The grid search object with the best model.\n",
    "    \"\"\"\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=10, scoring='neg_mean_squared_error')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return grid_search\n",
    "\n",
    "# Function to evaluate model performance\n",
    "def evaluate_model(y_test, y_pred):\n",
    "    \"\"\"\n",
    "    Evaluate model performance using R, RMSE, MAE, and output statistics.\n",
    "    \n",
    "    Parameters:\n",
    "        y_test (array): True target values.\n",
    "        y_pred (array): Predicted target values.\n",
    "        \n",
    "    Returns:\n",
    "        dict: Evaluation metrics including R, RMSE, MAE, and output statistics.\n",
    "    \"\"\"\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    output_mean = np.mean(y_test)\n",
    "    output_std_dev = np.std(y_test)\n",
    "    \n",
    "    return {\n",
    "        \"R Score\": r2, \n",
    "        \"RMSE\": rmse, \n",
    "        \"MAE\": mae, \n",
    "        \"Mean of Output\": output_mean, \n",
    "        \"Standard Deviation of Output\": output_std_dev\n",
    "    }\n",
    "\n",
    "# Function to perform cross-validation and calculate RMSE\n",
    "def cross_validate_model(model, X_train, y_train):\n",
    "    \"\"\"\n",
    "    Perform cross-validation on the model and return cross-validation scores.\n",
    "    \n",
    "    Parameters:\n",
    "        model (estimator): The trained model.\n",
    "        X_train (DataFrame): Feature data for cross-validation.\n",
    "        y_train (Series): Target data for cross-validation.\n",
    "        \n",
    "    Returns:\n",
    "        dict: Cross-validation scores and statistics (mean, std deviation).\n",
    "    \"\"\"\n",
    "    cross_val_scores = cross_val_score(model, X_train, y_train, cv=10, scoring='neg_mean_squared_error')\n",
    "    cv_scores = np.sqrt(-cross_val_scores)  # Convert to positive RMSE values\n",
    "    cv_mean = np.mean(cv_scores)\n",
    "    cv_std_dev = np.std(cv_scores)\n",
    "    \n",
    "    return {\n",
    "        \"Cross-Validation Scores\": cv_scores,\n",
    "        \"Cross-Validation Mean\": cv_mean,\n",
    "        \"Cross-Validation Std Dev\": cv_std_dev\n",
    "    }\n",
    "\n",
    "# Function to print results\n",
    "def print_results(grid_search, evaluation_metrics, cross_validation_results, std_dev):\n",
    "    \"\"\"\n",
    "    Print the results from grid search, model evaluation, and cross-validation.\n",
    "    \n",
    "    Parameters:\n",
    "        grid_search (GridSearchCV): The grid search object with best parameters.\n",
    "        evaluation_metrics (dict): Dictionary with evaluation metrics.\n",
    "        cross_validation_results (dict): Dictionary with cross-validation results.\n",
    "        std_dev (float): Standard deviation of model predictions.\n",
    "    \"\"\"\n",
    "    print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "    for metric, value in evaluation_metrics.items():\n",
    "        print(f\"{metric}: {value}\")\n",
    "    for metric, value in cross_validation_results.items():\n",
    "        print(f\"{metric}: {value}\")\n",
    "    print(f\"Standard Deviation of Predictions: {std_dev}\")\n",
    "\n",
    "# Main function to run the complete process\n",
    "def main():\n",
    "    # Load and prepare data\n",
    "    file_path = 'gpt2_test_2.csv'\n",
    "    target_column = 'output'\n",
    "    X, y = load_and_prepare_data(file_path, target_column)\n",
    "    \n",
    "    # Standardize features\n",
    "    X_scaled = standardize_features(X)\n",
    "    \n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Define the Logistic Regression model\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    \n",
    "    # Define parameter grid for grid search\n",
    "    param_grid = {\n",
    "        'C': [0.01, 0.1, 1, 10, 100],\n",
    "        'solver': ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "        'penalty': ['l2'],  # l2 regularization for Logistic Regression\n",
    "    }\n",
    "    \n",
    "    # Perform grid search\n",
    "    grid_search = perform_grid_search(model, param_grid, X_train, y_train)\n",
    "    \n",
    "    # Get the best model from grid search\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    evaluation_metrics = evaluate_model(y_test, y_pred)\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    cross_validation_results = cross_validate_model(best_model, X_train, y_train)\n",
    "    \n",
    "    # Calculate Standard Deviation of Predictions\n",
    "    std_dev = np.std(y_pred)\n",
    "    \n",
    "    # Print all results\n",
    "    print_results(grid_search, evaluation_metrics, cross_validation_results, std_dev)\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5e07bd-20d1-45c6-abd5-17aca527dd08",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cf15be-d4a7-47d5-b2e8-d2cf1f91ec4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    embed_0   embed_1   embed_2   embed_3   embed_4   embed_5    embed_6  \\\n",
      "0  0.088828 -0.161809 -0.061903 -0.041983 -0.216466 -0.119152  11.951169   \n",
      "1  0.146692 -0.119815 -0.979210  0.085807  0.008980 -0.136545   1.863782   \n",
      "2  0.018409 -0.323487 -0.255188 -0.175120  0.453114  0.234411   7.320464   \n",
      "3 -0.189907 -0.307564 -0.385835 -0.038812  0.373633  0.196549   9.743107   \n",
      "4 -0.007651 -0.369977 -0.555113 -0.006253  0.088651  0.129726   7.823362   \n",
      "\n",
      "    embed_7   embed_8   embed_9  ...  embed_759  embed_760  embed_761  \\\n",
      "0  0.126399  0.356953  0.219979  ...   1.018518  -0.063625  -0.211650   \n",
      "1  0.073784  0.191401  0.213136  ...   0.062188   0.018683  -0.260519   \n",
      "2 -0.036020 -0.241820 -0.175831  ...  -0.228277  -0.186306   0.217426   \n",
      "3 -0.085457 -0.206629 -0.151518  ...   0.292949  -0.014901   0.475006   \n",
      "4  0.179337 -0.134409  0.088882  ...  -0.025282   0.461727   0.503787   \n",
      "\n",
      "   embed_762  embed_763  embed_764  embed_765  embed_766  embed_767  output  \n",
      "0   4.267710   0.141019   0.039147  -0.135620  -0.451604   0.156114       0  \n",
      "1   2.096450  -0.106316   0.148366  -0.051111  -0.124474   0.120384       0  \n",
      "2   0.649411  -0.114102   0.242630   0.123016   0.005927  -0.344435       0  \n",
      "3   0.661420  -0.120505   0.410390   0.094925  -0.026481  -0.219293       0  \n",
      "4  -0.135410   0.209564   0.274533   0.088838  -0.067235   0.064882       0  \n",
      "\n",
      "[5 rows x 769 columns]\n",
      "Index(['embed_0', 'embed_1', 'embed_2', 'embed_3', 'embed_4', 'embed_5',\n",
      "       'embed_6', 'embed_7', 'embed_8', 'embed_9',\n",
      "       ...\n",
      "       'embed_759', 'embed_760', 'embed_761', 'embed_762', 'embed_763',\n",
      "       'embed_764', 'embed_765', 'embed_766', 'embed_767', 'output'],\n",
      "      dtype='object', length=769)\n",
      "R Score: -1.9761213474118361e+21\n",
      "RMSE: 53605303583.27091\n",
      "MAE: 0.018046983733049592\n",
      "Mean of Output: 3.37\n",
      "Standard Deviation of Output: 1.2120643547270913\n",
      "Cross-Validation Scores: [1.01408201e+11 1.66423159e+10 3.72862419e+10 3.22599719e+09\n",
      " 7.92942384e+10 6.36788658e+10 5.33137196e+10 1.93963243e+10\n",
      " 5.54192636e+10 1.18989813e+10]\n",
      "Cross-Validation Mean: 44156414945.45152\n",
      "Cross-Validation Std Dev: 30393084598.63432\n",
      "Standard Deviation of MSE: 3.143897685290116e+21\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Function to load and prepare the data\n",
    "def load_and_prepare_data(file_path, target_column):\n",
    "    \"\"\"\n",
    "    Load and prepare the dataset by separating features and target.\n",
    "    \n",
    "    Parameters:\n",
    "        file_path (str): Path to the dataset file.\n",
    "        target_column (str): The target column name in the dataset.\n",
    "        \n",
    "    Returns:\n",
    "        X (ndarray): Features data.\n",
    "        y (ndarray): Target data.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    X = df.drop(columns=[target_column]).values\n",
    "    y = df[target_column].values\n",
    "    return X, y\n",
    "\n",
    "# Function to normalize the data\n",
    "def normalize_data(X):\n",
    "    \"\"\"\n",
    "    Normalize features using StandardScaler.\n",
    "    \n",
    "    Parameters:\n",
    "        X (ndarray): Feature data.\n",
    "        \n",
    "    Returns:\n",
    "        X_scaled (ndarray): Scaled feature data.\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    return X_scaled, scaler\n",
    "\n",
    "# Function to perform grid search with cross-validation\n",
    "def perform_grid_search(model, X, y, param_grid=None, cv_folds=10):\n",
    "    \"\"\"\n",
    "    Perform GridSearchCV to find the best model and hyperparameters.\n",
    "    \n",
    "    Parameters:\n",
    "        model (estimator): The model to tune.\n",
    "        X (ndarray): Feature data.\n",
    "        y (ndarray): Target data.\n",
    "        param_grid (dict): Hyperparameter grid for tuning (default is empty for LinearRegression).\n",
    "        cv_folds (int): Number of cross-validation folds.\n",
    "        \n",
    "    Returns:\n",
    "        grid_search (GridSearchCV): The grid search object with the best model.\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=kf, scoring='neg_mean_squared_error')\n",
    "    grid_search.fit(X, y)\n",
    "    return grid_search\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate_model(model, X, y, cv_folds=10):\n",
    "    \"\"\"\n",
    "    Evaluate the model using cross-validation and calculate metrics like MSE, RMSE, R, etc.\n",
    "    \n",
    "    Parameters:\n",
    "        model (estimator): The trained model.\n",
    "        X (ndarray): Feature data.\n",
    "        y (ndarray): Target data.\n",
    "        cv_folds (int): Number of cross-validation folds.\n",
    "        \n",
    "    Returns:\n",
    "        metrics (dict): Calculated metrics including RMSE, MAE, R, and cross-validation results.\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Cross-validation scores for MSE and R\n",
    "    mse_scores = cross_val_score(model, X, y, cv=kf, scoring='neg_mean_squared_error')\n",
    "    r2_scores = cross_val_score(model, X, y, cv=kf, scoring='r2')\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse_mean = -mse_scores.mean()  # Convert negative MSE to positive\n",
    "    rmse = np.sqrt(mse_mean)       # RMSE\n",
    "    mae = mean_absolute_error(y, model.predict(X))  # MAE\n",
    "    r2_mean = r2_scores.mean()     # R\n",
    "    std_dev_mse = np.std(mse_scores)  # Standard deviation of MSE\n",
    "    \n",
    "    # Cross-validation RMSE\n",
    "    cv_scores = np.sqrt(-mse_scores)  # Convert negative MSE to positive RMSE\n",
    "    cv_mean = cv_scores.mean()        # Cross-validation mean RMSE\n",
    "    cv_std_dev = cv_scores.std()      # Cross-validation std dev RMSE\n",
    "    \n",
    "    # Additional statistics\n",
    "    output_mean = np.mean(y)         # Mean of Output\n",
    "    output_std_dev = np.std(y)       # Standard deviation of Output\n",
    "    \n",
    "    # Store metrics in a dictionary\n",
    "    metrics = {\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAE\": mae,\n",
    "        \"R\": r2_mean,\n",
    "        \"Mean of Output\": output_mean,\n",
    "        \"Standard Deviation of Output\": output_std_dev,\n",
    "        \"Cross-Validation Scores\": cv_scores,\n",
    "        \"Cross-Validation Mean\": cv_mean,\n",
    "        \"Cross-Validation Std Dev\": cv_std_dev,\n",
    "        \"Standard Deviation of MSE\": std_dev_mse\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Function to display results\n",
    "def print_results(metrics):\n",
    "    \"\"\"\n",
    "    Print the evaluation metrics.\n",
    "    \n",
    "    Parameters:\n",
    "        metrics (dict): Dictionary of calculated metrics.\n",
    "    \"\"\"\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value}\")\n",
    "\n",
    "# Main function to run the process\n",
    "def main():\n",
    "    # Load and prepare data\n",
    "    file_path = 'gpt2_test_2.csv'\n",
    "    target_column = 'output'\n",
    "    X, y = load_and_prepare_data(file_path, target_column)\n",
    "    \n",
    "    # Normalize the data\n",
    "    X_scaled, scaler = normalize_data(X)\n",
    "    \n",
    "    # Initialize the Linear Regression model\n",
    "    model = LinearRegression()\n",
    "    \n",
    "    # Perform grid search (no hyperparameters for LinearRegression)\n",
    "    grid_search = perform_grid_search(model, X_scaled, y)\n",
    "    \n",
    "    # Get the best model from grid search\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # Evaluate the model using cross-validation and calculate metrics\n",
    "    metrics = evaluate_model(best_model, X_scaled, y)\n",
    "    \n",
    "    # Print the results\n",
    "    print_results(metrics)\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c092cdfc-80b6-41b5-8fed-be61b036dcaa",
   "metadata": {},
   "source": [
    "# Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb002460-184d-413d-a240-612d79d7e5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    embed_0   embed_1   embed_2   embed_3   embed_4   embed_5    embed_6  \\\n",
      "0  0.088828 -0.161809 -0.061903 -0.041983 -0.216466 -0.119152  11.951169   \n",
      "1  0.146692 -0.119815 -0.979210  0.085807  0.008980 -0.136545   1.863782   \n",
      "2  0.018409 -0.323487 -0.255188 -0.175120  0.453114  0.234411   7.320464   \n",
      "3 -0.189907 -0.307564 -0.385835 -0.038812  0.373633  0.196549   9.743107   \n",
      "4 -0.007651 -0.369977 -0.555113 -0.006253  0.088651  0.129726   7.823362   \n",
      "\n",
      "    embed_7   embed_8   embed_9  ...  embed_759  embed_760  embed_761  \\\n",
      "0  0.126399  0.356953  0.219979  ...   1.018518  -0.063625  -0.211650   \n",
      "1  0.073784  0.191401  0.213136  ...   0.062188   0.018683  -0.260519   \n",
      "2 -0.036020 -0.241820 -0.175831  ...  -0.228277  -0.186306   0.217426   \n",
      "3 -0.085457 -0.206629 -0.151518  ...   0.292949  -0.014901   0.475006   \n",
      "4  0.179337 -0.134409  0.088882  ...  -0.025282   0.461727   0.503787   \n",
      "\n",
      "   embed_762  embed_763  embed_764  embed_765  embed_766  embed_767  output  \n",
      "0   4.267710   0.141019   0.039147  -0.135620  -0.451604   0.156114       0  \n",
      "1   2.096450  -0.106316   0.148366  -0.051111  -0.124474   0.120384       0  \n",
      "2   0.649411  -0.114102   0.242630   0.123016   0.005927  -0.344435       0  \n",
      "3   0.661420  -0.120505   0.410390   0.094925  -0.026481  -0.219293       0  \n",
      "4  -0.135410   0.209564   0.274533   0.088838  -0.067235   0.064882       0  \n",
      "\n",
      "[5 rows x 769 columns]\n",
      "Index(['embed_0', 'embed_1', 'embed_2', 'embed_3', 'embed_4', 'embed_5',\n",
      "       'embed_6', 'embed_7', 'embed_8', 'embed_9',\n",
      "       ...\n",
      "       'embed_759', 'embed_760', 'embed_761', 'embed_762', 'embed_763',\n",
      "       'embed_764', 'embed_765', 'embed_766', 'embed_767', 'output'],\n",
      "      dtype='object', length=769)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.054e+02, tolerance: 1.953e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.038e+02, tolerance: 1.962e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.016e+02, tolerance: 1.996e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.017e+02, tolerance: 1.952e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.937e+01, tolerance: 1.913e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.019e+02, tolerance: 1.955e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.045e+02, tolerance: 1.945e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.785e+01, tolerance: 1.945e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.040e+02, tolerance: 1.941e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.005e+02, tolerance: 1.957e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.911e+01, tolerance: 1.953e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.351e+01, tolerance: 1.962e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.655e+01, tolerance: 1.996e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.585e+01, tolerance: 1.952e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.065e+02, tolerance: 1.913e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.306e+01, tolerance: 1.955e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.542e+01, tolerance: 1.945e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.025e+01, tolerance: 1.945e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.791e+01, tolerance: 1.941e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.735e+01, tolerance: 1.957e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.162e+00, tolerance: 6.580e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.456e+00, tolerance: 6.540e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.529e+00, tolerance: 6.482e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.332e+00, tolerance: 6.713e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.506e+00, tolerance: 6.710e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.827e+00, tolerance: 6.402e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.196e+00, tolerance: 6.642e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.108e+00, tolerance: 6.755e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.406e+00, tolerance: 6.659e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.718e+00, tolerance: 6.607e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.451e+01, tolerance: 6.580e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.252e+01, tolerance: 6.540e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.349e+01, tolerance: 6.482e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.387e+01, tolerance: 6.713e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.598e+01, tolerance: 6.710e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.308e+01, tolerance: 6.402e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.426e+01, tolerance: 6.642e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.377e+01, tolerance: 6.755e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.050e+01, tolerance: 6.659e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.863e+00, tolerance: 6.607e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.378e-02, tolerance: 6.580e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha (regularization strength): 0.1\n",
      "R Score: 0.2175104477608861\n",
      "RMSE: 1.055485375336476\n",
      "MAE: 0.8255355608454793\n",
      "Mean of Output: 3.37\n",
      "Standard Deviation of Output: 1.2120643547270913\n",
      "Cross-Validation Scores: [0.97409814 1.07351147 1.1636563  1.1322387  1.00647335 1.18236412\n",
      " 1.026405   0.99413963 0.96097173 1.01334999]\n",
      "Cross-Validation Mean: 1.0527208450637222\n",
      "Cross-Validation Std Dev: 0.07634264809072241\n",
      "Standard Deviation of MSE: 0.16395240909413894\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Function to load and prepare the data\n",
    "def load_and_prepare_data(file_path, target_column):\n",
    "    \"\"\"\n",
    "    Load and prepare the dataset by separating features and target.\n",
    "    \n",
    "    Parameters:\n",
    "        file_path (str): Path to the dataset file.\n",
    "        target_column (str): The target column name in the dataset.\n",
    "        \n",
    "    Returns:\n",
    "        X (ndarray): Features data.\n",
    "        y (ndarray): Target data.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    X = df.drop(columns=[target_column]).values\n",
    "    y = df[target_column].values\n",
    "    return X, y\n",
    "\n",
    "# Function to normalize the data\n",
    "def normalize_data(X):\n",
    "    \"\"\"\n",
    "    Normalize features using StandardScaler.\n",
    "    \n",
    "    Parameters:\n",
    "        X (ndarray): Feature data.\n",
    "        \n",
    "    Returns:\n",
    "        X_scaled (ndarray): Scaled feature data.\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    return X_scaled, scaler\n",
    "\n",
    "# Function to perform grid search with cross-validation\n",
    "def perform_grid_search(model, X, y, param_grid, cv_folds=10):\n",
    "    \"\"\"\n",
    "    Perform GridSearchCV to find the best model and hyperparameters.\n",
    "    \n",
    "    Parameters:\n",
    "        model (estimator): The model to tune.\n",
    "        X (ndarray): Feature data.\n",
    "        y (ndarray): Target data.\n",
    "        param_grid (dict): Hyperparameter grid for tuning.\n",
    "        cv_folds (int): Number of cross-validation folds.\n",
    "        \n",
    "    Returns:\n",
    "        grid_search (GridSearchCV): The grid search object with the best model.\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=kf, scoring='neg_mean_squared_error')\n",
    "    grid_search.fit(X, y)\n",
    "    return grid_search\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate_model(model, X, y, cv_folds=10):\n",
    "    \"\"\"\n",
    "    Evaluate the model using cross-validation and calculate metrics like MSE, RMSE, R, etc.\n",
    "    \n",
    "    Parameters:\n",
    "        model (estimator): The trained model.\n",
    "        X (ndarray): Feature data.\n",
    "        y (ndarray): Target data.\n",
    "        cv_folds (int): Number of cross-validation folds.\n",
    "        \n",
    "    Returns:\n",
    "        metrics (dict): Calculated metrics including RMSE, MAE, R, and cross-validation results.\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Cross-validation scores for MSE and R\n",
    "    mse_scores = cross_val_score(model, X, y, cv=kf, scoring='neg_mean_squared_error')\n",
    "    r2_scores = cross_val_score(model, X, y, cv=kf, scoring='r2')\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse_mean = -mse_scores.mean()  # Convert negative MSE to positive\n",
    "    rmse = np.sqrt(mse_mean)       # RMSE\n",
    "    mae = mean_absolute_error(y, model.predict(X))  # MAE\n",
    "    r2_mean = r2_scores.mean()     # R\n",
    "    std_dev_mse = np.std(mse_scores)  # Standard deviation of MSE\n",
    "    \n",
    "    # Cross-validation RMSE\n",
    "    cv_scores = np.sqrt(-mse_scores)  # Convert negative MSE to positive RMSE\n",
    "    cv_mean = cv_scores.mean()        # Cross-validation mean RMSE\n",
    "    cv_std_dev = cv_scores.std()      # Cross-validation std dev RMSE\n",
    "    \n",
    "    # Additional statistics\n",
    "    output_mean = np.mean(y)         # Mean of Output\n",
    "    output_std_dev = np.std(y)       # Standard deviation of Output\n",
    "    \n",
    "    # Store metrics in a dictionary\n",
    "    metrics = {\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAE\": mae,\n",
    "        \"R\": r2_mean,\n",
    "        \"Mean of Output\": output_mean,\n",
    "        \"Standard Deviation of Output\": output_std_dev,\n",
    "        \"Cross-Validation Scores\": cv_scores,\n",
    "        \"Cross-Validation Mean\": cv_mean,\n",
    "        \"Cross-Validation Std Dev\": cv_std_dev,\n",
    "        \"Standard Deviation of MSE\": std_dev_mse\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Function to display results\n",
    "def print_results(metrics):\n",
    "    \"\"\"\n",
    "    Print the evaluation metrics.\n",
    "    \n",
    "    Parameters:\n",
    "        metrics (dict): Dictionary of calculated metrics.\n",
    "    \"\"\"\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value}\")\n",
    "\n",
    "# Main function to run the process\n",
    "def main():\n",
    "    # Load and prepare data\n",
    "    file_path = 'gpt2_test_2.csv'\n",
    "    target_column = 'output'\n",
    "    X, y = load_and_prepare_data(file_path, target_column)\n",
    "    \n",
    "    # Normalize the data\n",
    "    X_scaled, scaler = normalize_data(X)\n",
    "    \n",
    "    # Initialize the Lasso Regression model\n",
    "    model = Lasso()\n",
    "    \n",
    "    # Perform grid search with hyperparameter tuning\n",
    "    grid_params = {'alpha': [0.0001, 0.001, 0.01, 0.1, 1]}  # Regularization strength for Lasso\n",
    "    grid_search = perform_grid_search(model, X_scaled, y, grid_params)\n",
    "    \n",
    "    # Get the best model from grid search\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # Evaluate the model using cross-validation and calculate metrics\n",
    "    metrics = evaluate_model(best_model, X_scaled, y)\n",
    "    \n",
    "    # Print the results\n",
    "    print_results(metrics)\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b8f496-21fa-46d4-876b-dc7e5a8c2d56",
   "metadata": {},
   "source": [
    "# Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085b87b8-c623-45dd-9198-d1a1e4aba4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "10 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of DecisionTreeRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [        nan  0.01111834  0.02956292 -0.04410293 -0.02190407  0.0081497\n",
      "  0.02701636 -0.04442176  0.02831655         nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': None, 'max_depth': 40}\n",
      "R^2 Score: 0.24997756848855368\n",
      "RMSE: 1.0719129989041416\n",
      "MAE: 0.7497012827271129\n",
      "Mean of Output: 3.4022140221402215\n",
      "Standard Deviation of Output: 1.2377200077817099\n",
      "Cross-Validation Scores: [ 0.18342688 -0.04131913  0.2562512   0.18414116 -0.01076239]\n",
      "Cross-Validation Mean: 0.11434754471104336\n",
      "Cross-Validation Std Dev: 0.11803758848966257\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score, KFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Function to load and prepare data\n",
    "def load_and_prepare_data(file_path, target_column):\n",
    "    \"\"\"\n",
    "    Load and prepare the dataset by separating features and target.\n",
    "    \n",
    "    Parameters:\n",
    "        file_path (str): Path to the dataset file.\n",
    "        target_column (str): The target column name in the dataset.\n",
    "        \n",
    "    Returns:\n",
    "        X (ndarray): Features data.\n",
    "        y (ndarray): Target data.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "    return X, y\n",
    "\n",
    "# Function to normalize and apply PCA\n",
    "def normalize_and_reduce_dimensionality(X, variance_threshold=0.95):\n",
    "    \"\"\"\n",
    "    Normalize the features and apply PCA for dimensionality reduction.\n",
    "    \n",
    "    Parameters:\n",
    "        X (ndarray): Feature data.\n",
    "        variance_threshold (float): The proportion of variance to retain with PCA.\n",
    "        \n",
    "    Returns:\n",
    "        X_pca (ndarray): PCA-transformed feature data.\n",
    "    \"\"\"\n",
    "    # Standardize the features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Apply PCA to retain 'variance_threshold' proportion of variance\n",
    "    pca = PCA(n_components=variance_threshold)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    \n",
    "    return X_pca\n",
    "\n",
    "# Function to perform RandomizedSearchCV and return best model\n",
    "def tune_model(model, param_dist, X_train, y_train, cv_folds=5):\n",
    "    \"\"\"\n",
    "    Tune the model using RandomizedSearchCV.\n",
    "    \n",
    "    Parameters:\n",
    "        model (estimator): The model to tune.\n",
    "        param_dist (dict): Hyperparameter distribution for RandomizedSearchCV.\n",
    "        X_train (ndarray): Training feature data.\n",
    "        y_train (ndarray): Training target data.\n",
    "        cv_folds (int): Number of cross-validation folds.\n",
    "        \n",
    "    Returns:\n",
    "        best_model (estimator): The best model found by RandomizedSearchCV.\n",
    "    \"\"\"\n",
    "    random_search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=10, cv=cv_folds, random_state=42)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    return random_search.best_estimator_, random_search.best_params_\n",
    "\n",
    "# Function to evaluate the model and calculate metrics\n",
    "def evaluate_model(model, X_test, y_test, X_train, y_train, cv_folds=5):\n",
    "    \"\"\"\n",
    "    Evaluate the model using various metrics: R, RMSE, MAE, etc.\n",
    "    \n",
    "    Parameters:\n",
    "        model (estimator): The trained model.\n",
    "        X_test (ndarray): Test feature data.\n",
    "        y_test (ndarray): Test target data.\n",
    "        X_train (ndarray): Training feature data.\n",
    "        y_train (ndarray): Training target data.\n",
    "        cv_folds (int): Number of cross-validation folds.\n",
    "        \n",
    "    Returns:\n",
    "        metrics (dict): Calculated metrics.\n",
    "    \"\"\"\n",
    "    # Cross-validation scores\n",
    "    kf = KFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=kf)\n",
    "    \n",
    "    # Predictions on test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mean_value = np.mean(y_test)\n",
    "    std_dev = np.std(y_test)\n",
    "    cv_mean = cv_scores.mean()\n",
    "    cv_std_dev = cv_scores.std()\n",
    "\n",
    "    # Store the metrics in a dictionary\n",
    "    metrics = {\n",
    "        \"R^2 Score\": r2,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAE\": mae,\n",
    "        \"Mean of Output\": mean_value,\n",
    "        \"Standard Deviation of Output\": std_dev,\n",
    "        \"Cross-Validation Scores\": cv_scores,\n",
    "        \"Cross-Validation Mean\": cv_mean,\n",
    "        \"Cross-Validation Std Dev\": cv_std_dev\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Function to display results\n",
    "def print_results(metrics):\n",
    "    \"\"\"\n",
    "    Print the evaluation metrics in a readable format.\n",
    "    \n",
    "    Parameters:\n",
    "        metrics (dict): Dictionary of calculated metrics.\n",
    "    \"\"\"\n",
    "    for metric, value in metrics.items():\n",
    "        if isinstance(value, np.ndarray):\n",
    "            print(f\"{metric}: {value[:5]}... (first 5 values)\")\n",
    "        else:\n",
    "            print(f\"{metric}: {value}\")\n",
    "\n",
    "# Main function to run the process\n",
    "def main():\n",
    "    # Load and prepare data\n",
    "    file_path = 'gpt2_test_2.csv'\n",
    "    target_column = 'output'\n",
    "    X, y = load_and_prepare_data(file_path, target_column)\n",
    "    \n",
    "    # Normalize the data and apply PCA\n",
    "    X_pca = normalize_and_reduce_dimensionality(X)\n",
    "    \n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Initialize the Decision Tree Regressor\n",
    "    model = DecisionTreeRegressor()\n",
    "    \n",
    "    # Parameter tuning using RandomizedSearchCV\n",
    "    param_dist = {\n",
    "        'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "        'min_samples_split': np.arange(2, 10),\n",
    "        'min_samples_leaf': np.arange(1, 5),\n",
    "        'max_features': ['auto', 'sqrt', 'log2', None]\n",
    "    }\n",
    "    \n",
    "    best_model, best_params = tune_model(model, param_dist, X_train, y_train)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    metrics = evaluate_model(best_model, X_test, y_test, X_train, y_train)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Best Parameters: {best_params}\")\n",
    "    print_results(metrics)\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8eb688-2eaf-415d-a8d6-1c94fa818d23",
   "metadata": {},
   "source": [
    "# BayesianRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b40a3d1-9cb5-4118-ae7b-0e7c12cd9aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'lambda_2': 0.0001, 'lambda_1': 0.1, 'alpha_2': 0.1, 'alpha_1': 0.001}\n",
      "R^2 Score: 0.38821758790698147\n",
      "RMSE: 0.968101526926716\n",
      "MAE: 0.7995184038566036\n",
      "Mean of Output: 3.4022140221402215\n",
      "Standard Deviation of Output: 1.2377200077817099\n",
      "Cross-Validation Scores: [0.33302722 0.29569942 0.44906524 0.38284709 0.35967839]\n",
      "Cross-Validation Mean: 0.36406347110785237\n",
      "Cross-Validation Std Dev: 0.051447538182813425\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score, KFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "# Function to load and prepare data\n",
    "def load_and_prepare_data(file_path, target_column):\n",
    "    \"\"\"\n",
    "    Load and prepare the dataset by separating features and target.\n",
    "    \n",
    "    Parameters:\n",
    "        file_path (str): Path to the dataset file.\n",
    "        target_column (str): The target column name in the dataset.\n",
    "        \n",
    "    Returns:\n",
    "        X (ndarray): Features data.\n",
    "        y (ndarray): Target data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        X = df.drop(columns=[target_column])\n",
    "        y = df[target_column]\n",
    "        return X, y\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Function to normalize and apply PCA\n",
    "def normalize_and_reduce_dimensionality(X, variance_threshold=0.95):\n",
    "    \"\"\"\n",
    "    Normalize the features and apply PCA for dimensionality reduction.\n",
    "    \n",
    "    Parameters:\n",
    "        X (ndarray): Feature data.\n",
    "        variance_threshold (float): The proportion of variance to retain with PCA.\n",
    "        \n",
    "    Returns:\n",
    "        X_pca (ndarray): PCA-transformed feature data.\n",
    "        pca (PCA object): Fitted PCA model to access explained variance.\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    pca = PCA(n_components=variance_threshold)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    \n",
    "    # Print the explained variance ratio of the components\n",
    "    print(f\"Explained variance ratio by components: {pca.explained_variance_ratio_}\")\n",
    "    print(f\"Total variance retained: {np.sum(pca.explained_variance_ratio_)}\")\n",
    "    \n",
    "    return X_pca, pca\n",
    "\n",
    "# Function to perform RandomizedSearchCV and return best model\n",
    "def tune_model(model, param_dist, X_train, y_train, cv_folds=5):\n",
    "    \"\"\"\n",
    "    Tune the model using RandomizedSearchCV.\n",
    "    \n",
    "    Parameters:\n",
    "        model (estimator): The model to tune.\n",
    "        param_dist (dict): Hyperparameter distribution for RandomizedSearchCV.\n",
    "        X_train (ndarray): Training feature data.\n",
    "        y_train (ndarray): Training target data.\n",
    "        cv_folds (int): Number of cross-validation folds.\n",
    "        \n",
    "    Returns:\n",
    "        best_model (estimator): The best model found by RandomizedSearchCV.\n",
    "    \"\"\"\n",
    "    random_search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=20, cv=cv_folds, random_state=42)  # Increased n_iter for better search\n",
    "    random_search.fit(X_train, y_train)\n",
    "    return random_search.best_estimator_, random_search.best_params_\n",
    "\n",
    "# Function to evaluate the model and calculate metrics\n",
    "def evaluate_model(model, X_test, y_test, X_train, y_train, cv_folds=5):\n",
    "    \"\"\"\n",
    "    Evaluate the model using various metrics: R, RMSE, MAE, etc.\n",
    "    \n",
    "    Parameters:\n",
    "        model (estimator): The trained model.\n",
    "        X_test (ndarray): Test feature data.\n",
    "        y_test (ndarray): Test target data.\n",
    "        X_train (ndarray): Training feature data.\n",
    "        y_train (ndarray): Training target data.\n",
    "        cv_folds (int): Number of cross-validation folds.\n",
    "        \n",
    "    Returns:\n",
    "        metrics (dict): Calculated metrics.\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=kf)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mean_value = np.mean(y_test)\n",
    "    std_dev = np.std(y_test)\n",
    "    cv_mean = cv_scores.mean()\n",
    "    cv_std_dev = cv_scores.std()\n",
    "\n",
    "    metrics = {\n",
    "        \"R^2 Score\": r2,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAE\": mae,\n",
    "        \"Mean of Output\": mean_value,\n",
    "        \"Standard Deviation of Output\": std_dev,\n",
    "        \"Cross-Validation Scores\": cv_scores,\n",
    "        \"Cross-Validation Mean\": cv_mean,\n",
    "        \"Cross-Validation Std Dev\": cv_std_dev\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Function to print results in a readable format\n",
    "def print_results(metrics):\n",
    "    for metric, value in metrics.items():\n",
    "        if isinstance(value, np.ndarray):\n",
    "            print(f\"{metric}: {value[:5]}... (first 5 values)\")\n",
    "        else:\n",
    "            print(f\"{metric}: {value}\")\n",
    "\n",
    "# Main function to run the process\n",
    "def main():\n",
    "    file_path = 'gpt2_test_2.csv'\n",
    "    target_column = 'output'\n",
    "    \n",
    "    X, y = load_and_prepare_data(file_path, target_column)\n",
    "    if X is None or y is None:\n",
    "        return  # Exit if there was an error loading the data\n",
    "\n",
    "    X_pca, pca = normalize_and_reduce_dimensionality(X)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    model = BayesianRidge()\n",
    "    \n",
    "    param_dist = {\n",
    "        'alpha_1': np.logspace(-6, -1, 6),\n",
    "        'alpha_2': np.logspace(-6, -1, 6),\n",
    "        'lambda_1': np.logspace(-6, -1, 6),\n",
    "        'lambda_2': np.logspace(-6, -1, 6)\n",
    "    }\n",
    "    \n",
    "    best_model, best_params = tune_model(model, param_dist, X_train, y_train)\n",
    "    \n",
    "    metrics = evaluate_model(best_model, X_test, y_test, X_train, y_train)\n",
    "    \n",
    "    print(f\"Best Parameters: {best_params}\")\n",
    "    print_results(metrics)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60ff314-59cb-47cf-a018-5cedb8a897e2",
   "metadata": {},
   "source": [
    "# Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77332f4-7f89-450c-a6a6-fb1bd13d36a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_estimators': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None, 'bootstrap': True}\n",
      "R^2 Score: 0.5138861494944564\n",
      "RMSE: 0.8629614769845486\n",
      "MAE: 0.6788114273999883\n",
      "Mean of Output: 3.4022140221402215\n",
      "Standard Deviation of Output: 1.2377200077817099\n",
      "Cross-Validation Scores: [0.41714592 0.44639004 0.49721016]\n",
      "Cross-Validation Mean: 0.45358203813384307\n",
      "Cross-Validation Std Dev: 0.03307934109968348\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score, KFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Function to load and prepare data\n",
    "def load_and_prepare_data(file_path, target_column):\n",
    "    \"\"\"\n",
    "    Load and prepare the dataset by separating features and target.\n",
    "    \n",
    "    Parameters:\n",
    "        file_path (str): Path to the dataset file.\n",
    "        target_column (str): The target column name in the dataset.\n",
    "        \n",
    "    Returns:\n",
    "        X (ndarray): Features data.\n",
    "        y (ndarray): Target data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        X = df.drop(columns=[target_column])\n",
    "        y = df[target_column]\n",
    "        return X, y\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Function to standardize the data and apply PCA\n",
    "def standardize_and_reduce_dimensionality(X, variance_threshold=0.95):\n",
    "    \"\"\"\n",
    "    Standardize the features and apply PCA for dimensionality reduction.\n",
    "    \n",
    "    Parameters:\n",
    "        X (ndarray): Feature data.\n",
    "        variance_threshold (float): The proportion of variance to retain with PCA.\n",
    "        \n",
    "    Returns:\n",
    "        X_pca (ndarray): PCA-transformed feature data.\n",
    "        pca (PCA object): Fitted PCA model to access explained variance.\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    pca = PCA(n_components=variance_threshold)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    \n",
    "    print(f\"Explained variance ratio by components: {pca.explained_variance_ratio_}\")\n",
    "    print(f\"Total variance retained: {np.sum(pca.explained_variance_ratio_)}\")\n",
    "    \n",
    "    return X_pca, pca\n",
    "\n",
    "# Function to perform RandomizedSearchCV and return the best model\n",
    "def tune_model(model, param_dist, X_train, y_train, cv_folds=3):\n",
    "    \"\"\"\n",
    "    Tune the model using RandomizedSearchCV.\n",
    "    \n",
    "    Parameters:\n",
    "        model (estimator): The model to tune.\n",
    "        param_dist (dict): Hyperparameter distribution for RandomizedSearchCV.\n",
    "        X_train (ndarray): Training feature data.\n",
    "        y_train (ndarray): Training target data.\n",
    "        cv_folds (int): Number of cross-validation folds.\n",
    "        \n",
    "    Returns:\n",
    "        best_model (estimator): The best model found by RandomizedSearchCV.\n",
    "    \"\"\"\n",
    "    random_search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=5, cv=cv_folds, random_state=42, n_jobs=-1)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    return random_search.best_estimator_, random_search.best_params_\n",
    "\n",
    "# Function to evaluate the model and calculate performance metrics\n",
    "def evaluate_model(model, X_test, y_test, X_train, y_train, cv_folds=3):\n",
    "    \"\"\"\n",
    "    Evaluate the model using various metrics: R, RMSE, MAE, etc.\n",
    "    \n",
    "    Parameters:\n",
    "        model (estimator): The trained model.\n",
    "        X_test (ndarray): Test feature data.\n",
    "        y_test (ndarray): Test target data.\n",
    "        X_train (ndarray): Training feature data.\n",
    "        y_train (ndarray): Training target data.\n",
    "        cv_folds (int): Number of cross-validation folds.\n",
    "        \n",
    "    Returns:\n",
    "        metrics (dict): Calculated metrics.\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=kf)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    output_mean = np.mean(y_test)\n",
    "    output_std_dev = np.std(y_test)\n",
    "    cv_mean = cv_scores.mean()\n",
    "    cv_std_dev = cv_scores.std()\n",
    "\n",
    "    metrics = {\n",
    "        \"R^2 Score\": r2,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAE\": mae,\n",
    "        \"Mean of Output\": output_mean,\n",
    "        \"Standard Deviation of Output\": output_std_dev,\n",
    "        \"Cross-Validation Scores\": cv_scores,\n",
    "        \"Cross-Validation Mean\": cv_mean,\n",
    "        \"Cross-Validation Std Dev\": cv_std_dev\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Function to print results in a readable format\n",
    "def print_results(metrics):\n",
    "    for metric, value in metrics.items():\n",
    "        if isinstance(value, np.ndarray):\n",
    "            print(f\"{metric}: {value[:5]}... (first 5 values)\")\n",
    "        else:\n",
    "            print(f\"{metric}: {value}\")\n",
    "\n",
    "# Main function to run the entire process\n",
    "def main():\n",
    "    file_path = 'gpt2_test_2.csv'\n",
    "    target_column = 'output'\n",
    "    \n",
    "    X, y = load_and_prepare_data(file_path, target_column)\n",
    "    if X is None or y is None:\n",
    "        return  # Exit if there was an error loading the data\n",
    "\n",
    "    X_pca, pca = standardize_and_reduce_dimensionality(X)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    model = RandomForestRegressor()\n",
    "    \n",
    "    param_dist = {\n",
    "        'n_estimators': [10, 50],  # Reduced number of estimators\n",
    "        'max_depth': [None, 10],  # Reduced max_depth options\n",
    "        'min_samples_split': [2, 5],\n",
    "        'min_samples_leaf': [1, 2],\n",
    "        'bootstrap': [True]  # Keeping only one option for bootstrap\n",
    "    }\n",
    "    \n",
    "    best_model, best_params = tune_model(model, param_dist, X_train, y_train)\n",
    "    \n",
    "    metrics = evaluate_model(best_model, X_test, y_test, X_train, y_train)\n",
    "    \n",
    "    print(f\"Best Parameters: {best_params}\")\n",
    "    print_results(metrics)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d21b9f3-adeb-467d-bce8-36311b41d0f5",
   "metadata": {},
   "source": [
    "## Gausian Process regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e329bf50-7cf8-4d72-be38-7b98916e0d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:663: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:663: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:663: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:663: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Used: 3.06**2 * RBF(length_scale=8.07)\n",
      "R^2 Score: 0.20502505929057968\n",
      "RMSE: 1.7547210995549751\n",
      "MAE: 1.0603733358612224\n",
      "Mean of Output: 1.9384615384615385\n",
      "Standard Deviation of Output: 1.968028479131986\n",
      "Cross-Validation Scores: [-0.03958691  0.33522902 -0.52688427]\n",
      "Cross-Validation Mean: -0.07708072118671372\n",
      "Cross-Validation Std Dev: 0.3529534185213218\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "\n",
    "# Function to load and prepare data\n",
    "def load_and_prepare_data(file_path, target_column):\n",
    "    \"\"\"\n",
    "    Load and prepare the dataset by separating features and target.\n",
    "    \n",
    "    Parameters:\n",
    "        file_path (str): Path to the dataset file.\n",
    "        target_column (str): The target column name in the dataset.\n",
    "        \n",
    "    Returns:\n",
    "        X (ndarray): Features data.\n",
    "        y (ndarray): Target data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        X = df.drop(columns=[target_column])\n",
    "        y = df[target_column]\n",
    "        return X, y\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Function to standardize the data and apply PCA\n",
    "def standardize_and_reduce_dimensionality(X, variance_threshold=0.95):\n",
    "    \"\"\"\n",
    "    Standardize the features and apply PCA for dimensionality reduction.\n",
    "    \n",
    "    Parameters:\n",
    "        X (ndarray): Feature data.\n",
    "        variance_threshold (float): The proportion of variance to retain with PCA.\n",
    "        \n",
    "    Returns:\n",
    "        X_pca (ndarray): PCA-transformed feature data.\n",
    "        pca (PCA object): Fitted PCA model to access explained variance.\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    pca = PCA(n_components=variance_threshold)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    \n",
    "    print(f\"Explained variance ratio by components: {pca.explained_variance_ratio_}\")\n",
    "    print(f\"Total variance retained: {np.sum(pca.explained_variance_ratio_)}\")\n",
    "    \n",
    "    return X_pca, pca\n",
    "\n",
    "# Function to define and fit the Gaussian Process Regression model\n",
    "def fit_gaussian_process(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Define and fit the Gaussian Process Regression model.\n",
    "    \n",
    "    Parameters:\n",
    "        X_train (ndarray): Training feature data.\n",
    "        y_train (ndarray): Training target data.\n",
    "        \n",
    "    Returns:\n",
    "        model (GaussianProcessRegressor): Trained Gaussian Process model.\n",
    "    \"\"\"\n",
    "    kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2))  # Constant * Radial Basis Function\n",
    "    model = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "# Function to perform cross-validation\n",
    "def cross_validate_model(model, X_train, y_train, cv_folds=3):\n",
    "    \"\"\"\n",
    "    Perform cross-validation on the trained model.\n",
    "    \n",
    "    Parameters:\n",
    "        model (estimator): Trained model.\n",
    "        X_train (ndarray): Training feature data.\n",
    "        y_train (ndarray): Training target data.\n",
    "        cv_folds (int): Number of cross-validation folds.\n",
    "        \n",
    "    Returns:\n",
    "        cv_scores (ndarray): Cross-validation scores.\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=kf, scoring='r2')\n",
    "    return cv_scores\n",
    "\n",
    "# Function to evaluate the model and calculate performance metrics\n",
    "def evaluate_model(model, X_test, y_test, X_train, y_train, cv_folds=3):\n",
    "    \"\"\"\n",
    "    Evaluate the model using various metrics: R, RMSE, MAE, etc.\n",
    "    \n",
    "    Parameters:\n",
    "        model (estimator): The trained model.\n",
    "        X_test (ndarray): Test feature data.\n",
    "        y_test (ndarray): Test target data.\n",
    "        X_train (ndarray): Training feature data.\n",
    "        y_train (ndarray): Training target data.\n",
    "        cv_folds (int): Number of cross-validation folds.\n",
    "        \n",
    "    Returns:\n",
    "        metrics (dict): Calculated metrics.\n",
    "    \"\"\"\n",
    "    cv_scores = cross_validate_model(model, X_train, y_train, cv_folds)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    output_mean = np.mean(y_test)\n",
    "    output_std_dev = np.std(y_test)\n",
    "    cv_mean = cv_scores.mean()\n",
    "    cv_std_dev = cv_scores.std()\n",
    "\n",
    "    metrics = {\n",
    "        \"R^2 Score\": r2,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAE\": mae,\n",
    "        \"Mean of Output\": output_mean,\n",
    "        \"Standard Deviation of Output\": output_std_dev,\n",
    "        \"Cross-Validation Scores\": cv_scores,\n",
    "        \"Cross-Validation Mean\": cv_mean,\n",
    "        \"Cross-Validation Std Dev\": cv_std_dev\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Function to print results in a readable format\n",
    "def print_results(metrics):\n",
    "    for metric, value in metrics.items():\n",
    "        if isinstance(value, np.ndarray):\n",
    "            print(f\"{metric}: {value[:5]}... (first 5 values)\")\n",
    "        else:\n",
    "            print(f\"{metric}: {value}\")\n",
    "\n",
    "# Main function to run the entire process\n",
    "def main():\n",
    "    file_path = 'gpt2_test_2.csv'\n",
    "    target_column = 'output'\n",
    "    \n",
    "    X, y = load_and_prepare_data(file_path, target_column)\n",
    "    if X is None or y is None:\n",
    "        return  # Exit if there was an error loading the data\n",
    "\n",
    "    X_pca, pca = standardize_and_reduce_dimensionality(X)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    model = fit_gaussian_process(X_train, y_train)\n",
    "    \n",
    "    metrics = evaluate_model(model, X_test, y_test, X_train, y_train)\n",
    "    \n",
    "    print(f\"Kernel Used: {model.kernel_}\")\n",
    "    print_results(metrics)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b306693-c5e1-46fc-a72d-3f172d2b6165",
   "metadata": {},
   "source": [
    "## Support vector regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea070463-2edb-4208-9e2e-3e8b346eaad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 10, 'epsilon': 0.5, 'kernel': 'rbf'}\n",
      "R^2 Score: 0.4499167606357296\n",
      "RMSE: 1.4596394244666246\n",
      "MAE: 1.1750491433636607\n",
      "Mean of Output: 1.9384615384615385\n",
      "Standard Deviation of Output: 1.968028479131986\n",
      "Cross-Validation Scores: [0.34468544 0.28100373 0.26212836]\n",
      "Cross-Validation Mean: 0.2959391768193105\n",
      "Cross-Validation Std Dev: 0.03531966894150644\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('gpt2_test_2.csv')\n",
    "\n",
    "# Features and target\n",
    "X = df.drop(columns=['output'])\n",
    "y = df['output']\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply PCA for dimensionality reduction\n",
    "pca = PCA(n_components=0.95)  # Retain 95% of variance\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define SVR model\n",
    "svr = SVR()\n",
    "\n",
    "# Parameter tuning using GridSearchCV\n",
    "param_grid = {\n",
    "    'kernel': ['linear', 'rbf'],  # Linear and RBF kernels\n",
    "    'C': [0.1, 1, 10],  # Regularization parameter\n",
    "    'epsilon': [0.1, 0.2, 0.5]  # Epsilon in the epsilon-tube\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(svr, param_grid, cv=3, scoring='r2', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Cross-validation\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(grid_search.best_estimator_, X_train, y_train, cv=kf, scoring='r2')\n",
    "\n",
    "# Predictions\n",
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "# Performance metrics\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "output_mean = np.mean(y_test)\n",
    "output_std_dev = np.std(y_test)\n",
    "cv_mean = cv_scores.mean()\n",
    "cv_std_dev = cv_scores.std()\n",
    "\n",
    "# Print results\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"R^2 Score: {r2}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"Mean of Output: {output_mean}\")\n",
    "print(f\"Standard Deviation of Output: {output_std_dev}\")\n",
    "print(f\"Cross-Validation Scores: {cv_scores}\")\n",
    "print(f\"Cross-Validation Mean: {cv_mean}\")\n",
    "print(f\"Cross-Validation Std Dev: {cv_std_dev}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c00549c-6b0b-45f9-afd5-3116539784b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
