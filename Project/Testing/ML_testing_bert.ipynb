{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09f44bcb-8fec-44af-8186-8df211ce140c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# K-Nearest Neighbors (KNN) Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50800594-fffd-457e-80db-9989728cfdb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 80 candidates, totalling 800 fits\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=1, weights=uniform; total time=   0.5s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=3, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, n_neighbors=11, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=distance; total time=   0.6s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform; total time=   0.5s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=2, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=11, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=distance; total time=   0.5s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance; total time=   1.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance; total time=   0.8s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=uniform; total time=   0.8s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=distance; total time=   0.5s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=uniform; total time=   0.7s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=uniform; total time=   0.5s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=distance; total time=   0.6s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=distance; total time=   0.5s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=distance; total time=   0.5s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=distance; total time=   0.6s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=distance; total time=   0.5s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=distance; total time=   0.5s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=uniform; total time=   0.5s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=uniform; total time=   0.5s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=distance; total time=   0.5s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=uniform; total time=   0.5s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=distance; total time=   0.5s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=distance; total time=   0.6s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=1, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=1, weights=uniform; total time=   0.7s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=1, weights=uniform; total time=   0.5s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=1, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=1, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=1, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=1, weights=distance; total time=   0.6s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=2, weights=uniform; total time=   0.6s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=2, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=2, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=2, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=2, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=2, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=2, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=2, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=2, weights=uniform; total time=   0.6s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=2, weights=uniform; total time=   0.5s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=2, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=2, weights=distance; total time=   0.6s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=2, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=2, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=2, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=2, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=2, weights=distance; total time=   0.5s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=2, weights=distance; total time=   0.5s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=2, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=11, p=2, weights=distance; total time=   0.4s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=11, p=2, weights=distance; total time=   0.0s\n",
      "Best Parameters: {'algorithm': 'auto', 'n_neighbors': 7, 'p': 1, 'weights': 'distance'}\n",
      "Root Mean Squared Error (RMSE) on Test Set: 0.8545812213334695\n",
      "R² value: 0.4373235681018238\n",
      "Standard Deviation of Predictions: 0.9156634554963033\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Function to load the dataset\n",
    "def load_data(file_path, target_column):\n",
    "    \"\"\"\n",
    "    Load dataset and separate features and target.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): Path to the dataset.\n",
    "        target_column (str): The column to be used as the target.\n",
    "    \n",
    "    Returns:\n",
    "        X (DataFrame): Features.\n",
    "        y (Series): Target.\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(file_path)\n",
    "    X = data.drop(columns=[target_column])\n",
    "    y = data[target_column]\n",
    "    return X, y\n",
    "\n",
    "# Function to set up and perform grid search for KNN\n",
    "def perform_grid_search(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Set up the GridSearchCV for KNN and find the best parameters.\n",
    "    \n",
    "    Parameters:\n",
    "        X_train (DataFrame): Training features.\n",
    "        y_train (Series): Training target.\n",
    "        \n",
    "    Returns:\n",
    "        best_knn (KNeighborsRegressor): Best KNN model from the grid search.\n",
    "    \"\"\"\n",
    "    knn = KNeighborsRegressor()\n",
    "    param_grid = {\n",
    "        'n_neighbors': [3, 5, 7, 9, 11],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "        'p': [1, 2]\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(estimator=knn, param_grid=param_grid, cv=10, scoring='neg_mean_squared_error', verbose=2)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return grid_search.best_estimator_, grid_search.best_params_\n",
    "\n",
    "# Function to evaluate the model performance\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluate the model using R², RMSE, and standard deviation.\n",
    "    \n",
    "    Parameters:\n",
    "        model (KNeighborsRegressor): Trained model.\n",
    "        X_test (DataFrame): Test features.\n",
    "        y_test (Series): Test target.\n",
    "    \n",
    "    Returns:\n",
    "        metrics (dict): Dictionary with R², RMSE, and standard deviation.\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Performance metrics\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    std_dev = np.std(y_pred)\n",
    "    \n",
    "    metrics = {\n",
    "        \"R²\": r2,\n",
    "        \"RMSE\": rmse,\n",
    "        \"Standard Deviation\": std_dev\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "# Function to print results\n",
    "def print_results(metrics):\n",
    "    \"\"\"\n",
    "    Print the evaluation metrics.\n",
    "    \n",
    "    Parameters:\n",
    "        metrics (dict): The evaluation metrics to print.\n",
    "    \"\"\"\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value}\")\n",
    "\n",
    "# Main function to execute the full process\n",
    "def main():\n",
    "    # Load the data\n",
    "    X, y = load_data('bert_test_2.csv', 'output')\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Perform grid search\n",
    "    best_knn, best_params = perform_grid_search(X_train, y_train)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    metrics = evaluate_model(best_knn, X_test, y_test)\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"Best Parameters: {best_params}\")\n",
    "    print_results(metrics)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd63671e-29ae-4643-a9b8-8eb9478a406b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfa1720-a86a-412e-af16-8baa8bf4fb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=2; total time=  47.0s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=2; total time=  51.9s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=2; total time=  49.3s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=2; total time=  51.8s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=2; total time=  42.2s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=2; total time=  41.1s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=2; total time=  41.7s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=2; total time=  46.5s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=2; total time=  43.7s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=2; total time=  45.3s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=3; total time=   0.0s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=3; total time=   0.0s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=3; total time=   0.0s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=3; total time=   0.0s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=3; total time=   0.0s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=3; total time=   0.0s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=3; total time=   0.0s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=3; total time=   0.0s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=3; total time=   0.0s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=3; total time=   0.0s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=4; total time=   0.5s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=4; total time=   0.6s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=4; total time=   0.5s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=4; total time=   0.6s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=4; total time=   0.6s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=4; total time=   0.5s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=4; total time=   0.6s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=4; total time=   0.5s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=4; total time=   0.5s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=4; total time=   0.6s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=2; total time=  54.9s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=2; total time=  51.7s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=2; total time= 1.0min\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=2; total time=  55.2s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=2; total time= 1.0min\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=2; total time=  47.4s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=2; total time=  54.5s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=2; total time=  54.8s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=2; total time=  47.4s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=2; total time=  54.5s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=3; total time=   0.0s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=3; total time=   0.0s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=3; total time=   0.0s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=3; total time=   0.0s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=3; total time=   0.0s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=3; total time=   0.0s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=3; total time=   0.0s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=3; total time=   0.0s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=3; total time=   0.0s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=3; total time=   0.0s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=4; total time=   0.5s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=4; total time=   0.5s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=4; total time=   0.7s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=4; total time=   0.5s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=4; total time=   0.4s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=4; total time=   0.5s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=4; total time=   0.4s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=4; total time=   0.5s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=4; total time=   0.5s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=4; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "40 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1101, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "         ^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 553. GiB for an array with shape (975, 76088705) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1101, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "         ^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 553. GiB for an array with shape (976, 76088705) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1101, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "         ^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 104. TiB for an array with shape (975, 14685120065) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1101, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "         ^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 104. TiB for an array with shape (976, 14685120065) and data type float64\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [-2.94074505e+21             nan             nan -2.77587079e+21\n",
      "             nan             nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'linear__fit_intercept': False, 'poly__degree': 2}\n",
      "Root Mean Squared Error (RMSE) on Test Set: 2600922748.5203533\n",
      "R² value on Test Set: -4.415806999659239e+18\n",
      "Standard Deviation of Predictions: 2599536849.8859825\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, KFold\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load and split the dataset\n",
    "def load_and_split_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    X = data.drop(columns=['output'])\n",
    "    y = data['output']\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and configure the pipeline\n",
    "def create_pipeline():\n",
    "    return Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('poly', PolynomialFeatures()),\n",
    "        ('linear', LinearRegression())\n",
    "    ])\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "def grid_search_cv(pipeline, X_train, y_train):\n",
    "    param_grid = {'poly__degree': [2, 3, 4], 'linear__fit_intercept': [True, False]}\n",
    "    cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=cv, scoring='neg_mean_squared_error', verbose=2)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return grid_search\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "def evaluate_model(best_model, X_test, y_test):\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    std_dev = np.std(y_pred)\n",
    "    return rmse, r2, std_dev\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # Load and split data\n",
    "    X_train, X_test, y_train, y_test = load_and_split_data('bert_test_2.csv')\n",
    "\n",
    "    # Create pipeline and perform grid search\n",
    "    pipeline = create_pipeline()\n",
    "    grid_search = grid_search_cv(pipeline, X_train, y_train)\n",
    "\n",
    "    # Get the best model and evaluate it\n",
    "    best_model = grid_search.best_estimator_\n",
    "    rmse, r2, std_dev = evaluate_model(best_model, X_test, y_test)\n",
    "\n",
    "    # Print results\n",
    "    print(f'Best Parameters: {grid_search.best_params_}')\n",
    "    print(f'Root Mean Squared Error (RMSE) on Test Set: {rmse}')\n",
    "    print(f'R² value on Test Set: {r2}')\n",
    "    print(f'Standard Deviation of Predictions: {std_dev}')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea1506a-5107-479b-87b0-a665ac32caf8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a816964-4517-49e6-8569-a44ab9303d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "R^2 Score:  0.4363600810609023\n",
      "RMSE:  0.929230130100368\n",
      "Cross-validated RMSE:  0.9688596222791311\n",
      "Standard Deviation of Predictions: 1.1057434316551316\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Function to load the dataset\n",
    "def load_data(file_path, target_column):\n",
    "    \"\"\"\n",
    "    Load dataset and separate features and target.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): Path to the dataset.\n",
    "        target_column (str): The column to be used as the target.\n",
    "    \n",
    "    Returns:\n",
    "        X (DataFrame): Features.\n",
    "        y (Series): Target.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "    return X, y\n",
    "\n",
    "# Function to standardize features\n",
    "def standardize_features(X):\n",
    "    \"\"\"\n",
    "    Standardize features to have zero mean and unit variance.\n",
    "\n",
    "    Parameters:\n",
    "        X (DataFrame): Features to be standardized.\n",
    "    \n",
    "    Returns:\n",
    "        X_scaled (ndarray): Scaled features.\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    return X_scaled\n",
    "\n",
    "# Function to perform Grid Search for hyperparameter tuning\n",
    "def perform_grid_search(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Perform Grid Search for hyperparameter tuning of Logistic Regression model.\n",
    "\n",
    "    Parameters:\n",
    "        X_train (DataFrame): Training features.\n",
    "        y_train (Series): Training target.\n",
    "    \n",
    "    Returns:\n",
    "        best_model (LogisticRegression): Best model from the grid search.\n",
    "        best_params (dict): Best parameters found by Grid Search.\n",
    "    \"\"\"\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "    param_grid = {\n",
    "        'C': [0.01, 0.1, 1, 10, 100],\n",
    "        'solver': ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "        'penalty': ['l2'],\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=10, scoring='neg_mean_squared_error')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "    \n",
    "    return best_model, best_params\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluate the model using R², RMSE, and standard deviation.\n",
    "\n",
    "    Parameters:\n",
    "        model (LogisticRegression): Trained model.\n",
    "        X_test (DataFrame): Test features.\n",
    "        y_test (Series): Test target.\n",
    "    \n",
    "    Returns:\n",
    "        metrics (dict): Dictionary containing R², RMSE, and standard deviation.\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate R² score\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "    # Calculate standard deviation of the predictions\n",
    "    std_dev = np.std(y_pred)\n",
    "\n",
    "    metrics = {\n",
    "        \"R²\": r2,\n",
    "        \"RMSE\": rmse,\n",
    "        \"Standard Deviation\": std_dev\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Function to perform cross-validation and calculate RMSE\n",
    "def cross_validate_model(model, X_train, y_train):\n",
    "    \"\"\"\n",
    "    Perform cross-validation and calculate the RMSE.\n",
    "\n",
    "    Parameters:\n",
    "        model (LogisticRegression): Trained model.\n",
    "        X_train (DataFrame): Training features.\n",
    "        y_train (Series): Training target.\n",
    "    \n",
    "    Returns:\n",
    "        cv_rmse (float): Cross-validated RMSE.\n",
    "    \"\"\"\n",
    "    cross_val_scores = cross_val_score(model, X_train, y_train, cv=10, scoring='neg_mean_squared_error')\n",
    "    cv_rmse = np.mean(np.sqrt(-cross_val_scores))\n",
    "    return cv_rmse\n",
    "\n",
    "# Function to print evaluation results\n",
    "def print_results(best_params, metrics, cv_rmse):\n",
    "    \"\"\"\n",
    "    Print the evaluation results.\n",
    "\n",
    "    Parameters:\n",
    "        best_params (dict): Best parameters found by Grid Search.\n",
    "        metrics (dict): Dictionary containing evaluation metrics.\n",
    "        cv_rmse (float): Cross-validated RMSE.\n",
    "    \"\"\"\n",
    "    print(f\"Best Parameters: {best_params}\")\n",
    "    print(f\"R² Score: {metrics['R²']}\")\n",
    "    print(f\"RMSE: {metrics['RMSE']}\")\n",
    "    print(f\"Standard Deviation of Predictions: {metrics['Standard Deviation']}\")\n",
    "    print(f\"Cross-validated RMSE: {cv_rmse}\")\n",
    "\n",
    "# Main function to run the workflow\n",
    "def main():\n",
    "    # Load data\n",
    "    X, y = load_data('bert_test_2.csv', 'output')\n",
    "\n",
    "    # Standardize features\n",
    "    X_scaled = standardize_features(X)\n",
    "\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Perform Grid Search\n",
    "    best_model, best_params = perform_grid_search(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    metrics = evaluate_model(best_model, X_test, y_test)\n",
    "\n",
    "    # Perform cross-validation\n",
    "    cv_rmse = cross_validate_model(best_model, X_train, y_train)\n",
    "\n",
    "    # Print results\n",
    "    print_results(best_params, metrics, cv_rmse)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5e07bd-20d1-45c6-abd5-17aca527dd08",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cf15be-d4a7-47d5-b2e8-d2cf1f91ec4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    embed_0   embed_1   embed_2   embed_3   embed_4   embed_5   embed_6  \\\n",
      "0  0.445589  0.415333  0.118074  0.202017  0.293542 -0.090634 -0.329375   \n",
      "1  0.076474 -0.200395  0.185220  0.198175 -0.013897 -0.115137 -0.008887   \n",
      "2  0.018093 -0.260901  0.498325  0.019231 -0.152991 -0.289522 -0.052139   \n",
      "3 -0.036732 -0.256312  0.839563  0.082782 -0.107343 -0.260510  0.153343   \n",
      "4  0.301357  0.222360  0.552620 -0.363340 -0.269042 -0.081171  0.439332   \n",
      "\n",
      "    embed_7   embed_8   embed_9  ...  embed_759  embed_760  embed_761  \\\n",
      "0  0.540401  0.128381 -0.090013  ...  -0.294877   0.174255  -0.349183   \n",
      "1  0.263286 -0.105154 -0.296139  ...  -0.068586  -0.040534  -0.186894   \n",
      "2 -0.038137 -0.218562  0.039249  ...   0.276947  -0.006225  -0.283879   \n",
      "3 -0.442882 -0.200667  0.136391  ...   0.111054  -0.022571  -0.307118   \n",
      "4 -0.398349  0.077302  0.175215  ...   0.302719  -0.347563  -0.256054   \n",
      "\n",
      "   embed_762  embed_763  embed_764  embed_765  embed_766  embed_767  output  \n",
      "0  -0.066742   0.027607  -0.062663  -0.183947  -0.051938  -0.024111       0  \n",
      "1   0.143764  -0.386833   0.134549   0.347578  -0.102337  -0.111851       0  \n",
      "2   0.064606  -0.060236   0.105780  -0.426448  -0.014243   0.599546       0  \n",
      "3   0.220331   0.005625  -0.405961  -0.233538  -0.042100   0.661217       0  \n",
      "4   0.216916  -0.286896  -0.366760  -0.416491   0.393924   0.472254       0  \n",
      "\n",
      "[5 rows x 769 columns]\n",
      "Index(['embed_0', 'embed_1', 'embed_2', 'embed_3', 'embed_4', 'embed_5',\n",
      "       'embed_6', 'embed_7', 'embed_8', 'embed_9',\n",
      "       ...\n",
      "       'embed_759', 'embed_760', 'embed_761', 'embed_762', 'embed_763',\n",
      "       'embed_764', 'embed_765', 'embed_766', 'embed_767', 'output'],\n",
      "      dtype='object', length=769)\n",
      "MSE: 1.854524355069558e+21\n",
      "RMSE: 43064188777.56271\n",
      "R²: -1.3594827169905954e+21\n",
      "Standard Deviation of MSE: 2.972848094449883e+21\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load dataset\n",
    "def load_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df\n",
    "\n",
    "# Separate features and target\n",
    "def separate_features_target(df):\n",
    "    X = df.drop(columns=['output']).values\n",
    "    y = df['output'].values\n",
    "    return X, y\n",
    "\n",
    "# Normalize data\n",
    "def normalize_data(X):\n",
    "    scaler = StandardScaler()\n",
    "    return scaler.fit_transform(X)\n",
    "\n",
    "# Perform GridSearchCV for model fitting\n",
    "def perform_grid_search(model, X, y, cv):\n",
    "    grid_search = GridSearchCV(model, {}, cv=cv, scoring='neg_mean_squared_error')\n",
    "    grid_search.fit(X, y)\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "# Perform cross-validation and calculate metrics\n",
    "def evaluate_model(model, X, y, cv):\n",
    "    mse_scores = cross_val_score(model, X, y, cv=cv, scoring='neg_mean_squared_error')\n",
    "    r2_scores = cross_val_score(model, X, y, cv=cv, scoring='r2')\n",
    "    mse = -mse_scores.mean()  # Convert from negative MSE\n",
    "    rmse = np.sqrt(mse)       # RMSE\n",
    "    r2 = r2_scores.mean()     # R²\n",
    "    std_dev = np.std(mse_scores)  # Standard deviation of MSE\n",
    "    return mse, rmse, r2, std_dev\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # Load and prepare data\n",
    "    df = load_data('bert_test_2.csv')\n",
    "    X, y = separate_features_target(df)\n",
    "    \n",
    "    # Normalize data\n",
    "    X_scaled = normalize_data(X)\n",
    "\n",
    "    # Initialize model and KFold\n",
    "    model = LinearRegression()\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "    # Perform Grid Search for full dataset\n",
    "    best_model = perform_grid_search(model, X_scaled, y, kf)\n",
    "\n",
    "    # Sample 500 rows and reprocess\n",
    "    df_sample = df.sample(n=500, random_state=42)\n",
    "    X_sample, y_sample = separate_features_target(df_sample)\n",
    "    X_sample_scaled = normalize_data(X_sample)\n",
    "\n",
    "    # Perform Grid Search for the sample dataset\n",
    "    best_model_sample = perform_grid_search(model, X_sample_scaled, y_sample, kf)\n",
    "\n",
    "    # Evaluate the model on the sample data\n",
    "    mse_sample, rmse_sample, r2_sample, std_dev_sample = evaluate_model(best_model_sample, X_sample_scaled, y_sample, kf)\n",
    "\n",
    "    # Output the results\n",
    "    print(f\"MSE: {mse_sample}\")\n",
    "    print(f\"RMSE: {rmse_sample}\")\n",
    "    print(f\"R²: {r2_sample}\")\n",
    "    print(f\"Standard Deviation of MSE: {std_dev_sample}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c092cdfc-80b6-41b5-8fed-be61b036dcaa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb002460-184d-413d-a240-612d79d7e5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    embed_0   embed_1   embed_2   embed_3   embed_4   embed_5   embed_6  \\\n",
      "0  0.445589  0.415333  0.118074  0.202017  0.293542 -0.090634 -0.329375   \n",
      "1  0.076474 -0.200395  0.185220  0.198175 -0.013897 -0.115137 -0.008887   \n",
      "2  0.018093 -0.260901  0.498325  0.019231 -0.152991 -0.289522 -0.052139   \n",
      "3 -0.036732 -0.256312  0.839563  0.082782 -0.107343 -0.260510  0.153343   \n",
      "4  0.301357  0.222360  0.552620 -0.363340 -0.269042 -0.081171  0.439332   \n",
      "\n",
      "    embed_7   embed_8   embed_9  ...  embed_759  embed_760  embed_761  \\\n",
      "0  0.540401  0.128381 -0.090013  ...  -0.294877   0.174255  -0.349183   \n",
      "1  0.263286 -0.105154 -0.296139  ...  -0.068586  -0.040534  -0.186894   \n",
      "2 -0.038137 -0.218562  0.039249  ...   0.276947  -0.006225  -0.283879   \n",
      "3 -0.442882 -0.200667  0.136391  ...   0.111054  -0.022571  -0.307118   \n",
      "4 -0.398349  0.077302  0.175215  ...   0.302719  -0.347563  -0.256054   \n",
      "\n",
      "   embed_762  embed_763  embed_764  embed_765  embed_766  embed_767  output  \n",
      "0  -0.066742   0.027607  -0.062663  -0.183947  -0.051938  -0.024111       0  \n",
      "1   0.143764  -0.386833   0.134549   0.347578  -0.102337  -0.111851       0  \n",
      "2   0.064606  -0.060236   0.105780  -0.426448  -0.014243   0.599546       0  \n",
      "3   0.220331   0.005625  -0.405961  -0.233538  -0.042100   0.661217       0  \n",
      "4   0.216916  -0.286896  -0.366760  -0.416491   0.393924   0.472254       0  \n",
      "\n",
      "[5 rows x 769 columns]\n",
      "Index(['embed_0', 'embed_1', 'embed_2', 'embed_3', 'embed_4', 'embed_5',\n",
      "       'embed_6', 'embed_7', 'embed_8', 'embed_9',\n",
      "       ...\n",
      "       'embed_759', 'embed_760', 'embed_761', 'embed_762', 'embed_763',\n",
      "       'embed_764', 'embed_765', 'embed_766', 'embed_767', 'output'],\n",
      "      dtype='object', length=769)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.570e+01, tolerance: 1.953e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.809e+01, tolerance: 1.962e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.581e+01, tolerance: 1.996e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.230e+01, tolerance: 1.952e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.374e+01, tolerance: 1.913e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.984e+01, tolerance: 1.955e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.253e+01, tolerance: 1.945e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.376e+01, tolerance: 1.945e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.565e+01, tolerance: 1.941e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.529e+01, tolerance: 1.957e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.300e+01, tolerance: 1.953e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.876e+01, tolerance: 1.962e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.881e+01, tolerance: 1.996e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.063e+01, tolerance: 1.952e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.118e+01, tolerance: 1.913e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.262e+01, tolerance: 1.955e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.781e+01, tolerance: 1.945e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.246e+01, tolerance: 1.945e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.985e+01, tolerance: 1.941e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.409e+01, tolerance: 1.957e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.681e+00, tolerance: 6.580e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.450e+00, tolerance: 6.540e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.621e+00, tolerance: 6.482e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.044e+00, tolerance: 6.713e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.371e+00, tolerance: 6.710e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.472e+00, tolerance: 6.402e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.123e+00, tolerance: 6.642e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.065e+00, tolerance: 6.755e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.055e+00, tolerance: 6.659e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.899e+00, tolerance: 6.607e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.245e+01, tolerance: 6.580e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.077e+01, tolerance: 6.540e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.155e+01, tolerance: 6.482e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.075e+01, tolerance: 6.713e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.228e+01, tolerance: 6.710e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.467e+01, tolerance: 6.402e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.078e+01, tolerance: 6.642e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.088e+01, tolerance: 6.755e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.001e+00, tolerance: 6.659e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.356e+01, tolerance: 6.607e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.187e-01, tolerance: 6.540e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.793e-02, tolerance: 6.402e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.277e-02, tolerance: 6.755e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.334e-01, tolerance: 6.607e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.022e-01, tolerance: 7.346e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.187e-01, tolerance: 6.540e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.793e-02, tolerance: 6.402e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.277e-02, tolerance: 6.755e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.334e-01, tolerance: 6.607e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.187e-01, tolerance: 6.540e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.793e-02, tolerance: 6.402e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.277e-02, tolerance: 6.755e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha (regularization strength): 0.01\n",
      "MSE: 0.973829476591962\n",
      "RMSE: 0.9868279873371864\n",
      "R²: 0.3103738152553472\n",
      "Standard Deviation of MSE: 0.22928273282252234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.334e-01, tolerance: 6.607e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Function to load the dataset\n",
    "def load_data(file_path, target_column):\n",
    "    \"\"\"\n",
    "    Load dataset and separate features and target.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): Path to the dataset.\n",
    "        target_column (str): The column to be used as the target.\n",
    "    \n",
    "    Returns:\n",
    "        X (ndarray): Features.\n",
    "        y (ndarray): Target.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    X = df.drop(columns=[target_column]).values\n",
    "    y = df[target_column].values\n",
    "    return X, y\n",
    "\n",
    "# Function to standardize features\n",
    "def standardize_features(X):\n",
    "    \"\"\"\n",
    "    Standardize features to have zero mean and unit variance.\n",
    "\n",
    "    Parameters:\n",
    "        X (ndarray): Features to be standardized.\n",
    "    \n",
    "    Returns:\n",
    "        X_scaled (ndarray): Scaled features.\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    return X_scaled\n",
    "\n",
    "# Function to perform Grid Search for hyperparameter tuning\n",
    "def perform_grid_search(model, X, y, param_grid, cv_splits=10):\n",
    "    \"\"\"\n",
    "    Perform Grid Search for hyperparameter tuning of the model.\n",
    "\n",
    "    Parameters:\n",
    "        model: Model to be tuned.\n",
    "        X (ndarray): Features.\n",
    "        y (ndarray): Target.\n",
    "        param_grid (dict): Grid of parameters for tuning.\n",
    "        cv_splits (int): Number of splits for cross-validation.\n",
    "    \n",
    "    Returns:\n",
    "        best_model (object): Best model from the grid search.\n",
    "        best_params (dict): Best parameters found by Grid Search.\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=cv_splits, shuffle=True, random_state=42)\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=kf, scoring='neg_mean_squared_error')\n",
    "    grid_search.fit(X, y)\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "    \n",
    "    return best_model, best_params\n",
    "\n",
    "# Function to perform cross-validation and calculate performance metrics\n",
    "def evaluate_model(model, X, y, cv_splits=10):\n",
    "    \"\"\"\n",
    "    Perform cross-validation and calculate MSE, RMSE, R², and Standard Deviation.\n",
    "\n",
    "    Parameters:\n",
    "        model: Trained model.\n",
    "        X (ndarray): Features.\n",
    "        y (ndarray): Target.\n",
    "        cv_splits (int): Number of splits for cross-validation.\n",
    "    \n",
    "    Returns:\n",
    "        metrics (dict): Dictionary of performance metrics (MSE, RMSE, R², Standard Deviation).\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=cv_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    mse_scores = cross_val_score(model, X, y, cv=kf, scoring='neg_mean_squared_error')\n",
    "    r2_scores = cross_val_score(model, X, y, cv=kf, scoring='r2')\n",
    "    \n",
    "    mse = -mse_scores.mean()  # MSE (convert from negative MSE)\n",
    "    rmse = np.sqrt(mse)       # RMSE\n",
    "    r2 = r2_scores.mean()     # R²\n",
    "    std_dev = np.std(mse_scores)  # Standard deviation of MSE\n",
    "\n",
    "    metrics = {\n",
    "        \"MSE\": mse,\n",
    "        \"RMSE\": rmse,\n",
    "        \"R²\": r2,\n",
    "        \"Standard Deviation of MSE\": std_dev\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Function to print evaluation results\n",
    "def print_results(best_params, metrics):\n",
    "    \"\"\"\n",
    "    Print the evaluation results.\n",
    "\n",
    "    Parameters:\n",
    "        best_params (dict): Best parameters found by Grid Search.\n",
    "        metrics (dict): Dictionary containing evaluation metrics.\n",
    "    \"\"\"\n",
    "    print(f\"Best alpha (regularization strength): {best_params['alpha']}\")\n",
    "    print(f\"MSE: {metrics['MSE']}\")\n",
    "    print(f\"RMSE: {metrics['RMSE']}\")\n",
    "    print(f\"R²: {metrics['R²']}\")\n",
    "    print(f\"Standard Deviation of MSE: {metrics['Standard Deviation of MSE']}\")\n",
    "\n",
    "# Main function to run the workflow\n",
    "def main():\n",
    "    # Load data\n",
    "    X, y = load_data('bert_test_2.csv', 'output')\n",
    "\n",
    "    # Standardize features\n",
    "    X_scaled = standardize_features(X)\n",
    "\n",
    "    # Initialize Lasso Regression model\n",
    "    model = Lasso()\n",
    "\n",
    "    # Perform Grid Search for hyperparameter tuning\n",
    "    grid_params = {'alpha': [0.0001, 0.001, 0.01, 0.1, 1]}\n",
    "    best_model, best_params = perform_grid_search(model, X_scaled, y, grid_params)\n",
    "\n",
    "    # Perform evaluation using cross-validation\n",
    "    metrics = evaluate_model(best_model, X_scaled, y)\n",
    "\n",
    "    # Print the results\n",
    "    print_results(best_params, metrics)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b8f496-21fa-46d4-876b-dc7e5a8c2d56",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085b87b8-c623-45dd-9198-d1a1e4aba4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "10 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of DecisionTreeRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [        nan  0.04918136  0.13778886 -0.00023911 -0.00386285  0.0803768\n",
      "  0.11389676  0.00599924  0.04292613         nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': None, 'max_depth': 40}\n",
      "R^2 Score: 0.15949204352875646\n",
      "RMSE: 1.1347320613997438\n",
      "MAE: 0.7592250922509225\n",
      "Mean of Output: 3.4022140221402215\n",
      "Standard Deviation of Output: 1.2377200077817099\n",
      "Cross-Validation Scores: [ 0.22924306  0.16139765 -0.03558627 -0.03124128  0.10248387]\n",
      "Cross-Validation Mean: 0.08525940514233835\n",
      "Cross-Validation Std Dev: 0.10488192806411245\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score, KFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Load and prepare data\n",
    "def load_and_prepare_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    X = df.drop(columns=['output'])\n",
    "    y = df['output']\n",
    "    return X, y\n",
    "\n",
    "# Standardize features\n",
    "def standardize_features(X):\n",
    "    scaler = StandardScaler()\n",
    "    return scaler.fit_transform(X)\n",
    "\n",
    "# Apply PCA for dimensionality reduction\n",
    "def apply_pca(X_scaled, variance_retained=0.95):\n",
    "    pca = PCA(n_components=variance_retained)\n",
    "    return pca.fit_transform(X_scaled)\n",
    "\n",
    "# Train-test split\n",
    "def split_data(X_pca, y, test_size=0.2, random_state=42):\n",
    "    return train_test_split(X_pca, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "# RandomizedSearchCV for hyperparameter tuning\n",
    "def perform_random_search(model, X_train, y_train):\n",
    "    param_dist = {\n",
    "        'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "        'min_samples_split': np.arange(2, 10),\n",
    "        'min_samples_leaf': np.arange(1, 5),\n",
    "        'max_features': ['auto', 'sqrt', 'log2', None]\n",
    "    }\n",
    "    random_search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=10, cv=5, random_state=42)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    return random_search\n",
    "\n",
    "# Cross-validation scores\n",
    "def cross_validate_model(model, X_train, y_train, cv=5):\n",
    "    kf = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "    return cross_val_score(model, X_train, y_train, cv=kf)\n",
    "\n",
    "# Calculate performance metrics\n",
    "def calculate_metrics(y_test, y_pred):\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mean_value = np.mean(y_test)\n",
    "    std_dev = np.std(y_test)\n",
    "    return r2, rmse, mae, mean_value, std_dev\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # Load and prepare data\n",
    "    X, y = load_and_prepare_data('bert_test_2.csv')\n",
    "\n",
    "    # Standardize features\n",
    "    X_scaled = standardize_features(X)\n",
    "\n",
    "    # Apply PCA for dimensionality reduction\n",
    "    X_pca = apply_pca(X_scaled)\n",
    "\n",
    "    # Split data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = split_data(X_pca, y)\n",
    "\n",
    "    # Initialize and tune model\n",
    "    model = DecisionTreeRegressor()\n",
    "    random_search = perform_random_search(model, X_train, y_train)\n",
    "\n",
    "    # Cross-validation\n",
    "    cv_scores = cross_validate_model(random_search.best_estimator_, X_train, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = random_search.best_estimator_.predict(X_test)\n",
    "\n",
    "    # Calculate performance metrics\n",
    "    r2, rmse, mae, mean_value, std_dev = calculate_metrics(y_test, y_pred)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Best Parameters: {random_search.best_params_}\")\n",
    "    print(f\"R^2 Score: {r2}\")\n",
    "    print(f\"RMSE: {rmse}\")\n",
    "    print(f\"MAE: {mae}\")\n",
    "    print(f\"Mean of Output: {mean_value}\")\n",
    "    print(f\"Standard Deviation of Output: {std_dev}\")\n",
    "    print(f\"Cross-Validation Scores: {cv_scores}\")\n",
    "    print(f\"Cross-Validation Mean: {cv_scores.mean()}\")\n",
    "    print(f\"Cross-Validation Std Dev: {cv_scores.std()}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8eb688-2eaf-415d-a8d6-1c94fa818d23",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Bayesian Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b40a3d1-9cb5-4118-ae7b-0e7c12cd9aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'lambda_2': 0.0001, 'lambda_1': 0.1, 'alpha_2': 0.1, 'alpha_1': 0.001}\n",
      "R^2 Score: 0.46877192408957424\n",
      "RMSE: 0.9021171128277098\n",
      "MAE: 0.7487594495353221\n",
      "Mean of Output: 3.4022140221402215\n",
      "Standard Deviation of Output: 1.2377200077817099\n",
      "Cross-Validation Scores: [0.4049201  0.38162817 0.39868496 0.45921714 0.41678268]\n",
      "Cross-Validation Mean: 0.4122466075674997\n",
      "Cross-Validation Std Dev: 0.026084062382817932\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Function to load dataset\n",
    "def load_data(file_path, target_column):\n",
    "    \"\"\"\n",
    "    Load dataset and separate features and target.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): Path to the dataset.\n",
    "        target_column (str): Column name of the target.\n",
    "    \n",
    "    Returns:\n",
    "        X (ndarray): Features.\n",
    "        y (ndarray): Target.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "    return X, y\n",
    "\n",
    "# Function to standardize the features\n",
    "def standardize_features(X):\n",
    "    \"\"\"\n",
    "    Standardize features to have zero mean and unit variance.\n",
    "\n",
    "    Parameters:\n",
    "        X (ndarray): Features to be standardized.\n",
    "    \n",
    "    Returns:\n",
    "        X_scaled (ndarray): Scaled features.\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    return X_scaled\n",
    "\n",
    "# Function to apply PCA for dimension reduction\n",
    "def apply_pca(X_scaled, variance_retained=0.95):\n",
    "    \"\"\"\n",
    "    Apply PCA to retain a certain amount of variance.\n",
    "\n",
    "    Parameters:\n",
    "        X_scaled (ndarray): Scaled features.\n",
    "        variance_retained (float): Proportion of variance to retain.\n",
    "    \n",
    "    Returns:\n",
    "        X_pca (ndarray): Transformed features after PCA.\n",
    "    \"\"\"\n",
    "    pca = PCA(n_components=variance_retained)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    return X_pca\n",
    "\n",
    "# Function to perform RandomizedSearchCV for hyperparameter tuning\n",
    "def perform_random_search(model, X_train, y_train, param_dist, n_iter=10, cv_splits=5):\n",
    "    \"\"\"\n",
    "    Perform RandomizedSearchCV for hyperparameter tuning.\n",
    "\n",
    "    Parameters:\n",
    "        model: Model to be tuned.\n",
    "        X_train (ndarray): Training features.\n",
    "        y_train (ndarray): Training target.\n",
    "        param_dist (dict): Distribution of parameters to sample from.\n",
    "        n_iter (int): Number of iterations for RandomizedSearchCV.\n",
    "        cv_splits (int): Number of splits for cross-validation.\n",
    "    \n",
    "    Returns:\n",
    "        random_search (RandomizedSearchCV): Best model from RandomizedSearchCV.\n",
    "    \"\"\"\n",
    "    random_search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=n_iter, cv=cv_splits, random_state=42)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    return random_search\n",
    "\n",
    "# Function to perform cross-validation\n",
    "def perform_cross_validation(model, X_train, y_train, cv_splits=5):\n",
    "    \"\"\"\n",
    "    Perform cross-validation and return the scores.\n",
    "\n",
    "    Parameters:\n",
    "        model: Model to be evaluated.\n",
    "        X_train (ndarray): Training features.\n",
    "        y_train (ndarray): Training target.\n",
    "        cv_splits (int): Number of splits for cross-validation.\n",
    "    \n",
    "    Returns:\n",
    "        cv_scores (ndarray): Cross-validation scores.\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=cv_splits, shuffle=True, random_state=42)\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=kf)\n",
    "    return cv_scores\n",
    "\n",
    "# Function to calculate performance metrics\n",
    "def calculate_performance_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate R², RMSE, MAE, and other metrics.\n",
    "\n",
    "    Parameters:\n",
    "        y_true (ndarray): True target values.\n",
    "        y_pred (ndarray): Predicted target values.\n",
    "    \n",
    "    Returns:\n",
    "        metrics (dict): Dictionary of performance metrics (R², RMSE, MAE, etc.)\n",
    "    \"\"\"\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mean_value = np.mean(y_true)\n",
    "    std_dev = np.std(y_true)\n",
    "    \n",
    "    metrics = {\n",
    "        \"R²\": r2,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAE\": mae,\n",
    "        \"Mean of Output\": mean_value,\n",
    "        \"Standard Deviation of Output\": std_dev\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Function to print the evaluation results\n",
    "def print_results(best_params, metrics, cv_scores):\n",
    "    \"\"\"\n",
    "    Print the results of the grid search and performance evaluation.\n",
    "\n",
    "    Parameters:\n",
    "        best_params (dict): Best parameters found from RandomizedSearchCV.\n",
    "        metrics (dict): Dictionary of performance metrics.\n",
    "        cv_scores (ndarray): Cross-validation scores.\n",
    "    \"\"\"\n",
    "    print(f\"Best Parameters: {best_params}\")\n",
    "    print(f\"R² Score: {metrics['R²']}\")\n",
    "    print(f\"RMSE: {metrics['RMSE']}\")\n",
    "    print(f\"MAE: {metrics['MAE']}\")\n",
    "    print(f\"Mean of Output: {metrics['Mean of Output']}\")\n",
    "    print(f\"Standard Deviation of Output: {metrics['Standard Deviation of Output']}\")\n",
    "    print(f\"Cross-Validation Scores: {cv_scores}\")\n",
    "    print(f\"Cross-Validation Mean: {cv_scores.mean()}\")\n",
    "    print(f\"Cross-Validation Std Dev: {cv_scores.std()}\")\n",
    "\n",
    "# Main function to run the workflow\n",
    "def main():\n",
    "    # Load data\n",
    "    X, y = load_data('bert_test_2.csv', 'output')\n",
    "\n",
    "    # Standardize features\n",
    "    X_scaled = standardize_features(X)\n",
    "\n",
    "    # Apply PCA\n",
    "    X_pca = apply_pca(X_scaled)\n",
    "\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize the model\n",
    "    model = BayesianRidge()\n",
    "\n",
    "    # Perform RandomizedSearchCV for hyperparameter tuning\n",
    "    param_dist = {\n",
    "        'alpha_1': np.logspace(-6, -1, 6),\n",
    "        'alpha_2': np.logspace(-6, -1, 6),\n",
    "        'lambda_1': np.logspace(-6, -1, 6),\n",
    "        'lambda_2': np.logspace(-6, -1, 6)\n",
    "    }\n",
    "    random_search = perform_random_search(model, X_train, y_train, param_dist)\n",
    "\n",
    "    # Perform cross-validation\n",
    "    cv_scores = perform_cross_validation(random_search.best_estimator_, X_train, y_train)\n",
    "\n",
    "    # Predictions on the test set\n",
    "    y_pred = random_search.best_estimator_.predict(X_test)\n",
    "\n",
    "    # Calculate performance metrics\n",
    "    metrics = calculate_performance_metrics(y_test, y_pred)\n",
    "\n",
    "    # Print results\n",
    "    print_results(random_search.best_params_, metrics, cv_scores)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60ff314-59cb-47cf-a018-5cedb8a897e2",
   "metadata": {},
   "source": [
    "# Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77332f4-7f89-450c-a6a6-fb1bd13d36a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_estimators': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None, 'bootstrap': True}\n",
      "R^2 Score: 0.5627794695810993\n",
      "RMSE: 0.8184133118873096\n",
      "MAE: 0.6304905060089562\n",
      "Mean of Output: 3.4022140221402215\n",
      "Standard Deviation of Output: 1.2377200077817099\n",
      "Cross-Validation Scores: [0.48035684 0.51561573 0.48915119]\n",
      "Cross-Validation Mean: 0.4950412526770014\n",
      "Cross-Validation Std Dev: 0.014984814769876632\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score, KFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Function to load dataset\n",
    "def load_data(file_path, target_column):\n",
    "    \"\"\"\n",
    "    Load dataset and separate features and target.\n",
    "    \n",
    "    Parameters:\n",
    "        file_path (str): Path to the dataset.\n",
    "        target_column (str): Column name of the target.\n",
    "    \n",
    "    Returns:\n",
    "        X (ndarray): Features.\n",
    "        y (ndarray): Target.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "    return X, y\n",
    "\n",
    "# Function to standardize the features\n",
    "def standardize_features(X):\n",
    "    \"\"\"\n",
    "    Standardize features to have zero mean and unit variance.\n",
    "    \n",
    "    Parameters:\n",
    "        X (ndarray): Features to be standardized.\n",
    "    \n",
    "    Returns:\n",
    "        X_scaled (ndarray): Scaled features.\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    return X_scaled\n",
    "\n",
    "# Function to apply PCA for dimension reduction\n",
    "def apply_pca(X_scaled, variance_retained=0.95):\n",
    "    \"\"\"\n",
    "    Apply PCA to retain a certain amount of variance.\n",
    "    \n",
    "    Parameters:\n",
    "        X_scaled (ndarray): Scaled features.\n",
    "        variance_retained (float): Proportion of variance to retain.\n",
    "    \n",
    "    Returns:\n",
    "        X_pca (ndarray): Transformed features after PCA.\n",
    "    \"\"\"\n",
    "    pca = PCA(n_components=variance_retained)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    return X_pca\n",
    "\n",
    "# Function to perform RandomizedSearchCV for hyperparameter tuning\n",
    "def perform_random_search(model, X_train, y_train, param_dist, n_iter=5, cv_splits=3):\n",
    "    \"\"\"\n",
    "    Perform RandomizedSearchCV for hyperparameter tuning.\n",
    "    \n",
    "    Parameters:\n",
    "        model: Model to be tuned.\n",
    "        X_train (ndarray): Training features.\n",
    "        y_train (ndarray): Training target.\n",
    "        param_dist (dict): Distribution of parameters to sample from.\n",
    "        n_iter (int): Number of iterations for RandomizedSearchCV.\n",
    "        cv_splits (int): Number of splits for cross-validation.\n",
    "    \n",
    "    Returns:\n",
    "        random_search (RandomizedSearchCV): Best model from RandomizedSearchCV.\n",
    "    \"\"\"\n",
    "    random_search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=n_iter, cv=cv_splits, random_state=42, n_jobs=-1)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    return random_search\n",
    "\n",
    "# Function to perform cross-validation\n",
    "def perform_cross_validation(model, X_train, y_train, cv_splits=3):\n",
    "    \"\"\"\n",
    "    Perform cross-validation and return the scores.\n",
    "    \n",
    "    Parameters:\n",
    "        model: Model to be evaluated.\n",
    "        X_train (ndarray): Training features.\n",
    "        y_train (ndarray): Training target.\n",
    "        cv_splits (int): Number of splits for cross-validation.\n",
    "    \n",
    "    Returns:\n",
    "        cv_scores (ndarray): Cross-validation scores.\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=cv_splits, shuffle=True, random_state=42)\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=kf)\n",
    "    return cv_scores\n",
    "\n",
    "# Function to calculate performance metrics\n",
    "def calculate_performance_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate R², RMSE, MAE, and other metrics.\n",
    "    \n",
    "    Parameters:\n",
    "        y_true (ndarray): True target values.\n",
    "        y_pred (ndarray): Predicted target values.\n",
    "    \n",
    "    Returns:\n",
    "        metrics (dict): Dictionary of performance metrics (R², RMSE, MAE, etc.)\n",
    "    \"\"\"\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mean_value = np.mean(y_true)\n",
    "    std_dev = np.std(y_true)\n",
    "    \n",
    "    metrics = {\n",
    "        \"R²\": r2,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAE\": mae,\n",
    "        \"Mean of Output\": mean_value,\n",
    "        \"Standard Deviation of Output\": std_dev\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Function to print the evaluation results\n",
    "def print_results(best_params, metrics, cv_scores):\n",
    "    \"\"\"\n",
    "    Print the results of the grid search and performance evaluation.\n",
    "    \n",
    "    Parameters:\n",
    "        best_params (dict): Best parameters found from RandomizedSearchCV.\n",
    "        metrics (dict): Dictionary of performance metrics.\n",
    "        cv_scores (ndarray): Cross-validation scores.\n",
    "    \"\"\"\n",
    "    print(f\"Best Parameters: {best_params}\")\n",
    "    print(f\"R² Score: {metrics['R²']}\")\n",
    "    print(f\"RMSE: {metrics['RMSE']}\")\n",
    "    print(f\"MAE: {metrics['MAE']}\")\n",
    "    print(f\"Mean of Output: {metrics['Mean of Output']}\")\n",
    "    print(f\"Standard Deviation of Output: {metrics['Standard Deviation of Output']}\")\n",
    "    print(f\"Cross-Validation Scores: {cv_scores}\")\n",
    "    print(f\"Cross-Validation Mean: {cv_scores.mean()}\")\n",
    "    print(f\"Cross-Validation Std Dev: {cv_scores.std()}\")\n",
    "\n",
    "# Main function to run the workflow\n",
    "def main():\n",
    "    # Load data\n",
    "    X, y = load_data('bert_test_2.csv', 'output')\n",
    "\n",
    "    # Standardize features\n",
    "    X_scaled = standardize_features(X)\n",
    "\n",
    "    # Apply PCA\n",
    "    X_pca = apply_pca(X_scaled)\n",
    "\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize the model\n",
    "    model = RandomForestRegressor()\n",
    "\n",
    "    # Perform RandomizedSearchCV for hyperparameter tuning\n",
    "    param_dist = {\n",
    "        'n_estimators': [10, 50],  # Reduced number of estimators\n",
    "        'max_depth': [None, 10],  # Reduced max_depth options\n",
    "        'min_samples_split': [2, 5],\n",
    "        'min_samples_leaf': [1, 2],\n",
    "        'bootstrap': [True]  # Keeping only one option for bootstrap\n",
    "    }\n",
    "    random_search = perform_random_search(model, X_train, y_train, param_dist)\n",
    "\n",
    "    # Perform cross-validation\n",
    "    cv_scores = perform_cross_validation(random_search.best_estimator_, X_train, y_train)\n",
    "\n",
    "    # Predictions on the test set\n",
    "    y_pred = random_search.best_estimator_.predict(X_test)\n",
    "\n",
    "    # Calculate performance metrics\n",
    "    metrics = calculate_performance_metrics(y_test, y_pred)\n",
    "\n",
    "    # Print results\n",
    "    print_results(random_search.best_params_, metrics, cv_scores)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a66b834-f34c-4f57-86a2-a87b35823434",
   "metadata": {},
   "source": [
    "## Support vector regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156c64e2-8001-40f6-bdc5-47f49248c884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'kernel': 'poly', 'epsilon': 0.5, 'degree': 2, 'C': 100}\n",
      "R^2 Score: 0.5900439384391127\n",
      "RMSE: 1.260085560294259\n",
      "MAE: 1.0188619540208168\n",
      "Mean of Output: 1.9384615384615385\n",
      "Standard Deviation of Output: 1.968028479131986\n",
      "Cross-Validation Scores: [0.30503217 0.30320936 0.32239364]\n",
      "Cross-Validation Mean: 0.31021172122150475\n",
      "Cross-Validation Std Dev: 0.00864599882480651\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score, KFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Load and prepare data\n",
    "def load_and_prepare_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    X = df.drop(columns=['output'])\n",
    "    y = df['output']\n",
    "    return X, y\n",
    "\n",
    "# Standardize features\n",
    "def standardize_features(X):\n",
    "    scaler = StandardScaler()\n",
    "    return scaler.fit_transform(X)\n",
    "\n",
    "# Apply PCA for dimensionality reduction\n",
    "def apply_pca(X_scaled, variance_retained=0.95):\n",
    "    pca = PCA(n_components=variance_retained)\n",
    "    return pca.fit_transform(X_scaled)\n",
    "\n",
    "# Split data into train and test sets\n",
    "def split_data(X_pca, y, test_size=0.2, random_state=42):\n",
    "    return train_test_split(X_pca, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "# Perform RandomizedSearchCV for parameter tuning\n",
    "def perform_random_search(model, X_train, y_train, param_dist):\n",
    "    random_search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=5, cv=3, random_state=42, n_jobs=-1)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    return random_search\n",
    "\n",
    "# Cross-validation\n",
    "def cross_validate_model(model, X_train, y_train, cv=3):\n",
    "    kf = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "    return cross_val_score(model, X_train, y_train, cv=kf)\n",
    "\n",
    "# Calculate performance metrics\n",
    "def calculate_metrics(y_test, y_pred):\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mean_value = np.mean(y_test)\n",
    "    std_dev = np.std(y_test)\n",
    "    return r2, rmse, mae, mean_value, std_dev\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # Load and prepare data\n",
    "    X, y = load_and_prepare_data('bert_test_2.csv')\n",
    "\n",
    "    # Standardize features\n",
    "    X_scaled = standardize_features(X)\n",
    "\n",
    "    # Apply PCA for dimensionality reduction\n",
    "    X_pca = apply_pca(X_scaled)\n",
    "\n",
    "    # Split data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = split_data(X_pca, y)\n",
    "\n",
    "    # Initialize Support Vector Regression model\n",
    "    model = SVR()\n",
    "\n",
    "    # Define the parameter distribution for RandomizedSearchCV\n",
    "    param_dist = {\n",
    "        'kernel': ['linear', 'rbf', 'poly'],\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'epsilon': [0.1, 0.2, 0.5, 0.3],\n",
    "        'degree': [2, 3],\n",
    "    }\n",
    "\n",
    "    # Perform RandomizedSearchCV for hyperparameter tuning\n",
    "    random_search = perform_random_search(model, X_train, y_train, param_dist)\n",
    "\n",
    "    # Cross-validation\n",
    "    cv_scores = cross_validate_model(random_search.best_estimator_, X_train, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = random_search.best_estimator_.predict(X_test)\n",
    "\n",
    "    # Calculate performance metrics\n",
    "    r2, rmse, mae, mean_value, std_dev = calculate_metrics(y_test, y_pred)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Best Parameters: {random_search.best_params_}\")\n",
    "    print(f\"R^2 Score: {r2}\")\n",
    "    print(f\"RMSE: {rmse}\")\n",
    "    print(f\"MAE: {mae}\")\n",
    "    print(f\"Mean of Output: {mean_value}\")\n",
    "    print(f\"Standard Deviation of Output: {std_dev}\")\n",
    "    print(f\"Cross-Validation Scores: {cv_scores}\")\n",
    "    print(f\"Cross-Validation Mean: {cv_scores.mean()}\")\n",
    "    print(f\"Cross-Validation Std Dev: {cv_scores.std()}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3808b0-d0ef-40e2-af32-4063a5831c7e",
   "metadata": {},
   "source": [
    "## Gaussian Process Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913abd37-09f7-4edd-8a36-7a1b73cef5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_restarts_optimizer': 5, 'alpha': 1e-10}\n",
      "R^2 Score: 0.5568212376239063\n",
      "RMSE: 1.3101494803846034\n",
      "MAE: 0.9680913423899548\n",
      "Mean of Output: 1.9384615384615385\n",
      "Standard Deviation of Output: 1.968028479131986\n",
      "Cross-Validation Scores: [0.4084499  0.22946832 0.26207531]\n",
      "Cross-Validation Mean: 0.29999784492345233\n",
      "Cross-Validation Std Dev: 0.07783397165422182\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score, KFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C, WhiteKernel\n",
    "\n",
    "# Load and prepare data\n",
    "def load_and_prepare_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    X = df.drop(columns=['output'])\n",
    "    y = df['output']\n",
    "    return X, y\n",
    "\n",
    "# Standardize features\n",
    "def standardize_features(X):\n",
    "    scaler = StandardScaler()\n",
    "    return scaler.fit_transform(X)\n",
    "\n",
    "# Apply PCA for dimensionality reduction\n",
    "def apply_pca(X_scaled, variance_retained=0.95):\n",
    "    pca = PCA(n_components=variance_retained)\n",
    "    return pca.fit_transform(X_scaled)\n",
    "\n",
    "# Split data into train and test sets\n",
    "def split_data(X_pca, y, test_size=0.2, random_state=42):\n",
    "    return train_test_split(X_pca, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "# Initialize and perform RandomizedSearchCV for hyperparameter tuning\n",
    "def perform_random_search(model, X_train, y_train, param_dist):\n",
    "    random_search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=5, cv=3, random_state=42, n_jobs=-1)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    return random_search\n",
    "\n",
    "# Cross-validation\n",
    "def cross_validate_model(model, X_train, y_train, cv=3):\n",
    "    kf = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "    return cross_val_score(model, X_train, y_train, cv=kf)\n",
    "\n",
    "# Calculate performance metrics\n",
    "def calculate_metrics(y_test, y_pred):\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mean_value = np.mean(y_test)\n",
    "    std_dev = np.std(y_test)\n",
    "    return r2, rmse, mae, mean_value, std_dev\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # Load and prepare data\n",
    "    X, y = load_and_prepare_data('bert_test_2.csv')\n",
    "\n",
    "    # Standardize features\n",
    "    X_scaled = standardize_features(X)\n",
    "\n",
    "    # Apply PCA for dimensionality reduction\n",
    "    X_pca = apply_pca(X_scaled)\n",
    "\n",
    "    # Split data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = split_data(X_pca, y)\n",
    "\n",
    "    # Initialize Gaussian Process Regression model\n",
    "    kernel = C(1.0, (1e-3, 1e3)) * RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e2)) + WhiteKernel()\n",
    "    model = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10, random_state=42)\n",
    "\n",
    "    # Define the parameter distribution for RandomizedSearchCV\n",
    "    param_dist = {\n",
    "        'alpha': [1e-10, 1e-5, 1e-2],\n",
    "        'n_restarts_optimizer': [5, 10, 15],\n",
    "    }\n",
    "\n",
    "    # Perform RandomizedSearchCV for hyperparameter tuning\n",
    "    random_search = perform_random_search(model, X_train, y_train, param_dist)\n",
    "\n",
    "    # Cross-validation\n",
    "    cv_scores = cross_validate_model(random_search.best_estimator_, X_train, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = random_search.best_estimator_.predict(X_test)\n",
    "\n",
    "    # Calculate performance metrics\n",
    "    r2, rmse, mae, mean_value, std_dev = calculate_metrics(y_test, y_pred)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Best Parameters: {random_search.best_params_}\")\n",
    "    print(f\"R^2 Score: {r2}\")\n",
    "    print(f\"RMSE: {rmse}\")\n",
    "    print(f\"MAE: {mae}\")\n",
    "    print(f\"Mean of Output: {mean_value}\")\n",
    "    print(f\"Standard Deviation of Output: {std_dev}\")\n",
    "    print(f\"Cross-Validation Scores: {cv_scores}\")\n",
    "    print(f\"Cross-Validation Mean: {cv_scores.mean()}\")\n",
    "    print(f\"Cross-Validation Std Dev: {cv_scores.std()}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
