{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13ca5075-191d-4f60-8325-18dceb61868f",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e850783-6a2a-4bd3-a6fb-7a921fa228fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    embed_0   embed_1   embed_2   embed_3   embed_4   embed_5   embed_6  \\\n",
      "0 -0.002268 -0.057392 -0.051938 -0.254064 -0.107042 -0.005746  0.053339   \n",
      "1 -0.095116  0.002254 -0.080440 -0.032033  0.325927 -0.089124  0.060066   \n",
      "2  0.171062 -0.006862 -0.092904  0.191909 -0.059166  0.084494  0.057149   \n",
      "3  0.091722 -0.023084 -0.170847  0.275267 -0.098605 -0.062822  0.026235   \n",
      "4  0.058596 -0.003751 -0.051466  0.243470  0.019038 -0.036104 -0.019322   \n",
      "\n",
      "    embed_7   embed_8   embed_9  ...  embed_759  embed_760  embed_761  \\\n",
      "0  0.155956  0.116585 -0.038332  ...   0.072443   0.059975  -0.076614   \n",
      "1  0.011424  0.037144 -0.126206  ...   0.060893  -0.161714  -0.016327   \n",
      "2 -0.057770  0.018334  0.042601  ...  -0.011123   0.010387   0.074528   \n",
      "3 -0.048630 -0.013406 -0.024388  ...  -0.104926   0.042281   0.022375   \n",
      "4 -0.011959 -0.054584 -0.058981  ...  -0.159260   0.032556  -0.005767   \n",
      "\n",
      "   embed_762  embed_763  embed_764  embed_765  embed_766  embed_767  output  \n",
      "0   0.036943   0.130576   0.409834  -0.142671   0.027263  -0.046064       0  \n",
      "1   0.029357   0.101992   0.217288  -0.190804   0.010403  -0.092698       0  \n",
      "2  -0.054416  -0.009584   0.244145  -0.002439   0.106801   0.046556       0  \n",
      "3   0.038976  -0.098919  -0.080987   0.140436   0.061884   0.038201       0  \n",
      "4   0.025254  -0.051693   0.056800  -0.031124   0.041619   0.015181       0  \n",
      "\n",
      "[5 rows x 769 columns]\n",
      "Index(['embed_0', 'embed_1', 'embed_2', 'embed_3', 'embed_4', 'embed_5',\n",
      "       'embed_6', 'embed_7', 'embed_8', 'embed_9',\n",
      "       ...\n",
      "       'embed_759', 'embed_760', 'embed_761', 'embed_762', 'embed_763',\n",
      "       'embed_764', 'embed_765', 'embed_766', 'embed_767', 'output'],\n",
      "      dtype='object', length=769)\n",
      "MSE: 5.508192793445987e+21\n",
      "RMSE: 74217200118.61124\n",
      "R²: -3.568389584980578e+21\n",
      "Standard Deviation of MSE: 5.894379626681844e+21\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Function to load and inspect the dataset\n",
    "def load_and_inspect_data(file_path, target_column):\n",
    "    \"\"\"\n",
    "    Loads the dataset and displays basic information.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): Path to the dataset.\n",
    "        target_column (str): Name of the target column.\n",
    "\n",
    "    Returns:\n",
    "        X (numpy.ndarray): Features.\n",
    "        y (numpy.ndarray): Target.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(\"Dataset Preview:\")\n",
    "    print(df.head())\n",
    "    print(\"\\nColumns:\", df.columns)\n",
    "    X = df.drop(columns=[target_column]).values\n",
    "    y = df[target_column].values\n",
    "    return X, y\n",
    "\n",
    "# Function to preprocess the features\n",
    "def preprocess_features(X):\n",
    "    \"\"\"\n",
    "    Scales the features using StandardScaler.\n",
    "\n",
    "    Parameters:\n",
    "        X (numpy.ndarray): Features to be scaled.\n",
    "\n",
    "    Returns:\n",
    "        X_scaled (numpy.ndarray): Scaled features.\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    return X_scaled\n",
    "\n",
    "# Function to train the model using GridSearchCV\n",
    "def train_model(X, y, model, param_grid, cv_splits):\n",
    "    \"\"\"\n",
    "    Trains the model using GridSearchCV with cross-validation.\n",
    "\n",
    "    Parameters:\n",
    "        X (numpy.ndarray): Features.\n",
    "        y (numpy.ndarray): Target.\n",
    "        model: Machine learning model to train.\n",
    "        param_grid (dict): Hyperparameter grid for GridSearchCV.\n",
    "        cv_splits (int): Number of cross-validation splits.\n",
    "\n",
    "    Returns:\n",
    "        best_model: The best estimator found by GridSearchCV.\n",
    "        grid_search: The fitted GridSearchCV object.\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=cv_splits, shuffle=True, random_state=42)\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=kf, scoring='neg_mean_squared_error')\n",
    "    grid_search.fit(X, y)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    return best_model, grid_search\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate_model(model, X, y, cv_splits):\n",
    "    \"\"\"\n",
    "    Evaluates the model using cross-validation.\n",
    "\n",
    "    Parameters:\n",
    "        model: Trained machine learning model.\n",
    "        X (numpy.ndarray): Features.\n",
    "        y (numpy.ndarray): Target.\n",
    "        cv_splits (int): Number of cross-validation splits.\n",
    "\n",
    "    Returns:\n",
    "        dict: Evaluation metrics (MSE, RMSE, R², Std Dev of MSE).\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=cv_splits, shuffle=True, random_state=42)\n",
    "    mse_scores = cross_val_score(model, X, y, cv=kf, scoring='neg_mean_squared_error')\n",
    "    r2_scores = cross_val_score(model, X, y, cv=kf, scoring='r2')\n",
    "    mse = -mse_scores.mean()\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_scores.mean()\n",
    "    std_dev = np.std(mse_scores)\n",
    "    return {\"MSE\": mse, \"RMSE\": rmse, \"R²\": r2, \"Std Dev of MSE\": std_dev}\n",
    "\n",
    "# Main script\n",
    "if __name__ == \"__main__\":\n",
    "    # Parameters\n",
    "    file_path = 'roberta_test_2.csv'\n",
    "    target_column = 'output'\n",
    "    param_grid = {}  # No hyperparameters for LinearRegression\n",
    "    cv_splits = 10\n",
    "\n",
    "    # Load and preprocess data\n",
    "    X, y = load_and_inspect_data(file_path, target_column)\n",
    "    X_scaled = preprocess_features(X)\n",
    "\n",
    "    # Train the model\n",
    "    model = LinearRegression()\n",
    "    best_model, grid_search = train_model(X_scaled, y, model, param_grid, cv_splits)\n",
    "\n",
    "    # Reduce dataset size for faster evaluation\n",
    "    df_sample = pd.DataFrame(X_scaled).sample(n=500, random_state=42)\n",
    "    X_sample = df_sample.values\n",
    "    y_sample = y[:500]  # Corresponding targets\n",
    "    X_sample_scaled = preprocess_features(X_sample)\n",
    "\n",
    "    # Re-train and evaluate on the sample\n",
    "    best_model_sample, _ = train_model(X_sample_scaled, y_sample, model, param_grid, cv_splits)\n",
    "    metrics = evaluate_model(best_model_sample, X_sample_scaled, y_sample, cv_splits)\n",
    "\n",
    "    # Display metrics\n",
    "    print(\"\\nEvaluation Metrics:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cceb1b-f2c5-4845-932c-707032958ad4",
   "metadata": {},
   "source": [
    "# Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5dac324-bc3a-4fa5-9a37-6e769a8c6c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    embed_0   embed_1   embed_2   embed_3   embed_4   embed_5   embed_6  \\\n",
      "0 -0.002268 -0.057392 -0.051938 -0.254064 -0.107042 -0.005746  0.053339   \n",
      "1 -0.095116  0.002254 -0.080440 -0.032033  0.325927 -0.089124  0.060066   \n",
      "2  0.171062 -0.006862 -0.092904  0.191909 -0.059166  0.084494  0.057149   \n",
      "3  0.091722 -0.023084 -0.170847  0.275267 -0.098605 -0.062822  0.026235   \n",
      "4  0.058596 -0.003751 -0.051466  0.243470  0.019038 -0.036104 -0.019322   \n",
      "\n",
      "    embed_7   embed_8   embed_9  ...  embed_759  embed_760  embed_761  \\\n",
      "0  0.155956  0.116585 -0.038332  ...   0.072443   0.059975  -0.076614   \n",
      "1  0.011424  0.037144 -0.126206  ...   0.060893  -0.161714  -0.016327   \n",
      "2 -0.057770  0.018334  0.042601  ...  -0.011123   0.010387   0.074528   \n",
      "3 -0.048630 -0.013406 -0.024388  ...  -0.104926   0.042281   0.022375   \n",
      "4 -0.011959 -0.054584 -0.058981  ...  -0.159260   0.032556  -0.005767   \n",
      "\n",
      "   embed_762  embed_763  embed_764  embed_765  embed_766  embed_767  output  \n",
      "0   0.036943   0.130576   0.409834  -0.142671   0.027263  -0.046064       0  \n",
      "1   0.029357   0.101992   0.217288  -0.190804   0.010403  -0.092698       0  \n",
      "2  -0.054416  -0.009584   0.244145  -0.002439   0.106801   0.046556       0  \n",
      "3   0.038976  -0.098919  -0.080987   0.140436   0.061884   0.038201       0  \n",
      "4   0.025254  -0.051693   0.056800  -0.031124   0.041619   0.015181       0  \n",
      "\n",
      "[5 rows x 769 columns]\n",
      "Index(['embed_0', 'embed_1', 'embed_2', 'embed_3', 'embed_4', 'embed_5',\n",
      "       'embed_6', 'embed_7', 'embed_8', 'embed_9',\n",
      "       ...\n",
      "       'embed_759', 'embed_760', 'embed_761', 'embed_762', 'embed_763',\n",
      "       'embed_764', 'embed_765', 'embed_766', 'embed_767', 'output'],\n",
      "      dtype='object', length=769)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.904e+01, tolerance: 1.953e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.433e+01, tolerance: 1.962e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.049e+01, tolerance: 1.996e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.998e+01, tolerance: 1.952e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.957e+01, tolerance: 1.913e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.942e+01, tolerance: 1.955e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.234e+01, tolerance: 1.945e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.158e+01, tolerance: 1.945e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.973e+01, tolerance: 1.941e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.593e+01, tolerance: 1.957e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.073e+01, tolerance: 1.953e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.299e+01, tolerance: 1.962e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.029e+01, tolerance: 1.996e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.082e+01, tolerance: 1.952e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.016e+01, tolerance: 1.913e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.691e+01, tolerance: 1.955e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.752e+01, tolerance: 1.945e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.880e+01, tolerance: 1.945e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.209e+01, tolerance: 1.941e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.018e+01, tolerance: 1.957e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.604e+00, tolerance: 6.580e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.316e+00, tolerance: 6.540e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.752e+00, tolerance: 6.482e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.516e+00, tolerance: 6.713e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.702e+00, tolerance: 6.710e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.205e+00, tolerance: 6.402e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.674e+00, tolerance: 6.642e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.651e+00, tolerance: 6.755e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.555e+00, tolerance: 6.659e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.155e+00, tolerance: 6.607e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.509e+00, tolerance: 6.580e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.174e+01, tolerance: 6.540e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.218e+01, tolerance: 6.482e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.868e+00, tolerance: 6.713e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.620e+00, tolerance: 6.710e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.180e+01, tolerance: 6.402e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.461e+00, tolerance: 6.642e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.128e+01, tolerance: 6.755e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.058e+01, tolerance: 6.659e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.849e+00, tolerance: 6.607e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha (regularization strength): 0.01\n",
      "MSE: 0.9328511603607741\n",
      "RMSE: 0.9658422026194414\n",
      "R²: 0.33879625535420954\n",
      "Standard Deviation of MSE: 0.15535334313966961\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Function to load and inspect the dataset\n",
    "def load_and_inspect_data(file_path, target_column):\n",
    "    \"\"\"\n",
    "    Loads the dataset and separates features and target.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): Path to the dataset.\n",
    "        target_column (str): Name of the target column.\n",
    "\n",
    "    Returns:\n",
    "        X (numpy.ndarray): Features.\n",
    "        y (numpy.ndarray): Target.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(\"Dataset Preview:\")\n",
    "    print(df.head())\n",
    "    print(\"\\nColumns:\", df.columns)\n",
    "    X = df.drop(columns=[target_column]).values\n",
    "    y = df[target_column].values\n",
    "    return X, y, df\n",
    "\n",
    "# Function to preprocess the features\n",
    "def preprocess_features(X):\n",
    "    \"\"\"\n",
    "    Scales the features using StandardScaler.\n",
    "\n",
    "    Parameters:\n",
    "        X (numpy.ndarray): Features to be scaled.\n",
    "\n",
    "    Returns:\n",
    "        X_scaled (numpy.ndarray): Scaled features.\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    return X_scaled\n",
    "\n",
    "# Function to perform Grid Search for hyperparameter tuning\n",
    "def tune_model(X, y, model, param_grid, cv_splits):\n",
    "    \"\"\"\n",
    "    Tunes the model using GridSearchCV with cross-validation.\n",
    "\n",
    "    Parameters:\n",
    "        X (numpy.ndarray): Features.\n",
    "        y (numpy.ndarray): Target.\n",
    "        model: Machine learning model to tune.\n",
    "        param_grid (dict): Hyperparameter grid for GridSearchCV.\n",
    "        cv_splits (int): Number of cross-validation splits.\n",
    "\n",
    "    Returns:\n",
    "        best_model: The best estimator found by GridSearchCV.\n",
    "        grid_search: The fitted GridSearchCV object.\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=cv_splits, shuffle=True, random_state=42)\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=kf, scoring='neg_mean_squared_error')\n",
    "    grid_search.fit(X, y)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    return best_model, grid_search\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate_model(model, X, y, cv_splits):\n",
    "    \"\"\"\n",
    "    Evaluates the model using cross-validation.\n",
    "\n",
    "    Parameters:\n",
    "        model: Trained machine learning model.\n",
    "        X (numpy.ndarray): Features.\n",
    "        y (numpy.ndarray): Target.\n",
    "        cv_splits (int): Number of cross-validation splits.\n",
    "\n",
    "    Returns:\n",
    "        dict: Evaluation metrics (MSE, RMSE, R², Std Dev of MSE).\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=cv_splits, shuffle=True, random_state=42)\n",
    "    mse_scores = cross_val_score(model, X, y, cv=kf, scoring='neg_mean_squared_error')\n",
    "    r2_scores = cross_val_score(model, X, y, cv=kf, scoring='r2')\n",
    "    mse = -mse_scores.mean()\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_scores.mean()\n",
    "    std_dev = np.std(mse_scores)\n",
    "    return {\"MSE\": mse, \"RMSE\": rmse, \"R²\": r2, \"Std Dev of MSE\": std_dev}\n",
    "\n",
    "# Main script\n",
    "if __name__ == \"__main__\":\n",
    "    # Parameters\n",
    "    file_path = 'roberta_test_2.csv'\n",
    "    target_column = 'output'\n",
    "    param_grid = {'alpha': [0.0001, 0.001, 0.01, 0.1, 1]}  # Regularization strength\n",
    "    cv_splits = 10\n",
    "\n",
    "    # Load and preprocess data\n",
    "    X, y, df = load_and_inspect_data(file_path, target_column)\n",
    "    X_scaled = preprocess_features(X)\n",
    "\n",
    "    # Train the Lasso model\n",
    "    model = Lasso()\n",
    "    best_model, grid_search = tune_model(X_scaled, y, model, param_grid, cv_splits)\n",
    "\n",
    "    # Sample data for faster computation\n",
    "    df_sample = df.sample(n=500, random_state=42)\n",
    "    X_sample = df_sample.drop(columns=[target_column]).values\n",
    "    y_sample = df_sample[target_column].values\n",
    "    X_sample_scaled = preprocess_features(X_sample)\n",
    "\n",
    "    # Re-tune and evaluate on the sample\n",
    "    best_model_sample, _ = tune_model(X_sample_scaled, y_sample, model, param_grid, cv_splits)\n",
    "    metrics = evaluate_model(best_model_sample, X_sample_scaled, y_sample, cv_splits)\n",
    "\n",
    "    # Display the results\n",
    "    print(f\"Best alpha (regularization strength): {grid_search.best_params_['alpha']}\")\n",
    "    print(\"\\nEvaluation Metrics:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec61724-a409-4404-b8f9-06ec12651428",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b721206c-2b60-4c3b-a755-49ec248bba1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 80 candidates, totalling 800 fits\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=3, p=1, weights=uniform;, score=-0.767 total time=   0.4s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=3, p=1, weights=uniform;, score=-0.820 total time=   0.0s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=3, p=1, weights=uniform;, score=-0.942 total time=   0.0s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=3, p=1, weights=uniform;, score=-1.047 total time=   0.0s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=3, p=1, weights=uniform;, score=-1.235 total time=   0.0s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=3, p=1, weights=uniform;, score=-0.761 total time=   0.1s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=3, p=1, weights=uniform;, score=-0.722 total time=   0.0s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=3, p=1, weights=uniform;, score=-0.711 total time=   0.0s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=3, p=1, weights=uniform;, score=-0.750 total time=   0.0s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=3, p=1, weights=uniform;, score=-0.793 total time=   0.0s\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=3, p=1, weights=distance;, score=-0.644 total time=   0.0s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=3, p=1, weights=distance;, score=-0.696 total time=   0.0s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=3, p=1, weights=distance;, score=-0.799 total time=   0.0s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=3, p=1, weights=distance;, score=-0.928 total time=   0.0s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=3, p=1, weights=distance;, score=-1.181 total time=   0.0s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=3, p=1, weights=distance;, score=-0.681 total time=   0.0s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=3, p=1, weights=distance;, score=-0.621 total time=   0.0s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=3, p=1, weights=distance;, score=-0.547 total time=   0.0s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=3, p=1, weights=distance;, score=-0.674 total time=   0.0s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=3, p=1, weights=distance;, score=-0.707 total time=   0.0s\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=3, p=2, weights=uniform;, score=-0.788 total time=   0.0s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=3, p=2, weights=uniform;, score=-0.844 total time=   0.0s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=3, p=2, weights=uniform;, score=-0.912 total time=   0.0s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=3, p=2, weights=uniform;, score=-1.012 total time=   0.0s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=3, p=2, weights=uniform;, score=-1.241 total time=   0.0s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=3, p=2, weights=uniform;, score=-0.726 total time=   0.0s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=3, p=2, weights=uniform;, score=-0.682 total time=   0.0s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=3, p=2, weights=uniform;, score=-0.655 total time=   0.0s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=3, p=2, weights=uniform;, score=-0.729 total time=   0.0s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=3, p=2, weights=uniform;, score=-0.755 total time=   0.0s\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=3, p=2, weights=distance;, score=-0.659 total time=   0.0s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=3, p=2, weights=distance;, score=-0.696 total time=   0.0s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=3, p=2, weights=distance;, score=-0.768 total time=   0.0s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=3, p=2, weights=distance;, score=-0.908 total time=   0.0s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=3, p=2, weights=distance;, score=-1.179 total time=   0.0s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=3, p=2, weights=distance;, score=-0.651 total time=   0.0s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=3, p=2, weights=distance;, score=-0.614 total time=   0.0s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=3, p=2, weights=distance;, score=-0.478 total time=   0.0s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=3, p=2, weights=distance;, score=-0.668 total time=   0.0s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=3, p=2, weights=distance;, score=-0.682 total time=   0.0s\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=5, p=1, weights=uniform;, score=-0.736 total time=   0.0s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=5, p=1, weights=uniform;, score=-0.961 total time=   0.0s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=5, p=1, weights=uniform;, score=-1.059 total time=   0.1s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=5, p=1, weights=uniform;, score=-1.070 total time=   0.1s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=5, p=1, weights=uniform;, score=-1.171 total time=   0.1s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=5, p=1, weights=uniform;, score=-0.753 total time=   0.1s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=5, p=1, weights=uniform;, score=-0.743 total time=   0.0s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=5, p=1, weights=uniform;, score=-0.885 total time=   0.0s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=5, p=1, weights=uniform;, score=-0.727 total time=   0.0s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=5, p=1, weights=uniform;, score=-0.797 total time=   0.1s\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=5, p=1, weights=distance;, score=-0.559 total time=   0.0s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=5, p=1, weights=distance;, score=-0.686 total time=   0.0s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=5, p=1, weights=distance;, score=-0.868 total time=   0.0s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=5, p=1, weights=distance;, score=-0.927 total time=   0.0s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=5, p=1, weights=distance;, score=-1.049 total time=   0.0s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=5, p=1, weights=distance;, score=-0.653 total time=   0.0s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=5, p=1, weights=distance;, score=-0.596 total time=   0.0s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=5, p=1, weights=distance;, score=-0.598 total time=   0.0s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=5, p=1, weights=distance;, score=-0.634 total time=   0.0s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=5, p=1, weights=distance;, score=-0.647 total time=   0.0s\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=5, p=2, weights=uniform;, score=-0.723 total time=   0.0s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=5, p=2, weights=uniform;, score=-0.961 total time=   0.0s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=5, p=2, weights=uniform;, score=-1.063 total time=   0.0s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=5, p=2, weights=uniform;, score=-1.080 total time=   0.0s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=5, p=2, weights=uniform;, score=-1.186 total time=   0.0s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=5, p=2, weights=uniform;, score=-0.707 total time=   0.0s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=5, p=2, weights=uniform;, score=-0.725 total time=   0.0s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=5, p=2, weights=uniform;, score=-0.867 total time=   0.0s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=5, p=2, weights=uniform;, score=-0.727 total time=   0.0s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=5, p=2, weights=uniform;, score=-0.808 total time=   0.0s\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=5, p=2, weights=distance;, score=-0.545 total time=   0.0s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=5, p=2, weights=distance;, score=-0.717 total time=   0.0s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=5, p=2, weights=distance;, score=-0.863 total time=   0.3s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=5, p=2, weights=distance;, score=-0.938 total time=   0.0s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=5, p=2, weights=distance;, score=-1.067 total time=   0.0s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=5, p=2, weights=distance;, score=-0.634 total time=   0.0s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=5, p=2, weights=distance;, score=-0.576 total time=   0.0s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=5, p=2, weights=distance;, score=-0.597 total time=   0.0s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=5, p=2, weights=distance;, score=-0.633 total time=   0.0s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=5, p=2, weights=distance;, score=-0.661 total time=   0.0s\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=7, p=1, weights=uniform;, score=-0.754 total time=   0.1s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=7, p=1, weights=uniform;, score=-1.008 total time=   0.0s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=7, p=1, weights=uniform;, score=-1.180 total time=   0.0s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=7, p=1, weights=uniform;, score=-1.141 total time=   0.0s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=7, p=1, weights=uniform;, score=-1.133 total time=   0.0s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=7, p=1, weights=uniform;, score=-0.772 total time=   0.0s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=7, p=1, weights=uniform;, score=-0.845 total time=   0.0s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=7, p=1, weights=uniform;, score=-0.937 total time=   0.0s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=7, p=1, weights=uniform;, score=-0.728 total time=   0.0s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=7, p=1, weights=uniform;, score=-0.830 total time=   0.0s\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=7, p=1, weights=distance;, score=-0.566 total time=   0.0s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=7, p=1, weights=distance;, score=-0.722 total time=   0.1s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=7, p=1, weights=distance;, score=-0.925 total time=   0.0s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=7, p=1, weights=distance;, score=-0.956 total time=   0.0s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=7, p=1, weights=distance;, score=-0.985 total time=   0.0s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=7, p=1, weights=distance;, score=-0.637 total time=   0.0s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=7, p=1, weights=distance;, score=-0.635 total time=   0.0s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=7, p=1, weights=distance;, score=-0.620 total time=   0.0s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=7, p=1, weights=distance;, score=-0.606 total time=   0.0s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=7, p=1, weights=distance;, score=-0.652 total time=   0.0s\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=7, p=2, weights=uniform;, score=-0.783 total time=   0.0s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=7, p=2, weights=uniform;, score=-1.102 total time=   0.0s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=7, p=2, weights=uniform;, score=-1.194 total time=   0.0s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=7, p=2, weights=uniform;, score=-1.152 total time=   0.0s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=7, p=2, weights=uniform;, score=-1.121 total time=   0.0s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=7, p=2, weights=uniform;, score=-0.797 total time=   0.0s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=7, p=2, weights=uniform;, score=-0.823 total time=   0.0s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=7, p=2, weights=uniform;, score=-0.948 total time=   0.0s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=7, p=2, weights=uniform;, score=-0.743 total time=   0.0s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=7, p=2, weights=uniform;, score=-0.887 total time=   0.0s\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=7, p=2, weights=distance;, score=-0.582 total time=   0.0s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=7, p=2, weights=distance;, score=-0.788 total time=   0.0s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=7, p=2, weights=distance;, score=-0.922 total time=   0.0s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=7, p=2, weights=distance;, score=-0.962 total time=   0.0s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=7, p=2, weights=distance;, score=-0.971 total time=   0.0s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=7, p=2, weights=distance;, score=-0.658 total time=   0.0s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=7, p=2, weights=distance;, score=-0.628 total time=   0.0s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=7, p=2, weights=distance;, score=-0.619 total time=   0.0s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=7, p=2, weights=distance;, score=-0.617 total time=   0.0s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=7, p=2, weights=distance;, score=-0.690 total time=   0.0s\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=9, p=1, weights=uniform;, score=-0.794 total time=   0.0s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=9, p=1, weights=uniform;, score=-1.080 total time=   0.0s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=9, p=1, weights=uniform;, score=-1.268 total time=   0.0s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=9, p=1, weights=uniform;, score=-1.091 total time=   0.0s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=9, p=1, weights=uniform;, score=-1.113 total time=   0.1s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=9, p=1, weights=uniform;, score=-0.838 total time=   0.0s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=9, p=1, weights=uniform;, score=-0.879 total time=   0.0s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=9, p=1, weights=uniform;, score=-0.965 total time=   0.0s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=9, p=1, weights=uniform;, score=-0.729 total time=   0.0s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=9, p=1, weights=uniform;, score=-0.878 total time=   0.0s\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=9, p=1, weights=distance;, score=-0.576 total time=   0.0s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=9, p=1, weights=distance;, score=-0.758 total time=   0.0s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=9, p=1, weights=distance;, score=-0.919 total time=   0.0s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=9, p=1, weights=distance;, score=-0.903 total time=   0.0s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=9, p=1, weights=distance;, score=-0.950 total time=   0.0s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=9, p=1, weights=distance;, score=-0.659 total time=   0.0s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=9, p=1, weights=distance;, score=-0.639 total time=   0.0s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=9, p=1, weights=distance;, score=-0.629 total time=   0.0s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=9, p=1, weights=distance;, score=-0.600 total time=   0.0s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=9, p=1, weights=distance;, score=-0.653 total time=   0.0s\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=9, p=2, weights=uniform;, score=-0.806 total time=   0.0s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=9, p=2, weights=uniform;, score=-1.095 total time=   0.0s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=9, p=2, weights=uniform;, score=-1.249 total time=   0.0s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=9, p=2, weights=uniform;, score=-1.075 total time=   0.0s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=9, p=2, weights=uniform;, score=-1.095 total time=   0.0s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=9, p=2, weights=uniform;, score=-0.862 total time=   0.0s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=9, p=2, weights=uniform;, score=-0.899 total time=   0.0s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=9, p=2, weights=uniform;, score=-0.932 total time=   0.0s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=9, p=2, weights=uniform;, score=-0.722 total time=   0.0s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=9, p=2, weights=uniform;, score=-0.899 total time=   0.0s\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=9, p=2, weights=distance;, score=-0.566 total time=   0.0s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=9, p=2, weights=distance;, score=-0.764 total time=   0.0s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=9, p=2, weights=distance;, score=-0.881 total time=   0.0s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=9, p=2, weights=distance;, score=-0.882 total time=   0.0s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=9, p=2, weights=distance;, score=-0.920 total time=   0.0s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=9, p=2, weights=distance;, score=-0.673 total time=   0.0s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=9, p=2, weights=distance;, score=-0.649 total time=   0.0s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=9, p=2, weights=distance;, score=-0.605 total time=   0.0s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=9, p=2, weights=distance;, score=-0.594 total time=   0.0s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=9, p=2, weights=distance;, score=-0.665 total time=   0.0s\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=11, p=1, weights=uniform;, score=-0.803 total time=   0.1s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=11, p=1, weights=uniform;, score=-1.088 total time=   0.0s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=11, p=1, weights=uniform;, score=-1.330 total time=   0.0s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=11, p=1, weights=uniform;, score=-1.065 total time=   0.0s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=11, p=1, weights=uniform;, score=-1.128 total time=   0.0s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=11, p=1, weights=uniform;, score=-0.888 total time=   0.0s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=11, p=1, weights=uniform;, score=-0.925 total time=   0.0s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=11, p=1, weights=uniform;, score=-1.033 total time=   0.1s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=11, p=1, weights=uniform;, score=-0.735 total time=   0.0s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=11, p=1, weights=uniform;, score=-0.976 total time=   0.0s\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=11, p=1, weights=distance;, score=-0.559 total time=   0.0s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=11, p=1, weights=distance;, score=-0.776 total time=   0.0s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=11, p=1, weights=distance;, score=-0.899 total time=   0.0s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=11, p=1, weights=distance;, score=-0.879 total time=   0.0s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=11, p=1, weights=distance;, score=-0.930 total time=   0.0s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=11, p=1, weights=distance;, score=-0.664 total time=   0.0s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=11, p=1, weights=distance;, score=-0.638 total time=   0.0s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=11, p=1, weights=distance;, score=-0.653 total time=   0.0s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=11, p=1, weights=distance;, score=-0.586 total time=   0.0s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=11, p=1, weights=distance;, score=-0.716 total time=   0.0s\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=11, p=2, weights=uniform;, score=-0.818 total time=   0.0s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=11, p=2, weights=uniform;, score=-1.092 total time=   0.0s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=11, p=2, weights=uniform;, score=-1.323 total time=   0.0s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=11, p=2, weights=uniform;, score=-1.063 total time=   0.0s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=11, p=2, weights=uniform;, score=-1.125 total time=   0.0s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=11, p=2, weights=uniform;, score=-0.901 total time=   0.0s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=11, p=2, weights=uniform;, score=-0.956 total time=   0.0s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=11, p=2, weights=uniform;, score=-1.037 total time=   0.0s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=11, p=2, weights=uniform;, score=-0.739 total time=   0.0s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=11, p=2, weights=uniform;, score=-0.939 total time=   0.0s\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=11, p=2, weights=distance;, score=-0.565 total time=   0.0s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=11, p=2, weights=distance;, score=-0.771 total time=   0.0s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=11, p=2, weights=distance;, score=-0.878 total time=   0.0s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=11, p=2, weights=distance;, score=-0.877 total time=   0.0s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=11, p=2, weights=distance;, score=-0.920 total time=   0.0s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=11, p=2, weights=distance;, score=-0.688 total time=   0.0s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=11, p=2, weights=distance;, score=-0.648 total time=   0.0s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=11, p=2, weights=distance;, score=-0.651 total time=   0.0s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=11, p=2, weights=distance;, score=-0.587 total time=   0.0s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=11, p=2, weights=distance;, score=-0.676 total time=   0.0s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=3, p=1, weights=uniform;, score=-0.770 total time=   0.3s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=3, p=1, weights=uniform;, score=-0.820 total time=   0.3s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=3, p=1, weights=uniform;, score=-0.941 total time=   0.3s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=3, p=1, weights=uniform;, score=-1.047 total time=   0.3s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=3, p=1, weights=uniform;, score=-1.235 total time=   0.3s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=3, p=1, weights=uniform;, score=-0.761 total time=   0.3s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=3, p=1, weights=uniform;, score=-0.728 total time=   0.3s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=3, p=1, weights=uniform;, score=-0.711 total time=   0.3s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=3, p=1, weights=uniform;, score=-0.750 total time=   0.3s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=3, p=1, weights=uniform;, score=-0.800 total time=   0.3s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=3, p=1, weights=distance;, score=-0.647 total time=   0.3s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=3, p=1, weights=distance;, score=-0.696 total time=   0.3s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=3, p=1, weights=distance;, score=-0.797 total time=   0.3s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=3, p=1, weights=distance;, score=-0.928 total time=   0.3s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=3, p=1, weights=distance;, score=-1.181 total time=   0.3s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=3, p=1, weights=distance;, score=-0.681 total time=   0.3s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=3, p=1, weights=distance;, score=-0.626 total time=   0.3s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=3, p=1, weights=distance;, score=-0.547 total time=   0.3s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=3, p=1, weights=distance;, score=-0.674 total time=   0.3s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=3, p=1, weights=distance;, score=-0.714 total time=   0.3s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=3, p=2, weights=uniform;, score=-0.791 total time=   0.3s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=3, p=2, weights=uniform;, score=-0.844 total time=   0.3s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=3, p=2, weights=uniform;, score=-0.924 total time=   0.3s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=3, p=2, weights=uniform;, score=-1.012 total time=   0.3s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=3, p=2, weights=uniform;, score=-1.241 total time=   0.3s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=3, p=2, weights=uniform;, score=-0.726 total time=   0.3s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=3, p=2, weights=uniform;, score=-0.678 total time=   0.3s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=3, p=2, weights=uniform;, score=-0.641 total time=   0.3s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=3, p=2, weights=uniform;, score=-0.746 total time=   0.3s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=3, p=2, weights=uniform;, score=-0.760 total time=   0.3s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=3, p=2, weights=distance;, score=-0.661 total time=   0.3s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=3, p=2, weights=distance;, score=-0.696 total time=   0.3s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=3, p=2, weights=distance;, score=-0.778 total time=   0.3s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=3, p=2, weights=distance;, score=-0.908 total time=   0.3s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=3, p=2, weights=distance;, score=-1.179 total time=   0.3s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=3, p=2, weights=distance;, score=-0.652 total time=   0.3s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=3, p=2, weights=distance;, score=-0.611 total time=   0.3s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=3, p=2, weights=distance;, score=-0.472 total time=   0.3s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=3, p=2, weights=distance;, score=-0.683 total time=   0.3s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=3, p=2, weights=distance;, score=-0.688 total time=   0.3s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform;, score=-0.731 total time=   0.3s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform;, score=-0.961 total time=   0.3s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform;, score=-1.051 total time=   0.3s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform;, score=-1.062 total time=   0.3s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform;, score=-1.171 total time=   0.3s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform;, score=-0.753 total time=   0.3s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform;, score=-0.744 total time=   0.3s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform;, score=-0.885 total time=   0.3s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform;, score=-0.729 total time=   0.3s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform;, score=-0.793 total time=   0.3s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance;, score=-0.559 total time=   0.3s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance;, score=-0.686 total time=   0.3s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance;, score=-0.861 total time=   0.3s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance;, score=-0.918 total time=   0.3s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance;, score=-1.049 total time=   0.3s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance;, score=-0.653 total time=   0.3s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance;, score=-0.596 total time=   0.3s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance;, score=-0.598 total time=   0.3s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance;, score=-0.634 total time=   0.3s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance;, score=-0.643 total time=   0.3s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform;, score=-0.723 total time=   0.3s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform;, score=-0.957 total time=   0.3s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform;, score=-1.060 total time=   0.3s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform;, score=-1.080 total time=   0.3s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform;, score=-1.191 total time=   0.3s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform;, score=-0.713 total time=   0.3s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform;, score=-0.725 total time=   0.3s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform;, score=-0.874 total time=   0.3s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform;, score=-0.740 total time=   0.3s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform;, score=-0.808 total time=   0.3s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance;, score=-0.542 total time=   0.3s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance;, score=-0.717 total time=   0.3s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance;, score=-0.862 total time=   0.3s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance;, score=-0.937 total time=   0.3s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance;, score=-1.072 total time=   0.3s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance;, score=-0.642 total time=   0.3s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance;, score=-0.577 total time=   0.3s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance;, score=-0.601 total time=   0.3s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance;, score=-0.639 total time=   0.3s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance;, score=-0.661 total time=   0.3s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=7, p=1, weights=uniform;, score=-0.754 total time=   0.3s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=7, p=1, weights=uniform;, score=-1.008 total time=   0.3s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=7, p=1, weights=uniform;, score=-1.176 total time=   0.3s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=7, p=1, weights=uniform;, score=-1.143 total time=   0.3s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=7, p=1, weights=uniform;, score=-1.138 total time=   0.3s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=7, p=1, weights=uniform;, score=-0.772 total time=   0.3s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=7, p=1, weights=uniform;, score=-0.846 total time=   0.3s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=7, p=1, weights=uniform;, score=-0.937 total time=   0.3s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=7, p=1, weights=uniform;, score=-0.728 total time=   0.3s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=7, p=1, weights=uniform;, score=-0.833 total time=   0.3s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=7, p=1, weights=distance;, score=-0.566 total time=   0.3s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=7, p=1, weights=distance;, score=-0.722 total time=   0.3s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=7, p=1, weights=distance;, score=-0.922 total time=   0.3s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=7, p=1, weights=distance;, score=-0.958 total time=   0.3s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=7, p=1, weights=distance;, score=-0.989 total time=   0.3s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=7, p=1, weights=distance;, score=-0.637 total time=   0.3s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=7, p=1, weights=distance;, score=-0.635 total time=   0.3s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=7, p=1, weights=distance;, score=-0.620 total time=   0.3s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=7, p=1, weights=distance;, score=-0.606 total time=   0.3s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=7, p=1, weights=distance;, score=-0.652 total time=   0.3s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=7, p=2, weights=uniform;, score=-0.783 total time=   0.3s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=7, p=2, weights=uniform;, score=-1.102 total time=   0.3s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=7, p=2, weights=uniform;, score=-1.192 total time=   0.3s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=7, p=2, weights=uniform;, score=-1.152 total time=   0.3s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=7, p=2, weights=uniform;, score=-1.125 total time=   0.3s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=7, p=2, weights=uniform;, score=-0.797 total time=   0.3s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=7, p=2, weights=uniform;, score=-0.825 total time=   0.3s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=7, p=2, weights=uniform;, score=-0.950 total time=   0.3s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=7, p=2, weights=uniform;, score=-0.743 total time=   0.3s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=7, p=2, weights=uniform;, score=-0.889 total time=   0.2s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=7, p=2, weights=distance;, score=-0.580 total time=   0.3s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=7, p=2, weights=distance;, score=-0.788 total time=   0.3s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=7, p=2, weights=distance;, score=-0.922 total time=   0.3s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=7, p=2, weights=distance;, score=-0.963 total time=   0.3s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=7, p=2, weights=distance;, score=-0.975 total time=   0.3s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=7, p=2, weights=distance;, score=-0.661 total time=   0.3s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=7, p=2, weights=distance;, score=-0.629 total time=   0.3s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=7, p=2, weights=distance;, score=-0.620 total time=   0.3s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=7, p=2, weights=distance;, score=-0.617 total time=   0.3s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=7, p=2, weights=distance;, score=-0.693 total time=   0.3s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=9, p=1, weights=uniform;, score=-0.794 total time=   0.3s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=9, p=1, weights=uniform;, score=-1.078 total time=   0.3s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=9, p=1, weights=uniform;, score=-1.271 total time=   0.3s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=9, p=1, weights=uniform;, score=-1.090 total time=   0.3s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=9, p=1, weights=uniform;, score=-1.117 total time=   0.3s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=9, p=1, weights=uniform;, score=-0.838 total time=   0.3s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=9, p=1, weights=uniform;, score=-0.878 total time=   0.3s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=9, p=1, weights=uniform;, score=-0.966 total time=   0.3s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=9, p=1, weights=uniform;, score=-0.729 total time=   0.3s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=9, p=1, weights=uniform;, score=-0.874 total time=   0.3s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=9, p=1, weights=distance;, score=-0.576 total time=   0.3s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=9, p=1, weights=distance;, score=-0.757 total time=   0.3s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=9, p=1, weights=distance;, score=-0.919 total time=   0.3s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=9, p=1, weights=distance;, score=-0.903 total time=   0.3s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=9, p=1, weights=distance;, score=-0.953 total time=   0.3s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=9, p=1, weights=distance;, score=-0.659 total time=   0.3s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=9, p=1, weights=distance;, score=-0.639 total time=   0.3s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=9, p=1, weights=distance;, score=-0.630 total time=   0.4s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=9, p=1, weights=distance;, score=-0.600 total time=   0.3s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=9, p=1, weights=distance;, score=-0.653 total time=   0.3s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=9, p=2, weights=uniform;, score=-0.806 total time=   0.3s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=9, p=2, weights=uniform;, score=-1.095 total time=   0.3s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=9, p=2, weights=uniform;, score=-1.253 total time=   0.3s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=9, p=2, weights=uniform;, score=-1.080 total time=   0.3s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=9, p=2, weights=uniform;, score=-1.098 total time=   0.3s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=9, p=2, weights=uniform;, score=-0.866 total time=   0.3s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=9, p=2, weights=uniform;, score=-0.905 total time=   0.3s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=9, p=2, weights=uniform;, score=-0.933 total time=   0.3s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=9, p=2, weights=uniform;, score=-0.722 total time=   0.3s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=9, p=2, weights=uniform;, score=-0.896 total time=   0.3s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=9, p=2, weights=distance;, score=-0.564 total time=   0.3s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=9, p=2, weights=distance;, score=-0.764 total time=   0.3s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=9, p=2, weights=distance;, score=-0.881 total time=   0.2s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=9, p=2, weights=distance;, score=-0.887 total time=   0.2s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=9, p=2, weights=distance;, score=-0.923 total time=   0.2s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=9, p=2, weights=distance;, score=-0.678 total time=   0.2s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=9, p=2, weights=distance;, score=-0.651 total time=   0.3s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=9, p=2, weights=distance;, score=-0.605 total time=   0.2s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=9, p=2, weights=distance;, score=-0.594 total time=   0.2s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=9, p=2, weights=distance;, score=-0.666 total time=   0.2s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=11, p=1, weights=uniform;, score=-0.804 total time=   0.3s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=11, p=1, weights=uniform;, score=-1.089 total time=   0.3s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=11, p=1, weights=uniform;, score=-1.331 total time=   0.3s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=11, p=1, weights=uniform;, score=-1.066 total time=   0.3s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=11, p=1, weights=uniform;, score=-1.131 total time=   0.2s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=11, p=1, weights=uniform;, score=-0.891 total time=   0.2s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=11, p=1, weights=uniform;, score=-0.926 total time=   0.3s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=11, p=1, weights=uniform;, score=-1.032 total time=   0.3s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=11, p=1, weights=uniform;, score=-0.735 total time=   0.3s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=11, p=1, weights=uniform;, score=-0.977 total time=   0.3s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=11, p=1, weights=distance;, score=-0.559 total time=   0.3s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=11, p=1, weights=distance;, score=-0.777 total time=   0.3s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=11, p=1, weights=distance;, score=-0.900 total time=   0.3s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=11, p=1, weights=distance;, score=-0.880 total time=   0.3s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=11, p=1, weights=distance;, score=-0.933 total time=   0.2s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=11, p=1, weights=distance;, score=-0.667 total time=   0.3s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=11, p=1, weights=distance;, score=-0.639 total time=   0.3s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=11, p=1, weights=distance;, score=-0.653 total time=   0.3s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=11, p=1, weights=distance;, score=-0.586 total time=   0.3s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=11, p=1, weights=distance;, score=-0.716 total time=   0.3s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=11, p=2, weights=uniform;, score=-0.818 total time=   0.3s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=11, p=2, weights=uniform;, score=-1.093 total time=   0.3s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=11, p=2, weights=uniform;, score=-1.322 total time=   0.3s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=11, p=2, weights=uniform;, score=-1.065 total time=   0.3s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=11, p=2, weights=uniform;, score=-1.125 total time=   0.3s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=11, p=2, weights=uniform;, score=-0.901 total time=   0.3s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=11, p=2, weights=uniform;, score=-0.957 total time=   0.3s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=11, p=2, weights=uniform;, score=-1.038 total time=   0.3s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=11, p=2, weights=uniform;, score=-0.739 total time=   0.3s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=11, p=2, weights=uniform;, score=-0.939 total time=   0.3s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=11, p=2, weights=distance;, score=-0.563 total time=   0.2s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=11, p=2, weights=distance;, score=-0.771 total time=   0.3s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=11, p=2, weights=distance;, score=-0.877 total time=   0.3s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=11, p=2, weights=distance;, score=-0.880 total time=   0.3s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=11, p=2, weights=distance;, score=-0.920 total time=   0.3s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=11, p=2, weights=distance;, score=-0.691 total time=   0.3s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=11, p=2, weights=distance;, score=-0.650 total time=   0.3s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=11, p=2, weights=distance;, score=-0.650 total time=   0.3s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=11, p=2, weights=distance;, score=-0.587 total time=   0.3s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=11, p=2, weights=distance;, score=-0.676 total time=   0.3s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=3, p=1, weights=uniform;, score=-0.757 total time=   0.4s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=3, p=1, weights=uniform;, score=-0.820 total time=   0.4s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=3, p=1, weights=uniform;, score=-0.930 total time=   0.4s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=3, p=1, weights=uniform;, score=-1.047 total time=   0.3s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=3, p=1, weights=uniform;, score=-1.235 total time=   0.4s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=3, p=1, weights=uniform;, score=-0.761 total time=   0.4s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=3, p=1, weights=uniform;, score=-0.731 total time=   0.4s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=3, p=1, weights=uniform;, score=-0.711 total time=   0.4s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=3, p=1, weights=uniform;, score=-0.750 total time=   0.4s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=3, p=1, weights=uniform;, score=-0.800 total time=   0.4s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=3, p=1, weights=distance;, score=-0.636 total time=   0.4s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=3, p=1, weights=distance;, score=-0.696 total time=   0.4s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=3, p=1, weights=distance;, score=-0.787 total time=   0.4s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=3, p=1, weights=distance;, score=-0.928 total time=   0.4s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=3, p=1, weights=distance;, score=-1.181 total time=   0.4s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=3, p=1, weights=distance;, score=-0.681 total time=   0.4s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=3, p=1, weights=distance;, score=-0.629 total time=   0.4s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=3, p=1, weights=distance;, score=-0.547 total time=   0.4s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=3, p=1, weights=distance;, score=-0.674 total time=   0.4s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=3, p=1, weights=distance;, score=-0.715 total time=   0.4s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=3, p=2, weights=uniform;, score=-0.779 total time=   0.4s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=3, p=2, weights=uniform;, score=-0.844 total time=   0.5s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=3, p=2, weights=uniform;, score=-0.912 total time=   0.4s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=3, p=2, weights=uniform;, score=-1.012 total time=   0.5s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=3, p=2, weights=uniform;, score=-1.241 total time=   0.4s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=3, p=2, weights=uniform;, score=-0.726 total time=   0.4s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=3, p=2, weights=uniform;, score=-0.681 total time=   0.4s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=3, p=2, weights=uniform;, score=-0.655 total time=   0.4s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=3, p=2, weights=uniform;, score=-0.746 total time=   0.4s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=3, p=2, weights=uniform;, score=-0.760 total time=   0.4s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=3, p=2, weights=distance;, score=-0.650 total time=   0.5s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=3, p=2, weights=distance;, score=-0.696 total time=   0.5s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=3, p=2, weights=distance;, score=-0.768 total time=   0.4s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=3, p=2, weights=distance;, score=-0.908 total time=   0.5s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=3, p=2, weights=distance;, score=-1.179 total time=   0.4s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=3, p=2, weights=distance;, score=-0.652 total time=   0.4s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=3, p=2, weights=distance;, score=-0.614 total time=   0.5s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=3, p=2, weights=distance;, score=-0.478 total time=   0.5s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=3, p=2, weights=distance;, score=-0.683 total time=   0.4s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=3, p=2, weights=distance;, score=-0.689 total time=   0.4s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform;, score=-0.732 total time=   0.4s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform;, score=-0.961 total time=   0.4s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform;, score=-1.052 total time=   0.4s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform;, score=-1.062 total time=   0.4s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform;, score=-1.171 total time=   0.4s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform;, score=-0.750 total time=   0.4s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform;, score=-0.741 total time=   0.4s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform;, score=-0.885 total time=   0.4s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform;, score=-0.727 total time=   0.4s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform;, score=-0.794 total time=   0.3s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance;, score=-0.559 total time=   0.4s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance;, score=-0.686 total time=   0.4s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance;, score=-0.861 total time=   0.5s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance;, score=-0.918 total time=   0.4s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance;, score=-1.049 total time=   0.4s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance;, score=-0.650 total time=   0.4s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance;, score=-0.596 total time=   0.4s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance;, score=-0.598 total time=   0.4s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance;, score=-0.633 total time=   0.4s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance;, score=-0.643 total time=   0.3s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform;, score=-0.717 total time=   0.5s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform;, score=-0.961 total time=   0.5s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform;, score=-1.062 total time=   0.4s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform;, score=-1.080 total time=   0.5s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform;, score=-1.191 total time=   0.5s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform;, score=-0.710 total time=   0.5s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform;, score=-0.724 total time=   0.5s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform;, score=-0.874 total time=   0.5s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform;, score=-0.740 total time=   0.5s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform;, score=-0.808 total time=   0.5s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance;, score=-0.542 total time=   0.5s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance;, score=-0.717 total time=   0.5s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance;, score=-0.862 total time=   0.4s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance;, score=-0.937 total time=   0.5s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance;, score=-1.072 total time=   0.4s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance;, score=-0.639 total time=   0.4s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance;, score=-0.577 total time=   0.5s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance;, score=-0.601 total time=   0.5s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance;, score=-0.639 total time=   0.5s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance;, score=-0.661 total time=   0.5s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=7, p=1, weights=uniform;, score=-0.754 total time=   0.4s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=7, p=1, weights=uniform;, score=-1.008 total time=   0.4s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=7, p=1, weights=uniform;, score=-1.176 total time=   0.4s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=7, p=1, weights=uniform;, score=-1.143 total time=   0.4s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=7, p=1, weights=uniform;, score=-1.134 total time=   0.4s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=7, p=1, weights=uniform;, score=-0.772 total time=   0.4s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=7, p=1, weights=uniform;, score=-0.844 total time=   0.4s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=7, p=1, weights=uniform;, score=-0.937 total time=   0.4s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=7, p=1, weights=uniform;, score=-0.728 total time=   0.4s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=7, p=1, weights=uniform;, score=-0.833 total time=   0.4s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=7, p=1, weights=distance;, score=-0.566 total time=   0.4s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=7, p=1, weights=distance;, score=-0.722 total time=   0.4s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=7, p=1, weights=distance;, score=-0.922 total time=   0.4s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=7, p=1, weights=distance;, score=-0.958 total time=   0.4s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=7, p=1, weights=distance;, score=-0.985 total time=   0.4s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=7, p=1, weights=distance;, score=-0.637 total time=   0.4s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=7, p=1, weights=distance;, score=-0.634 total time=   0.4s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=7, p=1, weights=distance;, score=-0.620 total time=   0.3s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=7, p=1, weights=distance;, score=-0.606 total time=   0.4s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=7, p=1, weights=distance;, score=-0.652 total time=   0.4s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=7, p=2, weights=uniform;, score=-0.783 total time=   0.5s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=7, p=2, weights=uniform;, score=-1.102 total time=   0.5s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=7, p=2, weights=uniform;, score=-1.194 total time=   0.5s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=7, p=2, weights=uniform;, score=-1.151 total time=   0.4s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=7, p=2, weights=uniform;, score=-1.125 total time=   0.5s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=7, p=2, weights=uniform;, score=-0.797 total time=   0.5s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=7, p=2, weights=uniform;, score=-0.827 total time=   0.5s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=7, p=2, weights=uniform;, score=-0.949 total time=   0.5s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=7, p=2, weights=uniform;, score=-0.743 total time=   0.5s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=7, p=2, weights=uniform;, score=-0.882 total time=   0.5s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=7, p=2, weights=distance;, score=-0.580 total time=   0.5s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=7, p=2, weights=distance;, score=-0.788 total time=   0.5s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=7, p=2, weights=distance;, score=-0.922 total time=   0.5s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=7, p=2, weights=distance;, score=-0.962 total time=   0.4s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=7, p=2, weights=distance;, score=-0.975 total time=   0.5s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=7, p=2, weights=distance;, score=-0.661 total time=   0.4s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=7, p=2, weights=distance;, score=-0.628 total time=   0.5s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=7, p=2, weights=distance;, score=-0.619 total time=   0.4s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=7, p=2, weights=distance;, score=-0.617 total time=   0.5s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=7, p=2, weights=distance;, score=-0.687 total time=   0.5s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=9, p=1, weights=uniform;, score=-0.794 total time=   0.4s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=9, p=1, weights=uniform;, score=-1.078 total time=   0.4s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=9, p=1, weights=uniform;, score=-1.269 total time=   0.4s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=9, p=1, weights=uniform;, score=-1.096 total time=   0.4s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=9, p=1, weights=uniform;, score=-1.114 total time=   0.4s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=9, p=1, weights=uniform;, score=-0.838 total time=   0.4s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=9, p=1, weights=uniform;, score=-0.878 total time=   0.4s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=9, p=1, weights=uniform;, score=-0.966 total time=   0.4s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=9, p=1, weights=uniform;, score=-0.729 total time=   0.4s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=9, p=1, weights=uniform;, score=-0.874 total time=   0.4s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=9, p=1, weights=distance;, score=-0.576 total time=   0.4s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=9, p=1, weights=distance;, score=-0.757 total time=   0.4s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=9, p=1, weights=distance;, score=-0.919 total time=   0.4s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=9, p=1, weights=distance;, score=-0.909 total time=   0.4s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=9, p=1, weights=distance;, score=-0.950 total time=   0.4s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=9, p=1, weights=distance;, score=-0.659 total time=   0.4s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=9, p=1, weights=distance;, score=-0.639 total time=   0.4s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=9, p=1, weights=distance;, score=-0.630 total time=   0.4s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=9, p=1, weights=distance;, score=-0.600 total time=   0.4s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=9, p=1, weights=distance;, score=-0.652 total time=   0.4s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=9, p=2, weights=uniform;, score=-0.806 total time=   0.5s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=9, p=2, weights=uniform;, score=-1.095 total time=   0.5s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=9, p=2, weights=uniform;, score=-1.249 total time=   0.4s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=9, p=2, weights=uniform;, score=-1.081 total time=   0.5s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=9, p=2, weights=uniform;, score=-1.095 total time=   0.5s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=9, p=2, weights=uniform;, score=-0.866 total time=   0.5s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=9, p=2, weights=uniform;, score=-0.901 total time=   0.5s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=9, p=2, weights=uniform;, score=-0.933 total time=   0.5s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=9, p=2, weights=uniform;, score=-0.723 total time=   0.5s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=9, p=2, weights=uniform;, score=-0.896 total time=   0.5s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=9, p=2, weights=distance;, score=-0.564 total time=   0.5s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=9, p=2, weights=distance;, score=-0.764 total time=   0.5s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=9, p=2, weights=distance;, score=-0.881 total time=   0.5s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=9, p=2, weights=distance;, score=-0.887 total time=   0.5s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=9, p=2, weights=distance;, score=-0.920 total time=   0.5s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=9, p=2, weights=distance;, score=-0.678 total time=   0.5s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=9, p=2, weights=distance;, score=-0.648 total time=   0.5s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=9, p=2, weights=distance;, score=-0.605 total time=   0.5s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=9, p=2, weights=distance;, score=-0.595 total time=   0.5s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=9, p=2, weights=distance;, score=-0.666 total time=   0.5s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=11, p=1, weights=uniform;, score=-0.803 total time=   0.4s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=11, p=1, weights=uniform;, score=-1.089 total time=   0.4s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=11, p=1, weights=uniform;, score=-1.330 total time=   0.4s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=11, p=1, weights=uniform;, score=-1.067 total time=   0.4s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=11, p=1, weights=uniform;, score=-1.128 total time=   0.4s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=11, p=1, weights=uniform;, score=-0.891 total time=   0.4s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=11, p=1, weights=uniform;, score=-0.926 total time=   0.4s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=11, p=1, weights=uniform;, score=-1.032 total time=   0.4s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=11, p=1, weights=uniform;, score=-0.735 total time=   0.4s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=11, p=1, weights=uniform;, score=-0.977 total time=   0.4s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=11, p=1, weights=distance;, score=-0.559 total time=   0.3s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=11, p=1, weights=distance;, score=-0.776 total time=   0.3s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=11, p=1, weights=distance;, score=-0.899 total time=   0.4s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=11, p=1, weights=distance;, score=-0.880 total time=   0.4s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=11, p=1, weights=distance;, score=-0.930 total time=   0.4s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=11, p=1, weights=distance;, score=-0.667 total time=   0.4s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=11, p=1, weights=distance;, score=-0.639 total time=   0.4s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=11, p=1, weights=distance;, score=-0.653 total time=   0.4s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=11, p=1, weights=distance;, score=-0.586 total time=   0.4s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=11, p=1, weights=distance;, score=-0.716 total time=   0.4s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=11, p=2, weights=uniform;, score=-0.817 total time=   0.5s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=11, p=2, weights=uniform;, score=-1.092 total time=   0.5s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=11, p=2, weights=uniform;, score=-1.323 total time=   0.5s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=11, p=2, weights=uniform;, score=-1.066 total time=   0.5s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=11, p=2, weights=uniform;, score=-1.125 total time=   0.4s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=11, p=2, weights=uniform;, score=-0.902 total time=   0.5s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=11, p=2, weights=uniform;, score=-0.957 total time=   0.4s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=11, p=2, weights=uniform;, score=-1.039 total time=   0.5s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=11, p=2, weights=uniform;, score=-0.739 total time=   0.4s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=11, p=2, weights=uniform;, score=-0.939 total time=   0.4s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=11, p=2, weights=distance;, score=-0.563 total time=   0.5s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=11, p=2, weights=distance;, score=-0.771 total time=   0.4s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=11, p=2, weights=distance;, score=-0.878 total time=   0.5s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=11, p=2, weights=distance;, score=-0.880 total time=   0.5s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=11, p=2, weights=distance;, score=-0.920 total time=   0.5s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=11, p=2, weights=distance;, score=-0.691 total time=   0.5s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=11, p=2, weights=distance;, score=-0.650 total time=   0.5s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=11, p=2, weights=distance;, score=-0.650 total time=   0.5s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=11, p=2, weights=distance;, score=-0.587 total time=   0.5s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=11, p=2, weights=distance;, score=-0.676 total time=   0.5s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=3, p=1, weights=uniform;, score=-0.767 total time=   0.0s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=3, p=1, weights=uniform;, score=-0.820 total time=   0.0s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=3, p=1, weights=uniform;, score=-0.942 total time=   0.0s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=3, p=1, weights=uniform;, score=-1.047 total time=   0.0s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=3, p=1, weights=uniform;, score=-1.235 total time=   0.0s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=3, p=1, weights=uniform;, score=-0.761 total time=   0.0s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=3, p=1, weights=uniform;, score=-0.722 total time=   0.0s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=3, p=1, weights=uniform;, score=-0.711 total time=   0.0s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=3, p=1, weights=uniform;, score=-0.750 total time=   0.1s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=3, p=1, weights=uniform;, score=-0.793 total time=   0.0s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=3, p=1, weights=distance;, score=-0.644 total time=   0.1s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=3, p=1, weights=distance;, score=-0.696 total time=   0.0s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=3, p=1, weights=distance;, score=-0.799 total time=   0.0s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=3, p=1, weights=distance;, score=-0.928 total time=   0.1s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=3, p=1, weights=distance;, score=-1.181 total time=   0.0s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=3, p=1, weights=distance;, score=-0.681 total time=   0.0s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=3, p=1, weights=distance;, score=-0.621 total time=   0.0s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=3, p=1, weights=distance;, score=-0.547 total time=   0.0s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=3, p=1, weights=distance;, score=-0.674 total time=   0.0s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=3, p=1, weights=distance;, score=-0.707 total time=   0.0s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=3, p=2, weights=uniform;, score=-0.788 total time=   0.0s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=3, p=2, weights=uniform;, score=-0.844 total time=   0.0s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=3, p=2, weights=uniform;, score=-0.912 total time=   0.0s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=3, p=2, weights=uniform;, score=-1.012 total time=   0.0s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=3, p=2, weights=uniform;, score=-1.241 total time=   0.0s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=3, p=2, weights=uniform;, score=-0.726 total time=   0.0s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=3, p=2, weights=uniform;, score=-0.682 total time=   0.0s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=3, p=2, weights=uniform;, score=-0.655 total time=   0.0s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=3, p=2, weights=uniform;, score=-0.729 total time=   0.0s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=3, p=2, weights=uniform;, score=-0.755 total time=   0.0s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=3, p=2, weights=distance;, score=-0.659 total time=   0.0s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=3, p=2, weights=distance;, score=-0.696 total time=   0.0s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=3, p=2, weights=distance;, score=-0.768 total time=   0.0s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=3, p=2, weights=distance;, score=-0.908 total time=   0.0s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=3, p=2, weights=distance;, score=-1.179 total time=   0.0s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=3, p=2, weights=distance;, score=-0.651 total time=   0.0s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=3, p=2, weights=distance;, score=-0.614 total time=   0.0s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=3, p=2, weights=distance;, score=-0.478 total time=   0.0s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=3, p=2, weights=distance;, score=-0.668 total time=   0.0s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=3, p=2, weights=distance;, score=-0.682 total time=   0.0s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=5, p=1, weights=uniform;, score=-0.736 total time=   0.1s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=5, p=1, weights=uniform;, score=-0.961 total time=   0.0s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=5, p=1, weights=uniform;, score=-1.059 total time=   0.1s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=5, p=1, weights=uniform;, score=-1.070 total time=   0.0s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=5, p=1, weights=uniform;, score=-1.171 total time=   0.1s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=5, p=1, weights=uniform;, score=-0.753 total time=   0.1s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=5, p=1, weights=uniform;, score=-0.743 total time=   0.0s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=5, p=1, weights=uniform;, score=-0.885 total time=   0.0s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=5, p=1, weights=uniform;, score=-0.727 total time=   0.0s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=5, p=1, weights=uniform;, score=-0.797 total time=   0.0s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=5, p=1, weights=distance;, score=-0.559 total time=   0.0s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=5, p=1, weights=distance;, score=-0.686 total time=   0.0s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=5, p=1, weights=distance;, score=-0.868 total time=   0.0s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=5, p=1, weights=distance;, score=-0.927 total time=   0.0s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=5, p=1, weights=distance;, score=-1.049 total time=   0.0s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=5, p=1, weights=distance;, score=-0.653 total time=   0.0s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=5, p=1, weights=distance;, score=-0.596 total time=   0.0s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=5, p=1, weights=distance;, score=-0.598 total time=   0.0s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=5, p=1, weights=distance;, score=-0.634 total time=   0.0s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=5, p=1, weights=distance;, score=-0.647 total time=   0.0s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=5, p=2, weights=uniform;, score=-0.723 total time=   0.0s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=5, p=2, weights=uniform;, score=-0.961 total time=   0.0s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=5, p=2, weights=uniform;, score=-1.063 total time=   0.0s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=5, p=2, weights=uniform;, score=-1.080 total time=   0.0s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=5, p=2, weights=uniform;, score=-1.186 total time=   0.0s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=5, p=2, weights=uniform;, score=-0.707 total time=   0.0s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=5, p=2, weights=uniform;, score=-0.725 total time=   0.0s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=5, p=2, weights=uniform;, score=-0.867 total time=   0.0s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=5, p=2, weights=uniform;, score=-0.727 total time=   0.0s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=5, p=2, weights=uniform;, score=-0.808 total time=   0.0s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=5, p=2, weights=distance;, score=-0.545 total time=   0.0s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=5, p=2, weights=distance;, score=-0.717 total time=   0.0s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=5, p=2, weights=distance;, score=-0.863 total time=   0.0s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=5, p=2, weights=distance;, score=-0.938 total time=   0.0s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=5, p=2, weights=distance;, score=-1.067 total time=   0.0s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=5, p=2, weights=distance;, score=-0.634 total time=   0.0s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=5, p=2, weights=distance;, score=-0.576 total time=   0.0s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=5, p=2, weights=distance;, score=-0.597 total time=   0.0s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=5, p=2, weights=distance;, score=-0.633 total time=   0.0s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=5, p=2, weights=distance;, score=-0.661 total time=   0.0s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=7, p=1, weights=uniform;, score=-0.754 total time=   0.0s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=7, p=1, weights=uniform;, score=-1.008 total time=   0.1s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=7, p=1, weights=uniform;, score=-1.180 total time=   0.0s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=7, p=1, weights=uniform;, score=-1.141 total time=   0.0s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=7, p=1, weights=uniform;, score=-1.133 total time=   0.1s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=7, p=1, weights=uniform;, score=-0.772 total time=   0.0s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=7, p=1, weights=uniform;, score=-0.845 total time=   0.0s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=7, p=1, weights=uniform;, score=-0.937 total time=   0.0s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=7, p=1, weights=uniform;, score=-0.728 total time=   0.1s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=7, p=1, weights=uniform;, score=-0.830 total time=   0.0s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=7, p=1, weights=distance;, score=-0.566 total time=   0.0s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=7, p=1, weights=distance;, score=-0.722 total time=   0.0s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=7, p=1, weights=distance;, score=-0.925 total time=   0.0s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=7, p=1, weights=distance;, score=-0.956 total time=   0.0s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=7, p=1, weights=distance;, score=-0.985 total time=   0.0s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=7, p=1, weights=distance;, score=-0.637 total time=   0.0s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=7, p=1, weights=distance;, score=-0.635 total time=   0.0s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=7, p=1, weights=distance;, score=-0.620 total time=   0.1s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=7, p=1, weights=distance;, score=-0.606 total time=   0.0s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=7, p=1, weights=distance;, score=-0.652 total time=   0.0s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=7, p=2, weights=uniform;, score=-0.783 total time=   0.0s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=7, p=2, weights=uniform;, score=-1.102 total time=   0.0s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=7, p=2, weights=uniform;, score=-1.194 total time=   0.0s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=7, p=2, weights=uniform;, score=-1.152 total time=   0.0s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=7, p=2, weights=uniform;, score=-1.121 total time=   0.0s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=7, p=2, weights=uniform;, score=-0.797 total time=   0.0s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=7, p=2, weights=uniform;, score=-0.823 total time=   0.0s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=7, p=2, weights=uniform;, score=-0.948 total time=   0.0s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=7, p=2, weights=uniform;, score=-0.743 total time=   0.0s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=7, p=2, weights=uniform;, score=-0.887 total time=   0.0s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=7, p=2, weights=distance;, score=-0.582 total time=   0.0s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=7, p=2, weights=distance;, score=-0.788 total time=   0.0s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=7, p=2, weights=distance;, score=-0.922 total time=   0.0s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=7, p=2, weights=distance;, score=-0.962 total time=   0.0s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=7, p=2, weights=distance;, score=-0.971 total time=   0.0s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=7, p=2, weights=distance;, score=-0.658 total time=   0.0s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=7, p=2, weights=distance;, score=-0.628 total time=   0.0s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=7, p=2, weights=distance;, score=-0.619 total time=   0.0s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=7, p=2, weights=distance;, score=-0.617 total time=   0.0s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=7, p=2, weights=distance;, score=-0.690 total time=   0.0s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=9, p=1, weights=uniform;, score=-0.794 total time=   0.1s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=9, p=1, weights=uniform;, score=-1.080 total time=   0.0s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=9, p=1, weights=uniform;, score=-1.268 total time=   0.0s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=9, p=1, weights=uniform;, score=-1.091 total time=   0.1s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=9, p=1, weights=uniform;, score=-1.113 total time=   0.0s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=9, p=1, weights=uniform;, score=-0.838 total time=   0.0s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=9, p=1, weights=uniform;, score=-0.879 total time=   0.0s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=9, p=1, weights=uniform;, score=-0.965 total time=   0.0s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=9, p=1, weights=uniform;, score=-0.729 total time=   0.0s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=9, p=1, weights=uniform;, score=-0.878 total time=   0.0s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=9, p=1, weights=distance;, score=-0.576 total time=   0.0s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=9, p=1, weights=distance;, score=-0.758 total time=   0.0s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=9, p=1, weights=distance;, score=-0.919 total time=   0.0s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=9, p=1, weights=distance;, score=-0.903 total time=   0.1s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=9, p=1, weights=distance;, score=-0.950 total time=   0.0s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=9, p=1, weights=distance;, score=-0.659 total time=   0.1s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=9, p=1, weights=distance;, score=-0.639 total time=   0.0s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=9, p=1, weights=distance;, score=-0.629 total time=   0.0s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=9, p=1, weights=distance;, score=-0.600 total time=   0.0s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=9, p=1, weights=distance;, score=-0.653 total time=   0.0s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=9, p=2, weights=uniform;, score=-0.806 total time=   0.0s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=9, p=2, weights=uniform;, score=-1.095 total time=   0.0s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=9, p=2, weights=uniform;, score=-1.249 total time=   0.0s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=9, p=2, weights=uniform;, score=-1.075 total time=   0.0s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=9, p=2, weights=uniform;, score=-1.095 total time=   0.0s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=9, p=2, weights=uniform;, score=-0.862 total time=   0.0s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=9, p=2, weights=uniform;, score=-0.899 total time=   0.0s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=9, p=2, weights=uniform;, score=-0.932 total time=   0.0s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=9, p=2, weights=uniform;, score=-0.722 total time=   0.0s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=9, p=2, weights=uniform;, score=-0.899 total time=   0.0s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=9, p=2, weights=distance;, score=-0.566 total time=   0.0s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=9, p=2, weights=distance;, score=-0.764 total time=   0.0s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=9, p=2, weights=distance;, score=-0.881 total time=   0.0s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=9, p=2, weights=distance;, score=-0.882 total time=   0.0s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=9, p=2, weights=distance;, score=-0.920 total time=   0.0s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=9, p=2, weights=distance;, score=-0.673 total time=   0.0s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=9, p=2, weights=distance;, score=-0.649 total time=   0.0s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=9, p=2, weights=distance;, score=-0.605 total time=   0.0s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=9, p=2, weights=distance;, score=-0.594 total time=   0.0s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=9, p=2, weights=distance;, score=-0.665 total time=   0.0s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=11, p=1, weights=uniform;, score=-0.803 total time=   0.1s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=11, p=1, weights=uniform;, score=-1.088 total time=   0.0s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=11, p=1, weights=uniform;, score=-1.330 total time=   0.0s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=11, p=1, weights=uniform;, score=-1.065 total time=   0.0s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=11, p=1, weights=uniform;, score=-1.128 total time=   0.0s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=11, p=1, weights=uniform;, score=-0.888 total time=   0.0s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=11, p=1, weights=uniform;, score=-0.925 total time=   0.0s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=11, p=1, weights=uniform;, score=-1.033 total time=   0.1s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=11, p=1, weights=uniform;, score=-0.735 total time=   0.0s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=11, p=1, weights=uniform;, score=-0.976 total time=   0.0s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=11, p=1, weights=distance;, score=-0.559 total time=   0.0s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=11, p=1, weights=distance;, score=-0.776 total time=   0.0s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=11, p=1, weights=distance;, score=-0.899 total time=   0.0s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=11, p=1, weights=distance;, score=-0.879 total time=   0.0s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=11, p=1, weights=distance;, score=-0.930 total time=   0.0s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=11, p=1, weights=distance;, score=-0.664 total time=   0.0s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=11, p=1, weights=distance;, score=-0.638 total time=   0.0s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=11, p=1, weights=distance;, score=-0.653 total time=   0.0s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=11, p=1, weights=distance;, score=-0.586 total time=   0.0s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=11, p=1, weights=distance;, score=-0.716 total time=   0.0s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=11, p=2, weights=uniform;, score=-0.818 total time=   0.0s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=11, p=2, weights=uniform;, score=-1.092 total time=   0.0s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=11, p=2, weights=uniform;, score=-1.323 total time=   0.0s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=11, p=2, weights=uniform;, score=-1.063 total time=   0.0s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=11, p=2, weights=uniform;, score=-1.125 total time=   0.0s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=11, p=2, weights=uniform;, score=-0.901 total time=   0.0s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=11, p=2, weights=uniform;, score=-0.956 total time=   0.0s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=11, p=2, weights=uniform;, score=-1.037 total time=   0.0s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=11, p=2, weights=uniform;, score=-0.739 total time=   0.0s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=11, p=2, weights=uniform;, score=-0.939 total time=   0.0s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=11, p=2, weights=distance;, score=-0.565 total time=   0.0s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=11, p=2, weights=distance;, score=-0.771 total time=   0.0s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=11, p=2, weights=distance;, score=-0.878 total time=   0.0s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=11, p=2, weights=distance;, score=-0.877 total time=   0.0s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=11, p=2, weights=distance;, score=-0.920 total time=   0.0s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=11, p=2, weights=distance;, score=-0.688 total time=   0.0s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=11, p=2, weights=distance;, score=-0.648 total time=   0.0s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=11, p=2, weights=distance;, score=-0.651 total time=   0.0s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=11, p=2, weights=distance;, score=-0.587 total time=   0.0s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=11, p=2, weights=distance;, score=-0.676 total time=   0.0s\n",
      "Best Parameters: {'algorithm': 'kd_tree', 'n_neighbors': 5, 'p': 1, 'weights': 'distance'}\n",
      "Mean Squared Error (MSE) on Test Set: 0.6686\n",
      "Root Mean Squared Error (RMSE) on Test Set: 0.8177\n",
      "Standard Deviation of Predictions on Test Set: 1.0091\n",
      "R² value on Test Set: 0.5635\n",
      "Cross-Validation MSE: 1.2470 ± 1.4179\n",
      "Cross-Validation RMSE: 0.9982 ± 0.5005\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Function to load the dataset\n",
    "def load_dataset(file_path, target_column):\n",
    "    \"\"\"\n",
    "    Loads the dataset and separates features and target.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): Path to the dataset.\n",
    "        target_column (str): Name of the target column.\n",
    "\n",
    "    Returns:\n",
    "        X (DataFrame): Features.\n",
    "        y (Series): Target.\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(file_path)\n",
    "    X = data.drop(columns=[target_column])\n",
    "    y = data[target_column]\n",
    "    return X, y\n",
    "\n",
    "# Function to scale features\n",
    "def scale_features(X_train, X_test):\n",
    "    \"\"\"\n",
    "    Scales training and testing features using StandardScaler.\n",
    "\n",
    "    Parameters:\n",
    "        X_train (DataFrame): Training features.\n",
    "        X_test (DataFrame): Testing features.\n",
    "\n",
    "    Returns:\n",
    "        X_train_scaled (ndarray): Scaled training features.\n",
    "        X_test_scaled (ndarray): Scaled testing features.\n",
    "        scaler (StandardScaler): The scaler object for future use.\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return X_train_scaled, X_test_scaled, scaler\n",
    "\n",
    "# Function to perform grid search\n",
    "def perform_grid_search(X_train, y_train, model, param_grid, cv=10):\n",
    "    \"\"\"\n",
    "    Performs grid search with cross-validation to find the best parameters.\n",
    "\n",
    "    Parameters:\n",
    "        X_train (ndarray): Training features.\n",
    "        y_train (Series): Training target.\n",
    "        model: The machine learning model.\n",
    "        param_grid (dict): Hyperparameter grid for grid search.\n",
    "        cv (int): Number of cross-validation folds.\n",
    "\n",
    "    Returns:\n",
    "        grid_search: The fitted GridSearchCV object.\n",
    "    \"\"\"\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=cv, scoring='neg_mean_squared_error', verbose=3)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return grid_search\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluates the model on the test set.\n",
    "\n",
    "    Parameters:\n",
    "        model: Trained model.\n",
    "        X_test (ndarray): Testing features.\n",
    "        y_test (Series): Testing target.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing evaluation metrics.\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    std_dev = np.std(y_pred)\n",
    "    return {\"MSE\": mse, \"RMSE\": rmse, \"R²\": r2, \"Std Dev\": std_dev}\n",
    "\n",
    "# Function to perform cross-validation\n",
    "def cross_validate_model(model, X, y, cv=10):\n",
    "    \"\"\"\n",
    "    Performs cross-validation and calculates MSE and RMSE.\n",
    "\n",
    "    Parameters:\n",
    "        model: Trained model.\n",
    "        X (ndarray): Features.\n",
    "        y (Series): Target.\n",
    "        cv (int): Number of cross-validation folds.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing cross-validation metrics.\n",
    "    \"\"\"\n",
    "    mse_scores = cross_val_score(model, X, y, cv=cv, scoring='neg_mean_squared_error')\n",
    "    rmse_scores = np.sqrt(-mse_scores)\n",
    "    return {\"CV MSE\": mse_scores, \"CV RMSE\": rmse_scores}\n",
    "\n",
    "# Main script\n",
    "if __name__ == \"__main__\":\n",
    "    # File path and target column\n",
    "    file_path = 'roberta_test_2.csv'\n",
    "    target_column = 'output'\n",
    "\n",
    "    # Load dataset\n",
    "    X, y = load_dataset(file_path, target_column)\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Scale features\n",
    "    X_train_scaled, X_test_scaled, scaler = scale_features(X_train, X_test)\n",
    "\n",
    "    # Define KNN model and parameter grid\n",
    "    knn = KNeighborsRegressor()\n",
    "    param_grid = {\n",
    "        'n_neighbors': [3, 5, 7, 9, 11],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "        'p': [1, 2]\n",
    "    }\n",
    "\n",
    "    # Perform grid search\n",
    "    grid_search = perform_grid_search(X_train_scaled, y_train, knn, param_grid)\n",
    "\n",
    "    # Get the best model\n",
    "    best_knn = grid_search.best_estimator_\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    test_metrics = evaluate_model(best_knn, X_test_scaled, y_test)\n",
    "    print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Test Metrics: {test_metrics}\")\n",
    "\n",
    "    # Perform cross-validation on the entire dataset\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    cv_metrics = cross_validate_model(best_knn, X_scaled, y)\n",
    "\n",
    "    print(f\"Cross-Validation MSE: {cv_metrics['CV MSE'].mean():.4f} ± {cv_metrics['CV MSE'].std():.4f}\")\n",
    "    print(f\"Cross-Validation RMSE: {cv_metrics['CV RMSE'].mean():.4f} ± {cv_metrics['CV RMSE'].std():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a800c0-cb24-41cc-9170-f5b460436e45",
   "metadata": {},
   "source": [
    "# Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fae31c91-8bfe-4eb3-b017-0016a1ceb2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=2; total time= 1.1min\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=2; total time=  58.9s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=2; total time=  55.1s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=2; total time=  55.9s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=2; total time=  55.2s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=2; total time=  47.5s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=2; total time=  48.6s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=2; total time=  47.4s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=2; total time=  52.3s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=2; total time=  51.4s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=3; total time=   0.0s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=3; total time=   0.0s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=3; total time=   0.0s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=3; total time=   0.0s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=3; total time=   0.0s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=3; total time=   0.0s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=3; total time=   0.0s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=3; total time=   0.0s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=3; total time=   0.0s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=3; total time=   0.0s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=4; total time=   0.5s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=4; total time=   0.4s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=4; total time=   0.5s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=4; total time=   0.5s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=4; total time=   0.5s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=4; total time=   0.4s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=4; total time=   0.4s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=4; total time=   0.4s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=4; total time=   0.4s\n",
      "[CV] END .........linear__fit_intercept=True, poly__degree=4; total time=   0.4s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=2; total time=  58.6s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=2; total time=  56.6s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=2; total time=  54.0s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=2; total time=  50.3s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=2; total time=  44.2s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=2; total time=  44.4s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=2; total time=  55.7s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=2; total time=  49.4s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=2; total time=  44.6s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=2; total time=  44.3s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=3; total time=   0.0s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=3; total time=   0.0s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=3; total time=   0.0s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=3; total time=   0.0s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=3; total time=   0.0s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=3; total time=   0.0s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=3; total time=   0.0s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=3; total time=   0.0s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=3; total time=   0.0s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=3; total time=   0.0s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=4; total time=   0.5s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=4; total time=   0.5s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=4; total time=   0.5s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=4; total time=   0.5s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=4; total time=   0.5s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=4; total time=   0.4s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=4; total time=   0.5s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=4; total time=   0.5s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=4; total time=   0.5s\n",
      "[CV] END ........linear__fit_intercept=False, poly__degree=4; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "40 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1101, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "         ^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 553. GiB for an array with shape (975, 76088705) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1101, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "         ^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 553. GiB for an array with shape (976, 76088705) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1101, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "         ^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 104. TiB for an array with shape (975, 14685120065) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1101, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "         ^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 104. TiB for an array with shape (976, 14685120065) and data type float64\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [-1.53759240e+21             nan             nan -2.38968084e+21\n",
      "             nan             nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'linear__fit_intercept': True, 'poly__degree': 2}\n",
      "Root Mean Squared Error (RMSE) on Test Set: 77570434032.98264\n",
      "R² value on Test Set: -3.927784212579305e+21\n",
      "Standard Deviation of Predictions: 76796804149.78\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, KFold\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Function to load the dataset\n",
    "def load_dataset(file_path, target_column):\n",
    "    \"\"\"\n",
    "    Loads the dataset and separates features and target.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): Path to the dataset.\n",
    "        target_column (str): Name of the target column.\n",
    "\n",
    "    Returns:\n",
    "        X (DataFrame): Features.\n",
    "        y (Series): Target.\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(file_path)\n",
    "    X = data.drop(columns=[target_column])\n",
    "    y = data[target_column]\n",
    "    return X, y\n",
    "\n",
    "# Function to set up the polynomial regression pipeline\n",
    "def create_pipeline():\n",
    "    \"\"\"\n",
    "    Creates a pipeline with scaling, polynomial feature transformation, and linear regression.\n",
    "\n",
    "    Returns:\n",
    "        Pipeline: The configured pipeline.\n",
    "    \"\"\"\n",
    "    return Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('poly', PolynomialFeatures()),\n",
    "        ('linear', LinearRegression())\n",
    "    ])\n",
    "\n",
    "# Function to perform grid search\n",
    "def perform_grid_search(pipeline, X_train, y_train, param_grid, cv):\n",
    "    \"\"\"\n",
    "    Performs grid search with cross-validation to find the best parameters.\n",
    "\n",
    "    Parameters:\n",
    "        pipeline (Pipeline): The pipeline for polynomial regression.\n",
    "        X_train (DataFrame): Training features.\n",
    "        y_train (Series): Training target.\n",
    "        param_grid (dict): Hyperparameter grid for grid search.\n",
    "        cv (int or cross-validation generator): Cross-validation strategy.\n",
    "\n",
    "    Returns:\n",
    "        grid_search (GridSearchCV): The fitted grid search object.\n",
    "    \"\"\"\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=cv, scoring='neg_mean_squared_error', verbose=2)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return grid_search\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluates the model on the test set.\n",
    "\n",
    "    Parameters:\n",
    "        model: Trained model.\n",
    "        X_test (DataFrame): Testing features.\n",
    "        y_test (Series): Testing target.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing evaluation metrics.\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    std_dev = np.std(y_pred)\n",
    "    return {\"RMSE\": rmse, \"R²\": r2, \"Std Dev\": std_dev}\n",
    "\n",
    "# Main script\n",
    "if __name__ == \"__main__\":\n",
    "    # File path and target column\n",
    "    file_path = 'roberta_test_2.csv'\n",
    "    target_column = 'output'\n",
    "\n",
    "    # Load dataset\n",
    "    X, y = load_dataset(file_path, target_column)\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Create pipeline\n",
    "    pipeline = create_pipeline()\n",
    "\n",
    "    # Define parameter grid\n",
    "    param_grid = {\n",
    "        'poly__degree': [2, 3, 4],\n",
    "        'linear__fit_intercept': [True, False]\n",
    "    }\n",
    "\n",
    "    # Set up cross-validation strategy\n",
    "    cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "    # Perform grid search\n",
    "    grid_search = perform_grid_search(pipeline, X_train, y_train, param_grid, cv)\n",
    "\n",
    "    # Get the best model\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Evaluate the model\n",
    "    test_metrics = evaluate_model(best_model, X_test, y_test)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Test Metrics: {test_metrics}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d3ba5a-8343-4048-a397-549fc3efd191",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b851319-8d01-411b-a0fe-e19a8d7f862c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "R^2 Score:  0.352054964980268\n",
      "RMSE:  0.9963031296745293\n",
      "Cross-validated RMSE:  0.9779680670303673\n",
      "Standard Deviation of Predictions: 1.1961071190749342\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Function to load the dataset\n",
    "def load_dataset(file_path, target_column):\n",
    "    \"\"\"\n",
    "    Load dataset and split into features and target.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): Path to the dataset file.\n",
    "        target_column (str): Name of the target column.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame, Series: Features (X) and target (y).\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "    return X, y\n",
    "\n",
    "# Function to preprocess the data\n",
    "def preprocess_data(X, y, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Scale the features and split into training and testing sets.\n",
    "\n",
    "    Parameters:\n",
    "        X (DataFrame): Features.\n",
    "        y (Series): Target variable.\n",
    "        test_size (float): Test set proportion.\n",
    "        random_state (int): Random seed.\n",
    "\n",
    "    Returns:\n",
    "        Tuple: Scaled and split data (X_train, X_test, y_train, y_test).\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    return train_test_split(X_scaled, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "# Function to perform grid search\n",
    "def perform_grid_search(model, param_grid, X_train, y_train, cv=10):\n",
    "    \"\"\"\n",
    "    Perform grid search for hyperparameter tuning.\n",
    "\n",
    "    Parameters:\n",
    "        model: The machine learning model to tune.\n",
    "        param_grid (dict): Hyperparameter grid.\n",
    "        X_train (array): Training features.\n",
    "        y_train (array): Training target.\n",
    "        cv (int): Number of cross-validation folds.\n",
    "\n",
    "    Returns:\n",
    "        GridSearchCV: Fitted grid search object.\n",
    "    \"\"\"\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=cv, scoring='neg_mean_squared_error')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return grid_search\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluate the model on the test set.\n",
    "\n",
    "    Parameters:\n",
    "        model: Trained model.\n",
    "        X_test (array): Test features.\n",
    "        y_test (array): Test target.\n",
    "\n",
    "    Returns:\n",
    "        dict: Evaluation metrics (R², RMSE, standard deviation).\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    std_dev = np.std(y_pred)\n",
    "    return {\"R²\": r2, \"RMSE\": rmse, \"Std Dev\": std_dev}\n",
    "\n",
    "# Main function to execute the workflow\n",
    "def main():\n",
    "    # File path and target column\n",
    "    file_path = 'roberta_test_2.csv'\n",
    "    target_column = 'output'\n",
    "\n",
    "    # Load and preprocess the dataset\n",
    "    X, y = load_dataset(file_path, target_column)\n",
    "    X_train, X_test, y_train, y_test = preprocess_data(X, y)\n",
    "\n",
    "    # Define the Logistic Regression model and parameter grid\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    param_grid = {\n",
    "        'C': [0.01, 0.1, 1, 10, 100],\n",
    "        'solver': ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "        'penalty': ['l2'],\n",
    "    }\n",
    "\n",
    "    # Perform grid search\n",
    "    grid_search = perform_grid_search(model, param_grid, X_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Display best parameters\n",
    "    print(\"Best Parameters: \", grid_search.best_params_)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    test_metrics = evaluate_model(best_model, X_test, y_test)\n",
    "    print(\"Test Metrics: \", test_metrics)\n",
    "\n",
    "    # Perform cross-validation\n",
    "    cross_val_scores = cross_val_score(best_model, X_train, y_train, cv=10, scoring='neg_mean_squared_error')\n",
    "    cv_rmse = np.mean(np.sqrt(-cross_val_scores))\n",
    "    print(\"Cross-validated RMSE: \", cv_rmse)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc6b43f-022a-492b-a16a-7c9bb4c30772",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8eacf53e-4074-4561-927b-1c6e40373121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    embed_0   embed_1   embed_2   embed_3   embed_4   embed_5   embed_6  \\\n",
      "0 -0.002268 -0.057392 -0.051938 -0.254064 -0.107042 -0.005746  0.053339   \n",
      "1 -0.095116  0.002254 -0.080440 -0.032033  0.325927 -0.089124  0.060066   \n",
      "2  0.171062 -0.006862 -0.092904  0.191909 -0.059166  0.084494  0.057149   \n",
      "3  0.091722 -0.023084 -0.170847  0.275267 -0.098605 -0.062822  0.026235   \n",
      "4  0.058596 -0.003751 -0.051466  0.243470  0.019038 -0.036104 -0.019322   \n",
      "\n",
      "    embed_7   embed_8   embed_9  ...  embed_759  embed_760  embed_761  \\\n",
      "0  0.155956  0.116585 -0.038332  ...   0.072443   0.059975  -0.076614   \n",
      "1  0.011424  0.037144 -0.126206  ...   0.060893  -0.161714  -0.016327   \n",
      "2 -0.057770  0.018334  0.042601  ...  -0.011123   0.010387   0.074528   \n",
      "3 -0.048630 -0.013406 -0.024388  ...  -0.104926   0.042281   0.022375   \n",
      "4 -0.011959 -0.054584 -0.058981  ...  -0.159260   0.032556  -0.005767   \n",
      "\n",
      "   embed_762  embed_763  embed_764  embed_765  embed_766  embed_767  output  \n",
      "0   0.036943   0.130576   0.409834  -0.142671   0.027263  -0.046064       0  \n",
      "1   0.029357   0.101992   0.217288  -0.190804   0.010403  -0.092698       0  \n",
      "2  -0.054416  -0.009584   0.244145  -0.002439   0.106801   0.046556       0  \n",
      "3   0.038976  -0.098919  -0.080987   0.140436   0.061884   0.038201       0  \n",
      "4   0.025254  -0.051693   0.056800  -0.031124   0.041619   0.015181       0  \n",
      "\n",
      "[5 rows x 769 columns]\n",
      "Index(['embed_0', 'embed_1', 'embed_2', 'embed_3', 'embed_4', 'embed_5',\n",
      "       'embed_6', 'embed_7', 'embed_8', 'embed_9',\n",
      "       ...\n",
      "       'embed_759', 'embed_760', 'embed_761', 'embed_762', 'embed_763',\n",
      "       'embed_764', 'embed_765', 'embed_766', 'embed_767', 'output'],\n",
      "      dtype='object', length=769)\n",
      "MSE: 5.508192793445987e+21\n",
      "RMSE: 74217200118.61124\n",
      "R²: -3.568389584980578e+21\n",
      "Standard Deviation of MSE: 5.894379626681844e+21\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Function to load the dataset\n",
    "def load_dataset(file_path, target_column):\n",
    "    \"\"\"\n",
    "    Load the dataset and separate features and target.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): Path to the dataset file.\n",
    "        target_column (str): Name of the target column.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame, Series: Features (X) and target (y).\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    X = df.drop(columns=[target_column]).values\n",
    "    y = df[target_column].values\n",
    "    return X, y\n",
    "\n",
    "# Function to preprocess the data\n",
    "def preprocess_data(X, y, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Standardize the features.\n",
    "\n",
    "    Parameters:\n",
    "        X (array): Features.\n",
    "        y (array): Target variable.\n",
    "\n",
    "    Returns:\n",
    "        array: Scaled features.\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    return X_scaled\n",
    "\n",
    "# Function to perform grid search (though no hyperparameters for basic LinearRegression)\n",
    "def perform_grid_search(model, X_scaled, y, cv=10):\n",
    "    \"\"\"\n",
    "    Perform grid search for model tuning (even though no hyperparameters for basic LinearRegression).\n",
    "\n",
    "    Parameters:\n",
    "        model: The machine learning model to tune.\n",
    "        X_scaled (array): Scaled features.\n",
    "        y (array): Target variable.\n",
    "        cv (int): Number of cross-validation folds.\n",
    "\n",
    "    Returns:\n",
    "        GridSearchCV: Fitted grid search object.\n",
    "    \"\"\"\n",
    "    grid_params = {}  # No hyperparameters for basic LinearRegression\n",
    "    grid_search = GridSearchCV(model, grid_params, cv=cv, scoring='neg_mean_squared_error')\n",
    "    grid_search.fit(X_scaled, y)\n",
    "    return grid_search\n",
    "\n",
    "# Function to evaluate the model with cross-validation\n",
    "def evaluate_model_with_cv(model, X_scaled, y, cv=10):\n",
    "    \"\"\"\n",
    "    Evaluate the model using cross-validation.\n",
    "\n",
    "    Parameters:\n",
    "        model: The trained model.\n",
    "        X_scaled (array): Scaled features.\n",
    "        y (array): Target variable.\n",
    "        cv (int): Number of cross-validation folds.\n",
    "\n",
    "    Returns:\n",
    "        dict: Evaluation metrics (MSE, RMSE, R², standard deviation of MSE).\n",
    "    \"\"\"\n",
    "    mse_scores = cross_val_score(model, X_scaled, y, cv=cv, scoring='neg_mean_squared_error')\n",
    "    r2_scores = cross_val_score(model, X_scaled, y, cv=cv, scoring='r2')\n",
    "    \n",
    "    mse = -mse_scores.mean()  # Convert negative MSE to positive\n",
    "    rmse = np.sqrt(mse)       # RMSE\n",
    "    r2 = r2_scores.mean()     # R²\n",
    "    std_dev = np.std(mse_scores)  # Standard deviation of MSE\n",
    "    \n",
    "    return {\"MSE\": mse, \"RMSE\": rmse, \"R²\": r2, \"Std Dev\": std_dev}\n",
    "\n",
    "# Main function to execute the workflow\n",
    "def main():\n",
    "    # File path and target column\n",
    "    file_path = 'roberta_test_2.csv'\n",
    "    target_column = 'output'\n",
    "\n",
    "    # Load and preprocess the dataset\n",
    "    X, y = load_dataset(file_path, target_column)\n",
    "    X_scaled = preprocess_data(X, y)\n",
    "\n",
    "    # Initialize the Linear Regression model\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # Perform grid search (though no hyperparameters for LinearRegression)\n",
    "    grid_search = perform_grid_search(model, X_scaled, y)\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Evaluate the model with cross-validation\n",
    "    metrics = evaluate_model_with_cv(best_model, X_scaled, y)\n",
    "    print(\"Cross-Validation Metrics: \", metrics)\n",
    "\n",
    "    # For a sample evaluation (optional for reduced dataset size)\n",
    "    df_sample = pd.read_csv(file_path).sample(n=500, random_state=42)\n",
    "    X_sample = df_sample.drop(columns=[target_column]).values\n",
    "    y_sample = df_sample[target_column].values\n",
    "    X_sample_scaled = StandardScaler().fit_transform(X_sample)\n",
    "\n",
    "    # Perform evaluation on the sample\n",
    "    metrics_sample = evaluate_model_with_cv(best_model, X_sample_scaled, y_sample)\n",
    "    print(\"Sample Cross-Validation Metrics: \", metrics_sample)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262e058e-e945-47c4-8f93-8e10ee45593c",
   "metadata": {},
   "source": [
    "# Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "681b8be0-d664-444d-8623-f54a68431bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 20}\n",
      "R^2 Score: 0.27132947089194637\n",
      "RMSE: 1.0565450358948874\n",
      "MAE: 0.682410824108241\n",
      "Mean of Output: 3.4022140221402215\n",
      "Standard Deviation of Output: 1.2377200077817099\n",
      "Cross-Validation Scores: [-0.06341399 -0.05463411  0.03253953 -0.08660526 -0.13790409]\n",
      "Cross-Validation Mean: -0.062003585403908226\n",
      "Cross-Validation Std Dev: 0.055427119347098035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "10 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of DecisionTreeRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [        nan  0.07130069  0.02709009 -0.04284067  0.01876929  0.01214975\n",
      "  0.00238452  0.01057024 -0.00596887         nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Load the dataset\n",
    "df= pd.read_csv('roberta_test_2.csv')\n",
    "\n",
    "# Features and target\n",
    "X = df.drop(columns=['output'])\n",
    "y = df['output']\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply PCA for dimension reduction\n",
    "pca = PCA(n_components=0.95)  # Retain 95% of variance\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Decision Tree Regression model\n",
    "model = DecisionTreeRegressor()\n",
    "\n",
    "# Parameter tuning using RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': np.arange(2, 10),\n",
    "    'min_samples_leaf': np.arange(1, 5),\n",
    "    'max_features': ['auto', 'sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=10, cv=5, random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(random_search.best_estimator_, X_train, y_train, cv=kf)\n",
    "\n",
    "# Predictions\n",
    "y_pred = random_search.best_estimator_.predict(X_test)\n",
    "\n",
    "# Performance metrics\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score, KFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Function to load the dataset\n",
    "def load_dataset(file_path, target_column):\n",
    "    \"\"\"\n",
    "    Load the dataset and separate features and target.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): Path to the dataset file.\n",
    "        target_column (str): Name of the target column.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame, Series: Features (X) and target (y).\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "    return X, y\n",
    "\n",
    "# Function to preprocess the data (standardize the features)\n",
    "def preprocess_data(X):\n",
    "    \"\"\"\n",
    "    Standardize the features using StandardScaler.\n",
    "\n",
    "    Parameters:\n",
    "        X (DataFrame): Features.\n",
    "\n",
    "    Returns:\n",
    "        array: Scaled features.\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    return X_scaled\n",
    "\n",
    "# Function to apply PCA for dimension reduction\n",
    "def apply_pca(X_scaled, variance_retained=0.95):\n",
    "    \"\"\"\n",
    "    Apply PCA for dimension reduction, retaining the specified variance.\n",
    "\n",
    "    Parameters:\n",
    "        X_scaled (array): Scaled features.\n",
    "        variance_retained (float): Percentage of variance to retain (default 95%).\n",
    "\n",
    "    Returns:\n",
    "        array: Transformed features after PCA.\n",
    "    \"\"\"\n",
    "    pca = PCA(n_components=variance_retained)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    return X_pca\n",
    "\n",
    "# Function to perform randomized search for hyperparameter tuning\n",
    "def tune_model_with_random_search(model, X_train, y_train, param_dist, n_iter=10, cv=5):\n",
    "    \"\"\"\n",
    "    Perform RandomizedSearchCV for model hyperparameter tuning.\n",
    "\n",
    "    Parameters:\n",
    "        model: The machine learning model to tune.\n",
    "        X_train (array): Training features.\n",
    "        y_train (array): Training target.\n",
    "        param_dist (dict): Hyperparameter distribution for the model.\n",
    "        n_iter (int): Number of iterations for RandomizedSearchCV (default 10).\n",
    "        cv (int): Number of cross-validation folds (default 5).\n",
    "\n",
    "    Returns:\n",
    "        RandomizedSearchCV: Fitted RandomizedSearchCV object.\n",
    "    \"\"\"\n",
    "    random_search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=n_iter, cv=cv, random_state=42)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    return random_search\n",
    "\n",
    "# Function to evaluate model performance\n",
    "def evaluate_model(y_test, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate and return model evaluation metrics.\n",
    "\n",
    "    Parameters:\n",
    "        y_test (array): Actual target values.\n",
    "        y_pred (array): Predicted target values.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing R², RMSE, MAE, mean value, and standard deviation of the output.\n",
    "    \"\"\"\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mean_value = np.mean(y_test)\n",
    "    std_dev = np.std(y_test)\n",
    "    return {\"R^2\": r2, \"RMSE\": rmse, \"MAE\": mae, \"Mean of Output\": mean_value, \"Standard Deviation of Output\": std_dev}\n",
    "\n",
    "# Function to perform cross-validation\n",
    "def cross_validate_model(model, X_train, y_train, cv=5):\n",
    "    \"\"\"\n",
    "    Perform cross-validation and return the scores.\n",
    "\n",
    "    Parameters:\n",
    "        model: The trained model.\n",
    "        X_train (array): Training features.\n",
    "        y_train (array): Training target.\n",
    "        cv (int): Number of cross-validation folds (default 5).\n",
    "\n",
    "    Returns:\n",
    "        array: Cross-validation scores.\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=kf)\n",
    "    return cv_scores\n",
    "\n",
    "# Main function to execute the workflow\n",
    "def main():\n",
    "    # File path and target column\n",
    "    file_path = 'roberta_test_2.csv'\n",
    "    target_column = 'output'\n",
    "\n",
    "    # Load the dataset\n",
    "    X, y = load_dataset(file_path, target_column)\n",
    "\n",
    "    # Preprocess the data (standardization)\n",
    "    X_scaled = preprocess_data(X)\n",
    "\n",
    "    # Apply PCA for dimension reduction\n",
    "    X_pca = apply_pca(X_scaled)\n",
    "\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize the Decision Tree model\n",
    "    model = DecisionTreeRegressor()\n",
    "\n",
    "    # Define parameter grid for RandomizedSearchCV\n",
    "    param_dist = {\n",
    "        'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "        'min_samples_split': np.arange(2, 10),\n",
    "        'min_samples_leaf': np.arange(1, 5),\n",
    "        'max_features': ['auto', 'sqrt', 'log2', None]\n",
    "    }\n",
    "\n",
    "    # Perform RandomizedSearchCV for model hyperparameter tuning\n",
    "    random_search = tune_model_with_random_search(model, X_train, y_train, param_dist)\n",
    "\n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_validate_model(random_search.best_estimator_, X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = random_search.best_estimator_.predict(X_test)\n",
    "\n",
    "    # Evaluate model performance\n",
    "    metrics = evaluate_model(y_test, y_pred)\n",
    "\n",
    "    # Output the results\n",
    "    print(f\"Best Parameters: {random_search.best_params_}\")\n",
    "    print(f\"R^2 Score: {metrics['R^2']}\")\n",
    "    print(f\"RMSE: {metrics['RMSE']}\")\n",
    "    print(f\"MAE: {metrics['MAE']}\")\n",
    "    print(f\"Mean of Output: {metrics['Mean of Output']}\")\n",
    "    print(f\"Standard Deviation of Output: {metrics['Standard Deviation of Output']}\")\n",
    "    print(f\"Cross-Validation Scores: {cv_scores}\")\n",
    "    print(f\"Cross-Validation Mean: {cv_scores.mean()}\")\n",
    "    print(f\"Cross-Validation Std Dev: {cv_scores.std()}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "mean_value = np.mean(y_test)\n",
    "std_dev = np.std(y_test)\n",
    "\n",
    "# Print results\n",
    "print(f\"Best Parameters: {random_search.best_params_}\")\n",
    "print(f\"R^2 Score: {r2}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"Mean of Output: {mean_value}\")\n",
    "print(f\"Standard Deviation of Output: {std_dev}\")\n",
    "print(f\"Cross-Validation Scores: {cv_scores}\")\n",
    "print(f\"Cross-Validation Mean: {cv_scores.mean()}\")\n",
    "print(f\"Cross-Validation Std Dev: {cv_scores.std()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27729928-3f9e-48de-b6b9-169d3acfb1f4",
   "metadata": {},
   "source": [
    "# Bayesian Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "228f4655-e48c-4b90-8569-9de9ad20c2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'lambda_2': 0.0001, 'lambda_1': 0.1, 'alpha_2': 0.1, 'alpha_1': 0.001}\n",
      "R^2 Score: 0.43316623718084224\n",
      "RMSE: 0.931859134434971\n",
      "MAE: 0.7654710621707257\n",
      "Mean of Output: 3.4022140221402215\n",
      "Standard Deviation of Output: 1.2377200077817099\n",
      "Cross-Validation Scores: [0.39647098 0.37840157 0.45102912 0.44629659 0.41795508]\n",
      "Cross-Validation Mean: 0.4180306685016288\n",
      "Cross-Validation Std Dev: 0.028011251967096144\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score, KFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "\n",
    "# Function to load the dataset\n",
    "def load_dataset(file_path, target_column):\n",
    "    \"\"\"\n",
    "    Load the dataset and separate features and target.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): Path to the dataset file.\n",
    "        target_column (str): Name of the target column.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame, Series: Features (X) and target (y).\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# Function to preprocess the data (standardize the features)\n",
    "def preprocess_data(X):\n",
    "    \"\"\"\n",
    "    Standardize the features using StandardScaler.\n",
    "\n",
    "    Parameters:\n",
    "        X (DataFrame): Features.\n",
    "\n",
    "    Returns:\n",
    "        array: Scaled features.\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    return X_scaled\n",
    "\n",
    "\n",
    "# Function to apply PCA for dimension reduction\n",
    "def apply_pca(X_scaled, variance_retained=0.95):\n",
    "    \"\"\"\n",
    "    Apply PCA for dimension reduction, retaining the specified variance.\n",
    "\n",
    "    Parameters:\n",
    "        X_scaled (array): Scaled features.\n",
    "        variance_retained (float): Percentage of variance to retain (default 95%).\n",
    "\n",
    "    Returns:\n",
    "        array: Transformed features after PCA.\n",
    "    \"\"\"\n",
    "    pca = PCA(n_components=variance_retained)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    return X_pca\n",
    "\n",
    "\n",
    "# Function to perform randomized search for hyperparameter tuning\n",
    "def tune_model_with_random_search(model, X_train, y_train, param_dist, n_iter=10, cv=5):\n",
    "    \"\"\"\n",
    "    Perform RandomizedSearchCV for model hyperparameter tuning.\n",
    "\n",
    "    Parameters:\n",
    "        model: The machine learning model to tune.\n",
    "        X_train (array): Training features.\n",
    "        y_train (array): Training target.\n",
    "        param_dist (dict): Hyperparameter distribution for the model.\n",
    "        n_iter (int): Number of iterations for RandomizedSearchCV (default 10).\n",
    "        cv (int): Number of cross-validation folds (default 5).\n",
    "\n",
    "    Returns:\n",
    "        RandomizedSearchCV: Fitted RandomizedSearchCV object.\n",
    "    \"\"\"\n",
    "    random_search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=n_iter, cv=cv, random_state=42)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    return random_search\n",
    "\n",
    "\n",
    "# Function to evaluate model performance\n",
    "def evaluate_model(y_test, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate and return model evaluation metrics.\n",
    "\n",
    "    Parameters:\n",
    "        y_test (array): Actual target values.\n",
    "        y_pred (array): Predicted target values.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing R², RMSE, MAE, mean value, and standard deviation of the output.\n",
    "    \"\"\"\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mean_value = np.mean(y_test)\n",
    "    std_dev = np.std(y_test)\n",
    "    return {\"R^2\": r2, \"RMSE\": rmse, \"MAE\": mae, \"Mean of Output\": mean_value, \"Standard Deviation of Output\": std_dev}\n",
    "\n",
    "\n",
    "# Function to perform cross-validation\n",
    "def cross_validate_model(model, X_train, y_train, cv=5):\n",
    "    \"\"\"\n",
    "    Perform cross-validation and return the scores.\n",
    "\n",
    "    Parameters:\n",
    "        model: The trained model.\n",
    "        X_train (array): Training features.\n",
    "        y_train (array): Training target.\n",
    "        cv (int): Number of cross-validation folds (default 5).\n",
    "\n",
    "    Returns:\n",
    "        array: Cross-validation scores.\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=kf)\n",
    "    return cv_scores\n",
    "\n",
    "\n",
    "# Main function to execute the workflow\n",
    "def main():\n",
    "    # File path and target column\n",
    "    file_path = 'roberta_test_2.csv'\n",
    "    target_column = 'output'\n",
    "\n",
    "    # Load the dataset\n",
    "    X, y = load_dataset(file_path, target_column)\n",
    "\n",
    "    # Preprocess the data (standardization)\n",
    "    X_scaled = preprocess_data(X)\n",
    "\n",
    "    # Apply PCA for dimension reduction\n",
    "    X_pca = apply_pca(X_scaled)\n",
    "\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize the Bayesian Ridge model\n",
    "    model = BayesianRidge()\n",
    "\n",
    "    # Define parameter grid for RandomizedSearchCV\n",
    "    param_dist = {\n",
    "        'alpha_1': np.logspace(-6, -1, 6),\n",
    "        'alpha_2': np.logspace(-6, -1, 6),\n",
    "        'lambda_1': np.logspace(-6, -1, 6),\n",
    "        'lambda_2': np.logspace(-6, -1, 6)\n",
    "    }\n",
    "\n",
    "    # Perform RandomizedSearchCV for model hyperparameter tuning\n",
    "    random_search = tune_model_with_random_search(model, X_train, y_train, param_dist)\n",
    "\n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_validate_model(random_search.best_estimator_, X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = random_search.best_estimator_.predict(X_test)\n",
    "\n",
    "    # Evaluate model performance\n",
    "    metrics = evaluate_model(y_test, y_pred)\n",
    "\n",
    "    # Output the results\n",
    "    print(f\"Best Parameters: {random_search.best_params_}\")\n",
    "    print(f\"R^2 Score: {metrics['R^2']}\")\n",
    "    print(f\"RMSE: {metrics['RMSE']}\")\n",
    "    print(f\"MAE: {metrics['MAE']}\")\n",
    "    print(f\"Mean of Output: {metrics['Mean of Output']}\")\n",
    "    print(f\"Standard Deviation of Output: {metrics['Standard Deviation of Output']}\")\n",
    "    print(f\"Cross-Validation Scores: {cv_scores}\")\n",
    "    print(f\"Cross-Validation Mean: {cv_scores.mean()}\")\n",
    "    print(f\"Cross-Validation Std Dev: {cv_scores.std()}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23064eec-3ce6-437c-a088-e80edafcc052",
   "metadata": {},
   "source": [
    "# Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7efc220f-b1b5-4aa3-8666-0050b8a74c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_estimators': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': None, 'bootstrap': True}\n",
      "R^2 Score: 0.5354746999113791\n",
      "RMSE: 0.8435815984811348\n",
      "MAE: 0.6583421484214842\n",
      "Mean of Output: 3.4022140221402215\n",
      "Standard Deviation of Output: 1.2377200077817099\n",
      "Cross-Validation Scores: [0.46013964 0.49983669 0.44386573]\n",
      "Cross-Validation Mean: 0.46794735299501705\n",
      "Cross-Validation Std Dev: 0.023507547769574297\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score, KFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "# Function to load the dataset\n",
    "def load_dataset(file_path, target_column):\n",
    "    \"\"\"\n",
    "    Load the dataset and separate features and target.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): Path to the dataset file.\n",
    "        target_column (str): Name of the target column.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame, Series: Features (X) and target (y).\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# Function to preprocess the data (standardize the features)\n",
    "def preprocess_data(X):\n",
    "    \"\"\"\n",
    "    Standardize the features using StandardScaler.\n",
    "\n",
    "    Parameters:\n",
    "        X (DataFrame): Features.\n",
    "\n",
    "    Returns:\n",
    "        array: Scaled features.\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    return X_scaled\n",
    "\n",
    "\n",
    "# Function to apply PCA for dimension reduction\n",
    "def apply_pca(X_scaled, variance_retained=0.95):\n",
    "    \"\"\"\n",
    "    Apply PCA for dimension reduction, retaining the specified variance.\n",
    "\n",
    "    Parameters:\n",
    "        X_scaled (array): Scaled features.\n",
    "        variance_retained (float): Percentage of variance to retain (default 95%).\n",
    "\n",
    "    Returns:\n",
    "        array: Transformed features after PCA.\n",
    "    \"\"\"\n",
    "    pca = PCA(n_components=variance_retained)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    return X_pca\n",
    "\n",
    "\n",
    "# Function to perform randomized search for hyperparameter tuning\n",
    "def tune_model_with_random_search(model, X_train, y_train, param_dist, n_iter=5, cv=3):\n",
    "    \"\"\"\n",
    "    Perform RandomizedSearchCV for model hyperparameter tuning.\n",
    "\n",
    "    Parameters:\n",
    "        model: The machine learning model to tune.\n",
    "        X_train (array): Training features.\n",
    "        y_train (array): Training target.\n",
    "        param_dist (dict): Hyperparameter distribution for the model.\n",
    "        n_iter (int): Number of iterations for RandomizedSearchCV (default 5).\n",
    "        cv (int): Number of cross-validation folds (default 3).\n",
    "\n",
    "    Returns:\n",
    "        RandomizedSearchCV: Fitted RandomizedSearchCV object.\n",
    "    \"\"\"\n",
    "    random_search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=n_iter, cv=cv, random_state=42, n_jobs=-1)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    return random_search\n",
    "\n",
    "\n",
    "# Function to evaluate model performance\n",
    "def evaluate_model(y_test, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate and return model evaluation metrics.\n",
    "\n",
    "    Parameters:\n",
    "        y_test (array): Actual target values.\n",
    "        y_pred (array): Predicted target values.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing R², RMSE, MAE, mean value, and standard deviation of the output.\n",
    "    \"\"\"\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mean_value = np.mean(y_test)\n",
    "    std_dev = np.std(y_test)\n",
    "    return {\"R^2\": r2, \"RMSE\": rmse, \"MAE\": mae, \"Mean of Output\": mean_value, \"Standard Deviation of Output\": std_dev}\n",
    "\n",
    "\n",
    "# Function to perform cross-validation\n",
    "def cross_validate_model(model, X_train, y_train, cv=3):\n",
    "    \"\"\"\n",
    "    Perform cross-validation and return the scores.\n",
    "\n",
    "    Parameters:\n",
    "        model: The trained model.\n",
    "        X_train (array): Training features.\n",
    "        y_train (array): Training target.\n",
    "        cv (int): Number of cross-validation folds (default 3).\n",
    "\n",
    "    Returns:\n",
    "        array: Cross-validation scores.\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=kf)\n",
    "    return cv_scores\n",
    "\n",
    "\n",
    "# Main function to execute the workflow\n",
    "def main():\n",
    "    # File path and target column\n",
    "    file_path = 'roberta_test_2.csv'\n",
    "    target_column = 'output'\n",
    "\n",
    "    # Load the dataset\n",
    "    X, y = load_dataset(file_path, target_column)\n",
    "\n",
    "    # Preprocess the data (standardization)\n",
    "    X_scaled = preprocess_data(X)\n",
    "\n",
    "    # Apply PCA for dimension reduction\n",
    "    X_pca = apply_pca(X_scaled)\n",
    "\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize the Random Forest model\n",
    "    model = RandomForestRegressor()\n",
    "\n",
    "    # Define parameter grid for RandomizedSearchCV\n",
    "    param_dist = {\n",
    "        'n_estimators': [10, 50],  # Reduced number of estimators\n",
    "        'max_depth': [None, 10],  # Reduced max_depth options\n",
    "        'min_samples_split': [2, 5],\n",
    "        'min_samples_leaf': [1, 2],\n",
    "        'bootstrap': [True]  # Keeping only one option for bootstrap\n",
    "    }\n",
    "\n",
    "    # Perform RandomizedSearchCV for model hyperparameter tuning\n",
    "    random_search = tune_model_with_random_search(model, X_train, y_train, param_dist)\n",
    "\n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_validate_model(random_search.best_estimator_, X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = random_search.best_estimator_.predict(X_test)\n",
    "\n",
    "    # Evaluate model performance\n",
    "    metrics = evaluate_model(y_test, y_pred)\n",
    "\n",
    "    # Output the results\n",
    "    print(f\"Best Parameters: {random_search.best_params_}\")\n",
    "    print(f\"R^2 Score: {metrics['R^2']}\")\n",
    "    print(f\"RMSE: {metrics['RMSE']}\")\n",
    "    print(f\"MAE: {metrics['MAE']}\")\n",
    "    print(f\"Mean of Output: {metrics['Mean of Output']}\")\n",
    "    print(f\"Standard Deviation of Output: {metrics['Standard Deviation of Output']}\")\n",
    "    print(f\"Cross-Validation Scores: {cv_scores}\")\n",
    "    print(f\"Cross-Validation Mean: {cv_scores.mean()}\")\n",
    "    print(f\"Cross-Validation Std Dev: {cv_scores.std()}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190bf119-991b-4b96-9291-eee5845ab45c",
   "metadata": {},
   "source": [
    "## Gaussian Process Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa2172f6-bb35-4935-8449-5fed94a4efdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_restarts_optimizer': 15, 'alpha': 0.01}\n",
      "R^2 Score: 0.5139741128828532\n",
      "RMSE: 1.3720220137955668\n",
      "MAE: 1.0169708484273436\n",
      "Mean of Output: 1.9384615384615385\n",
      "Standard Deviation of Output: 1.968028479131986\n",
      "Cross-Validation Scores: [0.26014635 0.30029679 0.15823068]\n",
      "Cross-Validation Mean: 0.23955793927816293\n",
      "Cross-Validation Std Dev: 0.05979747276779415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score, KFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C, WhiteKernel\n",
    "\n",
    "\n",
    "# Function to load the dataset\n",
    "def load_dataset(file_path, target_column):\n",
    "    \"\"\"\n",
    "    Load the dataset and separate features and target.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): Path to the dataset file.\n",
    "        target_column (str): Name of the target column.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame, Series: Features (X) and target (y).\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# Function to preprocess the data (standardize the features)\n",
    "def preprocess_data(X):\n",
    "    \"\"\"\n",
    "    Standardize the features using StandardScaler.\n",
    "\n",
    "    Parameters:\n",
    "        X (DataFrame): Features.\n",
    "\n",
    "    Returns:\n",
    "        array: Scaled features.\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    return X_scaled\n",
    "\n",
    "\n",
    "# Function to apply PCA for dimension reduction\n",
    "def apply_pca(X_scaled, variance_retained=0.95):\n",
    "    \"\"\"\n",
    "    Apply PCA for dimension reduction, retaining the specified variance.\n",
    "\n",
    "    Parameters:\n",
    "        X_scaled (array): Scaled features.\n",
    "        variance_retained (float): Percentage of variance to retain (default 95%).\n",
    "\n",
    "    Returns:\n",
    "        array: Transformed features after PCA.\n",
    "    \"\"\"\n",
    "    pca = PCA(n_components=variance_retained)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    return X_pca\n",
    "\n",
    "\n",
    "# Function to perform randomized search for hyperparameter tuning\n",
    "def tune_model_with_random_search(model, X_train, y_train, param_dist, n_iter=5, cv=3):\n",
    "    \"\"\"\n",
    "    Perform RandomizedSearchCV for model hyperparameter tuning.\n",
    "\n",
    "    Parameters:\n",
    "        model: The machine learning model to tune.\n",
    "        X_train (array): Training features.\n",
    "        y_train (array): Training target.\n",
    "        param_dist (dict): Hyperparameter distribution for the model.\n",
    "        n_iter (int): Number of iterations for RandomizedSearchCV (default 5).\n",
    "        cv (int): Number of cross-validation folds (default 3).\n",
    "\n",
    "    Returns:\n",
    "        RandomizedSearchCV: Fitted RandomizedSearchCV object.\n",
    "    \"\"\"\n",
    "    random_search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=n_iter, cv=cv, random_state=42, n_jobs=-1)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    return random_search\n",
    "\n",
    "\n",
    "# Function to evaluate model performance\n",
    "def evaluate_model(y_test, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate and return model evaluation metrics.\n",
    "\n",
    "    Parameters:\n",
    "        y_test (array): Actual target values.\n",
    "        y_pred (array): Predicted target values.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing R², RMSE, MAE, mean value, and standard deviation of the output.\n",
    "    \"\"\"\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mean_value = np.mean(y_test)\n",
    "    std_dev = np.std(y_test)\n",
    "    return {\"R^2\": r2, \"RMSE\": rmse, \"MAE\": mae, \"Mean of Output\": mean_value, \"Standard Deviation of Output\": std_dev}\n",
    "\n",
    "\n",
    "# Function to perform cross-validation\n",
    "def cross_validate_model(model, X_train, y_train, cv=3):\n",
    "    \"\"\"\n",
    "    Perform cross-validation and return the scores.\n",
    "\n",
    "    Parameters:\n",
    "        model: The trained model.\n",
    "        X_train (array): Training features.\n",
    "        y_train (array): Training target.\n",
    "        cv (int): Number of cross-validation folds (default 3).\n",
    "\n",
    "    Returns:\n",
    "        array: Cross-validation scores.\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=kf)\n",
    "    return cv_scores\n",
    "\n",
    "\n",
    "# Main function to execute the workflow\n",
    "def main():\n",
    "    # File path and target column\n",
    "    file_path = 'roberta_test_2.csv'\n",
    "    target_column = 'output'\n",
    "\n",
    "    # Load the dataset\n",
    "    X, y = load_dataset(file_path, target_column)\n",
    "\n",
    "    # Preprocess the data (standardization)\n",
    "    X_scaled = preprocess_data(X)\n",
    "\n",
    "    # Apply PCA for dimension reduction\n",
    "    X_pca = apply_pca(X_scaled)\n",
    "\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Gaussian Process Regression model with kernel\n",
    "    kernel = C(1.0, (1e-3, 1e3)) * RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e2)) + WhiteKernel()\n",
    "    model = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10, random_state=42)\n",
    "\n",
    "    # Define parameter grid for RandomizedSearchCV\n",
    "    param_dist = {\n",
    "        'alpha': [1e-10, 1e-5, 1e-2],  # Noise level\n",
    "        'n_restarts_optimizer': [5, 10, 15],  # Number of restarts for optimizer\n",
    "    }\n",
    "\n",
    "    # Perform RandomizedSearchCV for model hyperparameter tuning\n",
    "    random_search = tune_model_with_random_search(model, X_train, y_train, param_dist)\n",
    "\n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_validate_model(random_search.best_estimator_, X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = random_search.best_estimator_.predict(X_test)\n",
    "\n",
    "    # Evaluate model performance\n",
    "    metrics = evaluate_model(y_test, y_pred)\n",
    "\n",
    "    # Output the results\n",
    "    print(f\"Best Parameters: {random_search.best_params_}\")\n",
    "    print(f\"R^2 Score: {metrics['R^2']}\")\n",
    "    print(f\"RMSE: {metrics['RMSE']}\")\n",
    "    print(f\"MAE: {metrics['MAE']}\")\n",
    "    print(f\"Mean of Output: {metrics['Mean of Output']}\")\n",
    "    print(f\"Standard Deviation of Output: {metrics['Standard Deviation of Output']}\")\n",
    "    print(f\"Cross-Validation Scores: {cv_scores}\")\n",
    "    print(f\"Cross-Validation Mean: {cv_scores.mean()}\")\n",
    "    print(f\"Cross-Validation Std Dev: {cv_scores.std()}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6263224-442f-4edc-905d-62c9edeb4c90",
   "metadata": {},
   "source": [
    "## Support vector regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14b08128-e53f-49c2-a9a4-bc9022613f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'kernel': 'rbf', 'epsilon': 0.3, 'degree': 3, 'C': 100}\n",
      "R^2 Score: 0.4892619949836724\n",
      "RMSE: 1.4064699791146675\n",
      "MAE: 1.1220054585976629\n",
      "Mean of Output: 1.9384615384615385\n",
      "Standard Deviation of Output: 1.968028479131986\n",
      "Cross-Validation Scores: [0.30643979 0.32267058 0.2641492 ]\n",
      "Cross-Validation Mean: 0.29775318831807834\n",
      "Cross-Validation Std Dev: 0.024668205101982726\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score, KFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Function to load the dataset\n",
    "def load_dataset(file_path, target_column):\n",
    "    \"\"\"\n",
    "    Load the dataset and separate features and target.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): Path to the dataset file.\n",
    "        target_column (str): Name of the target column.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame, Series: Features (X) and target (y).\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# Function to preprocess the data (standardize the features)\n",
    "def preprocess_data(X):\n",
    "    \"\"\"\n",
    "    Standardize the features using StandardScaler.\n",
    "\n",
    "    Parameters:\n",
    "        X (DataFrame): Features.\n",
    "\n",
    "    Returns:\n",
    "        array: Scaled features.\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    return X_scaled\n",
    "\n",
    "\n",
    "# Function to apply PCA for dimension reduction\n",
    "def apply_pca(X_scaled, variance_retained=0.95):\n",
    "    \"\"\"\n",
    "    Apply PCA for dimension reduction, retaining the specified variance.\n",
    "\n",
    "    Parameters:\n",
    "        X_scaled (array): Scaled features.\n",
    "        variance_retained (float): Percentage of variance to retain (default 95%).\n",
    "\n",
    "    Returns:\n",
    "        array: Transformed features after PCA.\n",
    "    \"\"\"\n",
    "    pca = PCA(n_components=variance_retained)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    return X_pca\n",
    "\n",
    "\n",
    "# Function to perform randomized search for hyperparameter tuning\n",
    "def tune_model_with_random_search(model, X_train, y_train, param_dist, n_iter=5, cv=3):\n",
    "    \"\"\"\n",
    "    Perform RandomizedSearchCV for model hyperparameter tuning.\n",
    "\n",
    "    Parameters:\n",
    "        model: The machine learning model to tune.\n",
    "        X_train (array): Training features.\n",
    "        y_train (array): Training target.\n",
    "        param_dist (dict): Hyperparameter distribution for the model.\n",
    "        n_iter (int): Number of iterations for RandomizedSearchCV (default 5).\n",
    "        cv (int): Number of cross-validation folds (default 3).\n",
    "\n",
    "    Returns:\n",
    "        RandomizedSearchCV: Fitted RandomizedSearchCV object.\n",
    "    \"\"\"\n",
    "    random_search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=n_iter, cv=cv, random_state=42, n_jobs=-1)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    return random_search\n",
    "\n",
    "\n",
    "# Function to evaluate model performance\n",
    "def evaluate_model(y_test, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate and return model evaluation metrics.\n",
    "\n",
    "    Parameters:\n",
    "        y_test (array): Actual target values.\n",
    "        y_pred (array): Predicted target values.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing R², RMSE, MAE, mean value, and standard deviation of the output.\n",
    "    \"\"\"\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mean_value = np.mean(y_test)\n",
    "    std_dev = np.std(y_test)\n",
    "    return {\"R^2\": r2, \"RMSE\": rmse, \"MAE\": mae, \"Mean of Output\": mean_value, \"Standard Deviation of Output\": std_dev}\n",
    "\n",
    "\n",
    "# Function to perform cross-validation\n",
    "def cross_validate_model(model, X_train, y_train, cv=3):\n",
    "    \"\"\"\n",
    "    Perform cross-validation and return the scores.\n",
    "\n",
    "    Parameters:\n",
    "        model: The trained model.\n",
    "        X_train (array): Training features.\n",
    "        y_train (array): Training target.\n",
    "        cv (int): Number of cross-validation folds (default 3).\n",
    "\n",
    "    Returns:\n",
    "        array: Cross-validation scores.\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=kf)\n",
    "    return cv_scores\n",
    "\n",
    "\n",
    "# Main function to execute the workflow\n",
    "def main():\n",
    "    # File path and target column\n",
    "    file_path = 'roberta_test_2.csv'\n",
    "    target_column = 'output'\n",
    "\n",
    "    # Load the dataset\n",
    "    X, y = load_dataset(file_path, target_column)\n",
    "\n",
    "    # Preprocess the data (standardization)\n",
    "    X_scaled = preprocess_data(X)\n",
    "\n",
    "    # Apply PCA for dimension reduction\n",
    "    X_pca = apply_pca(X_scaled)\n",
    "\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Support Vector Regression model\n",
    "    model = SVR()\n",
    "\n",
    "    # Define parameter grid for RandomizedSearchCV\n",
    "    param_dist = {\n",
    "        'kernel': ['linear', 'rbf', 'poly'],  # Different kernel functions\n",
    "        'C': [0.1, 1, 10, 100],  # Regularization parameter\n",
    "        'epsilon': [0.1, 0.2, 0.5, 0.3],  # Epsilon for the epsilon-tube\n",
    "        'degree': [2, 3],  # Degree of the polynomial kernel (if applicable)\n",
    "    }\n",
    "\n",
    "    # Perform RandomizedSearchCV for model hyperparameter tuning\n",
    "    random_search = tune_model_with_random_search(model, X_train, y_train, param_dist)\n",
    "\n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_validate_model(random_search.best_estimator_, X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = random_search.best_estimator_.predict(X_test)\n",
    "\n",
    "    # Evaluate model performance\n",
    "    metrics = evaluate_model(y_test, y_pred)\n",
    "\n",
    "    # Output the results\n",
    "    print(f\"Best Parameters: {random_search.best_params_}\")\n",
    "    print(f\"R^2 Score: {metrics['R^2']}\")\n",
    "    print(f\"RMSE: {metrics['RMSE']}\")\n",
    "    print(f\"MAE: {metrics['MAE']}\")\n",
    "    print(f\"Mean of Output: {metrics['Mean of Output']}\")\n",
    "    print(f\"Standard Deviation of Output: {metrics['Standard Deviation of Output']}\")\n",
    "    print(f\"Cross-Validation Scores: {cv_scores}\")\n",
    "    print(f\"Cross-Validation Mean: {cv_scores.mean()}\")\n",
    "    print(f\"Cross-Validation Std Dev: {cv_scores.std()}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2386b6a-afab-4f11-8ec3-9f99b5e9b5b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
