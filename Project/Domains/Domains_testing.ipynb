{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bae0f82-f69b-494d-b03f-3fc86e83a8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RoBERTa embeddings saved to bio_roberta.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "\n",
    "# Function to load data from a CSV file\n",
    "def load_data(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "# Function to load the pre-trained RoBERTa model and tokenizer\n",
    "def load_roberta_model():\n",
    "    tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "    model = RobertaModel.from_pretrained('roberta-base')\n",
    "    return tokenizer, model\n",
    "\n",
    "# Function to compute RoBERTa embeddings for a given text\n",
    "def get_roberta_embedding(text, tokenizer, model):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    # Average token embeddings for simplicity\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "    return embeddings.detach().numpy().flatten()\n",
    "\n",
    "# Function to extract RoBERTa embeddings for a specific column in the DataFrame\n",
    "def extract_embeddings(data, column_name, tokenizer, model):\n",
    "    return data[column_name].apply(lambda text: get_roberta_embedding(str(text), tokenizer, model))\n",
    "\n",
    "# Function to save the embeddings to a CSV file\n",
    "def save_embeddings(embeddings, output_file):\n",
    "    embeddings.to_csv(output_file, index=False)\n",
    "    print(f'Embeddings saved to {output_file}')\n",
    "\n",
    "# Main function to orchestrate the process\n",
    "def main():\n",
    "    # Load data and model\n",
    "    data = load_data('bio.csv')\n",
    "    tokenizer, model = load_roberta_model()\n",
    "    \n",
    "    # Extract embeddings and create a new DataFrame\n",
    "    roberta_input_embeddings = extract_embeddings(data, 'Input', tokenizer, model)\n",
    "    embeddings_df = pd.DataFrame(roberta_input_embeddings.tolist(), columns=[f'embed_{i}' for i in range(roberta_input_embeddings.iloc[0].size)])\n",
    "    \n",
    "    # Add the 'Output' column to the embeddings DataFrame\n",
    "    embeddings_df['output'] = data['Output']\n",
    "    \n",
    "    # Save the embeddings to CSV\n",
    "    save_embeddings(embeddings_df, 'bio_roberta.csv')\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2767e9-cd7c-4e6a-8d5f-b77d5269a767",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RoBERTa embeddings saved to chemistry_roberta.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "\n",
    "# Function to load data from a CSV file\n",
    "def load_data(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "# Function to load the pre-trained RoBERTa model and tokenizer\n",
    "def load_roberta_model():\n",
    "    tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "    model = RobertaModel.from_pretrained('roberta-base')\n",
    "    return tokenizer, model\n",
    "\n",
    "# Function to compute RoBERTa embeddings for a given text\n",
    "def get_roberta_embedding(text, tokenizer, model):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    # Average token embeddings for simplicity\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "    return embeddings.detach().numpy().flatten()\n",
    "\n",
    "# Function to extract RoBERTa embeddings for a specific column in the DataFrame\n",
    "def extract_embeddings(data, column_name, tokenizer, model):\n",
    "    return data[column_name].apply(lambda text: get_roberta_embedding(str(text), tokenizer, model))\n",
    "\n",
    "# Function to save the embeddings to a CSV file\n",
    "def save_embeddings(embeddings, output_file):\n",
    "    embeddings.to_csv(output_file, index=False)\n",
    "    print(f'Embeddings saved to {output_file}')\n",
    "\n",
    "# Main function to orchestrate the process\n",
    "def main():\n",
    "    # Load data and model\n",
    "    data = load_data('chemistry.csv')\n",
    "    tokenizer, model = load_roberta_model()\n",
    "    \n",
    "    # Extract embeddings and create a new DataFrame\n",
    "    roberta_input_embeddings = extract_embeddings(data, 'Input', tokenizer, model)\n",
    "    embeddings_df = pd.DataFrame(roberta_input_embeddings.tolist(), columns=[f'embed_{i}' for i in range(roberta_input_embeddings.iloc[0].size)])\n",
    "    \n",
    "    # Add the 'Output' column to the embeddings DataFrame\n",
    "    embeddings_df['output'] = data['Output']  # Fixed typo: 'Ouput' -> 'Output'\n",
    "    \n",
    "    # Save the embeddings to CSV\n",
    "    save_embeddings(embeddings_df, 'chemistry_roberta.csv')\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc8d053-e63f-4a60-bc54-1c97fad242a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RoBERTa embeddings saved to civics_roberta.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "\n",
    "# Function to load data from a CSV file\n",
    "def load_data(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "# Function to load the pre-trained RoBERTa model and tokenizer\n",
    "def load_roberta_model():\n",
    "    tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "    model = RobertaModel.from_pretrained('roberta-base')\n",
    "    return tokenizer, model\n",
    "\n",
    "# Function to compute RoBERTa embeddings for a given text\n",
    "def get_roberta_embedding(text, tokenizer, model):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    # Average token embeddings for simplicity\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "    return embeddings.detach().numpy().flatten()\n",
    "\n",
    "# Function to extract RoBERTa embeddings for a specific column in the DataFrame\n",
    "def extract_embeddings(data, column_name, tokenizer, model):\n",
    "    return data[column_name].apply(lambda text: get_roberta_embedding(str(text), tokenizer, model))\n",
    "\n",
    "# Function to save the embeddings to a CSV file\n",
    "def save_embeddings(embeddings, output_file):\n",
    "    embeddings.to_csv(output_file, index=False)\n",
    "    print(f'Embeddings saved to {output_file}')\n",
    "\n",
    "# Main function to orchestrate the process\n",
    "def main():\n",
    "    # Load data and model\n",
    "    data = load_data('civics.csv')\n",
    "    tokenizer, model = load_roberta_model()\n",
    "    \n",
    "    # Extract embeddings and create a new DataFrame\n",
    "    roberta_input_embeddings = extract_embeddings(data, 'Input', tokenizer, model)\n",
    "    embeddings_df = pd.DataFrame(roberta_input_embeddings.tolist(), columns=[f'embed_{i}' for i in range(roberta_input_embeddings.iloc[0].size)])\n",
    "    \n",
    "    # Add the 'Output' column to the embeddings DataFrame\n",
    "    embeddings_df['output'] = data['Output']\n",
    "    \n",
    "    # Save the embeddings to CSV\n",
    "    save_embeddings(embeddings_df, 'civics_roberta.csv')\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2de5b2-65b8-4a15-83b7-1cdba7b2e85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RoBERTa embeddings saved to comp_roberta.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "\n",
    "# Function to load data from a CSV file\n",
    "def load_data(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "# Function to load the pre-trained RoBERTa model and tokenizer\n",
    "def load_roberta_model():\n",
    "    tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "    model = RobertaModel.from_pretrained('roberta-base')\n",
    "    return tokenizer, model\n",
    "\n",
    "# Function to compute RoBERTa embeddings for a given text\n",
    "def get_roberta_embedding(text, tokenizer, model):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    # Average token embeddings for simplicity\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "    return embeddings.detach().numpy().flatten()\n",
    "\n",
    "# Function to extract RoBERTa embeddings for a specific column in the DataFrame\n",
    "def extract_embeddings(data, column_name, tokenizer, model):\n",
    "    return data[column_name].apply(lambda text: get_roberta_embedding(str(text), tokenizer, model))\n",
    "\n",
    "# Function to save the embeddings to a CSV file\n",
    "def save_embeddings(embeddings, output_file):\n",
    "    embeddings.to_csv(output_file, index=False)\n",
    "    print(f'Embeddings saved to {output_file}')\n",
    "\n",
    "# Main function to orchestrate the process\n",
    "def main():\n",
    "    # Load data and model\n",
    "    data = load_data('comp.csv')\n",
    "    tokenizer, model = load_roberta_model()\n",
    "    \n",
    "    # Extract embeddings and create a new DataFrame\n",
    "    roberta_input_embeddings = extract_embeddings(data, 'Input', tokenizer, model)\n",
    "    embeddings_df = pd.DataFrame(roberta_input_embeddings.tolist(), columns=[f'embed_{i}' for i in range(roberta_input_embeddings.iloc[0].size)])\n",
    "    \n",
    "    # Add the 'Output' column to the embeddings DataFrame\n",
    "    embeddings_df['output'] = data['Output']\n",
    "    \n",
    "    # Save the embeddings to CSV\n",
    "    save_embeddings(embeddings_df, 'comp_roberta.csv')\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc90893-7a03-47f9-bd21-6ebbd1eca845",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RoBERTa embeddings saved to english_roberta.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "\n",
    "# Function to load data from a CSV file\n",
    "def load_data(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "# Function to load the pre-trained RoBERTa model and tokenizer\n",
    "def load_roberta_model():\n",
    "    tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "    model = RobertaModel.from_pretrained('roberta-base')\n",
    "    return tokenizer, model\n",
    "\n",
    "# Function to compute RoBERTa embeddings for a given text\n",
    "def get_roberta_embedding(text, tokenizer, model):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    # Average token embeddings for simplicity\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "    return embeddings.detach().numpy().flatten()\n",
    "\n",
    "# Function to extract RoBERTa embeddings for a specific column in the DataFrame\n",
    "def extract_embeddings(data, column_name, tokenizer, model):\n",
    "    return data[column_name].apply(lambda text: get_roberta_embedding(str(text), tokenizer, model))\n",
    "\n",
    "# Function to save the embeddings to a CSV file\n",
    "def save_embeddings(embeddings, output_file):\n",
    "    embeddings.to_csv(output_file, index=False)\n",
    "    print(f'Embeddings saved to {output_file}')\n",
    "\n",
    "# Main function to orchestrate the process\n",
    "def main():\n",
    "    # Load data and model\n",
    "    data = load_data('english.csv')\n",
    "    tokenizer, model = load_roberta_model()\n",
    "    \n",
    "    # Extract embeddings and create a new DataFrame\n",
    "    roberta_input_embeddings = extract_embeddings(data, 'Input', tokenizer, model)\n",
    "    embeddings_df = pd.DataFrame(roberta_input_embeddings.tolist(), columns=[f'embed_{i}' for i in range(roberta_input_embeddings.iloc[0].size)])\n",
    "    \n",
    "    # Add the 'Output' column to the embeddings DataFrame\n",
    "    embeddings_df['output'] = data['Output']\n",
    "    \n",
    "    # Save the embeddings to CSV\n",
    "    save_embeddings(embeddings_df, 'english_roberta.csv')\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77389b4-29ad-4572-ad38-9ddb9736470b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RoBERTa embeddings saved to geo_roberta.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "\n",
    "# Function to load data from a CSV file\n",
    "def load_data(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "# Function to load the pre-trained RoBERTa model and tokenizer\n",
    "def load_roberta_model():\n",
    "    tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "    model = RobertaModel.from_pretrained('roberta-base')\n",
    "    return tokenizer, model\n",
    "\n",
    "# Function to compute RoBERTa embeddings for a given text\n",
    "def get_roberta_embedding(text, tokenizer, model):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    # Average token embeddings for simplicity\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "    return embeddings.detach().numpy().flatten()\n",
    "\n",
    "# Function to extract RoBERTa embeddings for a specific column in the DataFrame\n",
    "def extract_embeddings(data, column_name, tokenizer, model):\n",
    "    return data[column_name].apply(lambda text: get_roberta_embedding(str(text), tokenizer, model))\n",
    "\n",
    "# Function to save the embeddings to a CSV file\n",
    "def save_embeddings(embeddings, output_file):\n",
    "    embeddings.to_csv(output_file, index=False)\n",
    "    print(f'Embeddings saved to {output_file}')\n",
    "\n",
    "# Main function to orchestrate the process\n",
    "def main():\n",
    "    # Load data and model\n",
    "    data = load_data('geo.csv')\n",
    "    tokenizer, model = load_roberta_model()\n",
    "    \n",
    "    # Extract embeddings and create a new DataFrame\n",
    "    roberta_input_embeddings = extract_embeddings(data, 'Input', tokenizer, model)\n",
    "    embeddings_df = pd.DataFrame(roberta_input_embeddings.tolist(), columns=[f'embed_{i}' for i in range(roberta_input_embeddings.iloc[0].size)])\n",
    "    \n",
    "    # Add the 'Output' column to the embeddings DataFrame\n",
    "    embeddings_df['output'] = data['Output']\n",
    "    \n",
    "    # Save the embeddings to CSV\n",
    "    save_embeddings(embeddings_df, 'geo_roberta.csv')\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1398285-6900-4fd1-95e7-89ccdaffb72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RoBERTa embeddings saved to history_roberta.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "\n",
    "# Function to load data from a CSV file\n",
    "def load_data(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "# Function to load the pre-trained RoBERTa model and tokenizer\n",
    "def load_roberta_model():\n",
    "    tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "    model = RobertaModel.from_pretrained('roberta-base')\n",
    "    return tokenizer, model\n",
    "\n",
    "# Function to compute RoBERTa embeddings for a given text\n",
    "def get_roberta_embedding(text, tokenizer, model):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    # Average token embeddings for simplicity\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "    return embeddings.detach().numpy().flatten()\n",
    "\n",
    "# Function to extract RoBERTa embeddings for a specific column in the DataFrame\n",
    "def extract_embeddings(data, column_name, tokenizer, model):\n",
    "    return data[column_name].apply(lambda text: get_roberta_embedding(str(text), tokenizer, model))\n",
    "\n",
    "# Function to save the embeddings to a CSV file\n",
    "def save_embeddings(embeddings, output_file):\n",
    "    embeddings.to_csv(output_file, index=False)\n",
    "    print(f'Embeddings saved to {output_file}')\n",
    "\n",
    "# Main function to orchestrate the process\n",
    "def main():\n",
    "    # Load data and model\n",
    "    data = load_data('history.csv')\n",
    "    tokenizer, model = load_roberta_model()\n",
    "    \n",
    "    # Extract embeddings and create a new DataFrame\n",
    "    roberta_input_embeddings = extract_embeddings(data, 'Input', tokenizer, model)\n",
    "    embeddings_df = pd.DataFrame(roberta_input_embeddings.tolist(), columns=[f'embed_{i}' for i in range(roberta_input_embeddings.iloc[0].size)])\n",
    "    \n",
    "    # Add the 'Output' column to the embeddings DataFrame\n",
    "    embeddings_df['output'] = data['Output']\n",
    "    \n",
    "    # Save the embeddings to CSV\n",
    "    save_embeddings(embeddings_df, 'history_roberta.csv')\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a3c397-861a-4abe-9547-1c6f34cd7474",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RoBERTa embeddings saved to network_roberta.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "\n",
    "# Function to load data from a CSV file\n",
    "def load_data(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "# Function to load the pre-trained RoBERTa model and tokenizer\n",
    "def load_roberta_model():\n",
    "    tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "    model = RobertaModel.from_pretrained('roberta-base')\n",
    "    return tokenizer, model\n",
    "\n",
    "# Function to compute RoBERTa embeddings for a given text\n",
    "def get_roberta_embedding(text, tokenizer, model):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    # Average token embeddings for simplicity\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "    return embeddings.detach().numpy().flatten()\n",
    "\n",
    "# Function to extract RoBERTa embeddings for a specific column in the DataFrame\n",
    "def extract_embeddings(data, column_name, tokenizer, model):\n",
    "    return data[column_name].apply(lambda text: get_roberta_embedding(str(text), tokenizer, model))\n",
    "\n",
    "# Function to save the embeddings to a CSV file\n",
    "def save_embeddings(embeddings, output_file):\n",
    "    embeddings.to_csv(output_file, index=False)\n",
    "    print(f'Embeddings saved to {output_file}')\n",
    "\n",
    "# Main function to orchestrate the process\n",
    "def main():\n",
    "    # Load data and model\n",
    "    data = load_data('network.csv')\n",
    "    tokenizer, model = load_roberta_model()\n",
    "    \n",
    "    # Extract embeddings and create a new DataFrame\n",
    "    roberta_input_embeddings = extract_embeddings(data, 'Input', tokenizer, model)\n",
    "    embeddings_df = pd.DataFrame(roberta_input_embeddings.tolist(), columns=[f'embed_{i}' for i in range(roberta_input_embeddings.iloc[0].size)])\n",
    "    \n",
    "    # Add the 'Output' column to the embeddings DataFrame\n",
    "    embeddings_df['output'] = data['Output']\n",
    "    \n",
    "    # Save the embeddings to CSV\n",
    "    save_embeddings(embeddings_df, 'network_roberta.csv')\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1d8826-4b63-4023-9fc9-60f22e5f1511",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RoBERTa embeddings saved to algebra_roberta.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "\n",
    "# Function to load data from a CSV file\n",
    "def load_data(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "# Function to load the pre-trained RoBERTa model and tokenizer\n",
    "def load_roberta_model():\n",
    "    tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "    model = RobertaModel.from_pretrained('roberta-base')\n",
    "    return tokenizer, model\n",
    "\n",
    "# Function to compute RoBERTa embeddings for a given text\n",
    "def get_roberta_embedding(text, tokenizer, model):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    # Average token embeddings for simplicity\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "    return embeddings.detach().numpy().flatten()\n",
    "\n",
    "# Function to extract RoBERTa embeddings for a specific column in the DataFrame\n",
    "def extract_embeddings(data, column_name, tokenizer, model):\n",
    "    return data[column_name].apply(lambda text: get_roberta_embedding(str(text), tokenizer, model))\n",
    "\n",
    "# Function to save the embeddings to a CSV file\n",
    "def save_embeddings(embeddings, output_file):\n",
    "    embeddings.to_csv(output_file, index=False)\n",
    "    print(f'Embeddings saved to {output_file}')\n",
    "\n",
    "# Main function to orchestrate the process\n",
    "def main():\n",
    "    # Load data and model\n",
    "    data = load_data('algebra.csv')\n",
    "    tokenizer, model = load_roberta_model()\n",
    "    \n",
    "    # Extract embeddings and create a new DataFrame\n",
    "    roberta_input_embeddings = extract_embeddings(data, 'Input', tokenizer, model)\n",
    "    embeddings_df = pd.DataFrame(roberta_input_embeddings.tolist(), columns=[f'embed_{i}' for i in range(roberta_input_embeddings.iloc[0].size)])\n",
    "    \n",
    "    # Add the 'Output' column to the embeddings DataFrame\n",
    "    embeddings_df['output'] = data['Output']\n",
    "    \n",
    "    # Save the embeddings to CSV\n",
    "    save_embeddings(embeddings_df, 'algebra_roberta.csv')\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d7c9f6-11ba-4db5-b768-c0030382fc09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Linear Regression...\n",
      "Evaluating Polynomial Regression...\n",
      "Evaluating Lasso Regression...\n",
      "Evaluating Logistic Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Bayesian Linear Regression...\n",
      "Evaluating Support Vector Regression...\n",
      "Evaluating Decision Tree Regression...\n",
      "Evaluating Gaussian Process Regression...\n",
      "Evaluating Random Forest Regression...\n",
      "Evaluating KNN Regression...\n",
      "\n",
      "----------------------------------------\n",
      "Model: Linear Regression\n",
      "Best Params: None\n",
      "RMSE: 1.7013\n",
      "R^2: 0.2282\n",
      "MAE: 1.3251\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Polynomial Regression\n",
      "Best Params: None\n",
      "RMSE: 1.6733\n",
      "R^2: 0.2534\n",
      "MAE: 1.2928\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Lasso Regression\n",
      "Best Params: {'alpha': 0.01}\n",
      "RMSE: 1.7452\n",
      "R^2: 0.1878\n",
      "MAE: 1.4298\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Logistic Regression\n",
      "Best Params: None\n",
      "RMSE: 2.0917\n",
      "R^2: -0.1667\n",
      "MAE: 1.3750\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Bayesian Linear Regression\n",
      "Best Params: None\n",
      "RMSE: 1.6649\n",
      "R^2: 0.2608\n",
      "MAE: 1.3809\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Support Vector Regression\n",
      "Best Params: {'C': 1, 'kernel': 'linear'}\n",
      "RMSE: 1.6901\n",
      "R^2: 0.2383\n",
      "MAE: 1.3582\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Decision Tree Regression\n",
      "Best Params: {'max_depth': 10}\n",
      "RMSE: 2.4109\n",
      "R^2: -0.5500\n",
      "MAE: 1.5625\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Gaussian Process Regression\n",
      "Best Params: {'alpha': 1e-10}\n",
      "RMSE: 2.0426\n",
      "R^2: -0.1126\n",
      "MAE: 1.4061\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Random Forest Regression\n",
      "Best Params: {'max_depth': 10, 'n_estimators': 100}\n",
      "RMSE: 1.8496\n",
      "R^2: 0.0878\n",
      "MAE: 1.6213\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: KNN Regression\n",
      "Best Params: {'n_neighbors': 5}\n",
      "RMSE: 2.0359\n",
      "R^2: -0.1053\n",
      "MAE: 1.6250\n",
      "----------------------------------------\n",
      "\n",
      "Summary of Metrics:\n",
      "Mean RMSE: 1.8905\n",
      "Std Dev RMSE: 0.2477\n",
      "Mean R^2: 0.0322\n",
      "Std Dev R^2: 0.2641\n",
      "Mean MAE: 1.4377\n",
      "Std Dev MAE: 0.1213\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Lasso, BayesianRidge, LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "def load_data(file_path):\n",
    "    \"\"\"Load dataset from a CSV file.\"\"\"\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "def preprocess_data(data):\n",
    "    \"\"\"Preprocess the data: split into features and target.\"\"\"\n",
    "    X = data.drop(columns=['output'])\n",
    "    y = data['output']\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "def define_models():\n",
    "    \"\"\"Define regression models.\"\"\"\n",
    "    return {\n",
    "        'Linear Regression': LinearRegression(),\n",
    "        'Polynomial Regression': Pipeline([\n",
    "            ('poly', PolynomialFeatures(degree=2)),\n",
    "            ('linear', LinearRegression())\n",
    "        ]),\n",
    "        'Lasso Regression': Lasso(),\n",
    "        'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "        'Bayesian Linear Regression': BayesianRidge(),\n",
    "        'Support Vector Regression': SVR(),\n",
    "        'Decision Tree Regression': DecisionTreeRegressor(),\n",
    "        'Gaussian Process Regression': GaussianProcessRegressor(),\n",
    "        'Random Forest Regression': RandomForestRegressor(),\n",
    "        'KNN Regression': KNeighborsRegressor()\n",
    "    }\n",
    "\n",
    "\n",
    "def define_param_grids():\n",
    "    \"\"\"Define hyperparameter grids for models.\"\"\"\n",
    "    return {\n",
    "        'Lasso Regression': {'alpha': [0.01, 0.1, 1, 10]},\n",
    "        'Support Vector Regression': {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']},\n",
    "        'Decision Tree Regression': {'max_depth': [3, 5, 10, None]},\n",
    "        'Random Forest Regression': {'n_estimators': [10, 50, 100], 'max_depth': [3, 5, 10, None]},\n",
    "        'KNN Regression': {'n_neighbors': [3, 5, 10]},\n",
    "        'Gaussian Process Regression': {'alpha': [1e-10, 1e-5, 1e-2]},\n",
    "    }\n",
    "\n",
    "\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test, param_grid=None):\n",
    "    \"\"\"Evaluate a single model with optional hyperparameter tuning.\"\"\"\n",
    "    if param_grid:\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=10, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_params = grid_search.best_params_\n",
    "    else:\n",
    "        best_model = model\n",
    "        best_model.fit(X_train, y_train)\n",
    "        best_params = None\n",
    "\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    return best_model, best_params, rmse, r2, mae\n",
    "\n",
    "\n",
    "def evaluate_all_models(models, param_grids, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Evaluate all models in the provided dictionary.\"\"\"\n",
    "    results = []\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"Evaluating {model_name}...\")\n",
    "\n",
    "        param_grid = param_grids.get(model_name, None)\n",
    "        best_model, best_params, rmse, r2, mae = evaluate_model(model, X_train, y_train, X_test, y_test, param_grid)\n",
    "\n",
    "        results.append({\n",
    "            'Model': model_name,\n",
    "            'Best Params': best_params,\n",
    "            'RMSE': rmse,\n",
    "            'R^2': r2,\n",
    "            'MAE': mae\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "def print_model_results(results_df):\n",
    "    \"\"\"Print the evaluation results for all models.\"\"\"\n",
    "    for index, row in results_df.iterrows():\n",
    "        print(\"\\n----------------------------------------\")\n",
    "        print(f\"Model: {row['Model']}\")\n",
    "        print(f\"Best Params: {row['Best Params']}\")\n",
    "        print(f\"RMSE: {row['RMSE']:.4f}\")\n",
    "        print(f\"R^2: {row['R^2']:.4f}\")\n",
    "        print(f\"MAE: {row['MAE']:.4f}\")\n",
    "        print(\"----------------------------------------\")\n",
    "\n",
    "\n",
    "def print_summary(results_df):\n",
    "    \"\"\"Print summary statistics of the model evaluations.\"\"\"\n",
    "    print(\"\\nSummary of Metrics:\")\n",
    "    print(f\"Mean RMSE: {results_df['RMSE'].mean():.4f}\")\n",
    "    print(f\"Std Dev RMSE: {results_df['RMSE'].std():.4f}\")\n",
    "    print(f\"Mean R^2: {results_df['R^2'].mean():.4f}\")\n",
    "    print(f\"Std Dev R^2: {results_df['R^2'].std():.4f}\")\n",
    "    print(f\"Mean MAE: {results_df['MAE'].mean():.4f}\")\n",
    "    print(f\"Std Dev MAE: {results_df['MAE'].std():.4f}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to execute the pipeline.\"\"\"\n",
    "    # Load and preprocess data\n",
    "    data = load_data('algebra_roberta.csv')\n",
    "    X_train, X_test, y_train, y_test = preprocess_data(data)\n",
    "\n",
    "    # Define models and parameters\n",
    "    models = define_models()\n",
    "    param_grids = define_param_grids()\n",
    "\n",
    "    # Evaluate all models\n",
    "    results_df = evaluate_all_models(models, param_grids, X_train, y_train, X_test, y_test)\n",
    "\n",
    "    # Print detailed results and summary\n",
    "    print_model_results(results_df)\n",
    "    print_summary(results_df)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e71def-b0ca-4371-92fd-aea103d5fe89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Linear Regression...\n",
      "Evaluating Polynomial Regression...\n",
      "Evaluating Lasso Regression...\n",
      "Evaluating Logistic Regression...\n",
      "Evaluating Bayesian Linear Regression...\n",
      "Evaluating Support Vector Regression...\n",
      "Evaluating Decision Tree Regression...\n",
      "Evaluating Gaussian Process Regression...\n",
      "Evaluating Random Forest Regression...\n",
      "Evaluating KNN Regression...\n",
      "\n",
      "----------------------------------------\n",
      "Model: Linear Regression\n",
      "Best Params: None\n",
      "RMSE: 2.3197\n",
      "R^2: 0.1031\n",
      "MAE: 1.7811\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Polynomial Regression\n",
      "Best Params: None\n",
      "RMSE: 2.4954\n",
      "R^2: -0.0379\n",
      "MAE: 1.8049\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Lasso Regression\n",
      "Best Params: {'alpha': 0.1}\n",
      "RMSE: 2.7140\n",
      "R^2: -0.2276\n",
      "MAE: 2.5198\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Logistic Regression\n",
      "Best Params: None\n",
      "RMSE: 3.1623\n",
      "R^2: -0.6667\n",
      "MAE: 2.0000\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Bayesian Linear Regression\n",
      "Best Params: None\n",
      "RMSE: 2.4830\n",
      "R^2: -0.0276\n",
      "MAE: 2.4527\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Support Vector Regression\n",
      "Best Params: {'C': 10, 'kernel': 'rbf'}\n",
      "RMSE: 2.6670\n",
      "R^2: -0.1855\n",
      "MAE: 2.4106\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Decision Tree Regression\n",
      "Best Params: {'max_depth': 3}\n",
      "RMSE: 1.3416\n",
      "R^2: 0.7000\n",
      "MAE: 0.6000\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Gaussian Process Regression\n",
      "Best Params: {'alpha': 1e-10}\n",
      "RMSE: 2.9616\n",
      "R^2: -0.4619\n",
      "MAE: 1.9836\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Random Forest Regression\n",
      "Best Params: {'max_depth': 10, 'n_estimators': 10}\n",
      "RMSE: 2.0293\n",
      "R^2: 0.3137\n",
      "MAE: 1.9000\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: KNN Regression\n",
      "Best Params: {'n_neighbors': 10}\n",
      "RMSE: 2.4273\n",
      "R^2: 0.0180\n",
      "MAE: 2.4000\n",
      "----------------------------------------\n",
      "\n",
      "Summary of Metrics:\n",
      "Mean RMSE: 2.4601\n",
      "Std Dev RMSE: 0.5067\n",
      "Mean R^2: -0.0472\n",
      "Std Dev R^2: 0.3834\n",
      "Mean MAE: 1.9853\n",
      "Std Dev MAE: 0.5635\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Lasso, BayesianRidge, LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "def load_data(file_path):\n",
    "    \"\"\"Load dataset from a CSV file.\"\"\"\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "def preprocess_data(data):\n",
    "    \"\"\"Preprocess the data: split into features and target.\"\"\"\n",
    "    X = data.drop(columns=['output'])\n",
    "    y = data['output']\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "def define_models():\n",
    "    \"\"\"Define regression models.\"\"\"\n",
    "    return {\n",
    "        'Linear Regression': LinearRegression(),\n",
    "        'Polynomial Regression': Pipeline([\n",
    "            ('poly', PolynomialFeatures(degree=2)),\n",
    "            ('linear', LinearRegression())\n",
    "        ]),\n",
    "        'Lasso Regression': Lasso(),\n",
    "        'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "        'Bayesian Linear Regression': BayesianRidge(),\n",
    "        'Support Vector Regression': SVR(),\n",
    "        'Decision Tree Regression': DecisionTreeRegressor(),\n",
    "        'Gaussian Process Regression': GaussianProcessRegressor(),\n",
    "        'Random Forest Regression': RandomForestRegressor(),\n",
    "        'KNN Regression': KNeighborsRegressor()\n",
    "    }\n",
    "\n",
    "\n",
    "def define_param_grids():\n",
    "    \"\"\"Define hyperparameter grids for models.\"\"\"\n",
    "    return {\n",
    "        'Lasso Regression': {'alpha': [0.01, 0.1, 1, 10]},\n",
    "        'Support Vector Regression': {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']},\n",
    "        'Decision Tree Regression': {'max_depth': [3, 5, 10, None]},\n",
    "        'Random Forest Regression': {'n_estimators': [10, 50, 100], 'max_depth': [3, 5, 10, None]},\n",
    "        'KNN Regression': {'n_neighbors': [3, 5, 10]},\n",
    "        'Gaussian Process Regression': {'alpha': [1e-10, 1e-5, 1e-2]},\n",
    "    }\n",
    "\n",
    "\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test, param_grid=None):\n",
    "    \"\"\"Evaluate a single model with optional hyperparameter tuning.\"\"\"\n",
    "    if param_grid:\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=10, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_params = grid_search.best_params_\n",
    "    else:\n",
    "        best_model = model\n",
    "        best_model.fit(X_train, y_train)\n",
    "        best_params = None\n",
    "\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    return best_model, best_params, rmse, r2, mae\n",
    "\n",
    "\n",
    "def evaluate_all_models(models, param_grids, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Evaluate all models in the provided dictionary.\"\"\"\n",
    "    results = []\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"Evaluating {model_name}...\")\n",
    "\n",
    "        param_grid = param_grids.get(model_name, None)\n",
    "        best_model, best_params, rmse, r2, mae = evaluate_model(model, X_train, y_train, X_test, y_test, param_grid)\n",
    "\n",
    "        results.append({\n",
    "            'Model': model_name,\n",
    "            'Best Params': best_params,\n",
    "            'RMSE': rmse,\n",
    "            'R^2': r2,\n",
    "            'MAE': mae\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "def print_model_results(results_df):\n",
    "    \"\"\"Print the evaluation results for all models.\"\"\"\n",
    "    for index, row in results_df.iterrows():\n",
    "        print(\"\\n----------------------------------------\")\n",
    "        print(f\"Model: {row['Model']}\")\n",
    "        print(f\"Best Params: {row['Best Params']}\")\n",
    "        print(f\"RMSE: {row['RMSE']:.4f}\")\n",
    "        print(f\"R^2: {row['R^2']:.4f}\")\n",
    "        print(f\"MAE: {row['MAE']:.4f}\")\n",
    "        print(\"----------------------------------------\")\n",
    "\n",
    "\n",
    "def print_summary(results_df):\n",
    "    \"\"\"Print summary statistics of the model evaluations.\"\"\"\n",
    "    print(\"\\nSummary of Metrics:\")\n",
    "    print(f\"Mean RMSE: {results_df['RMSE'].mean():.4f}\")\n",
    "    print(f\"Std Dev RMSE: {results_df['RMSE'].std():.4f}\")\n",
    "    print(f\"Mean R^2: {results_df['R^2'].mean():.4f}\")\n",
    "    print(f\"Std Dev R^2: {results_df['R^2'].std():.4f}\")\n",
    "    print(f\"Mean MAE: {results_df['MAE'].mean():.4f}\")\n",
    "    print(f\"Std Dev MAE: {results_df['MAE'].std():.4f}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to execute the pipeline.\"\"\"\n",
    "    # Load and preprocess data\n",
    "    data = load_data('bio_roberta.csv')\n",
    "    X_train, X_test, y_train, y_test = preprocess_data(data)\n",
    "\n",
    "    # Define models and parameters\n",
    "    models = define_models()\n",
    "    param_grids = define_param_grids()\n",
    "\n",
    "    # Evaluate all models\n",
    "    results_df = evaluate_all_models(models, param_grids, X_train, y_train, X_test, y_test)\n",
    "\n",
    "    # Print detailed results and summary\n",
    "    print_model_results(results_df)\n",
    "    print_summary(results_df)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39900f74-cca4-47eb-b818-7c8e54b944b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Linear Regression...\n",
      "Evaluating Polynomial Regression...\n",
      "Evaluating Lasso Regression...\n",
      "Evaluating Logistic Regression...\n",
      "Evaluating Bayesian Linear Regression...\n",
      "Evaluating Support Vector Regression...\n",
      "Evaluating Decision Tree Regression...\n",
      "Evaluating Gaussian Process Regression...\n",
      "Evaluating Random Forest Regression...\n",
      "Evaluating KNN Regression...\n",
      "\n",
      "----------------------------------------\n",
      "Model: Linear Regression\n",
      "Best Params: None\n",
      "RMSE: 2.7192\n",
      "R^2: -0.4253\n",
      "MAE: 2.3546\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Polynomial Regression\n",
      "Best Params: None\n",
      "RMSE: 2.6875\n",
      "R^2: -0.3923\n",
      "MAE: 2.3802\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Lasso Regression\n",
      "Best Params: {'alpha': 0.01}\n",
      "RMSE: 2.1127\n",
      "R^2: 0.1396\n",
      "MAE: 2.0061\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Logistic Regression\n",
      "Best Params: None\n",
      "RMSE: 3.2404\n",
      "R^2: -1.0241\n",
      "MAE: 2.5000\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Bayesian Linear Regression\n",
      "Best Params: None\n",
      "RMSE: 2.6991\n",
      "R^2: -0.4043\n",
      "MAE: 2.3588\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Support Vector Regression\n",
      "Best Params: {'C': 0.1, 'kernel': 'linear'}\n",
      "RMSE: 2.3480\n",
      "R^2: -0.0628\n",
      "MAE: 2.0520\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Decision Tree Regression\n",
      "Best Params: {'max_depth': 5}\n",
      "RMSE: 2.9155\n",
      "R^2: -0.6386\n",
      "MAE: 2.5000\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Gaussian Process Regression\n",
      "Best Params: {'alpha': 1e-10}\n",
      "RMSE: 3.2931\n",
      "R^2: -1.0905\n",
      "MAE: 2.5261\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Random Forest Regression\n",
      "Best Params: {'max_depth': 3, 'n_estimators': 50}\n",
      "RMSE: 2.5747\n",
      "R^2: -0.2779\n",
      "MAE: 2.2950\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: KNN Regression\n",
      "Best Params: {'n_neighbors': 3}\n",
      "RMSE: 2.7538\n",
      "R^2: -0.4618\n",
      "MAE: 2.4167\n",
      "----------------------------------------\n",
      "\n",
      "Summary of Metrics:\n",
      "Mean RMSE: 2.7344\n",
      "Std Dev RMSE: 0.3600\n",
      "Mean R^2: -0.4638\n",
      "Std Dev R^2: 0.3811\n",
      "Mean MAE: 2.3389\n",
      "Std Dev MAE: 0.1796\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Lasso, BayesianRidge, LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "def load_data(file_path):\n",
    "    \"\"\"Load dataset from a CSV file.\"\"\"\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "def preprocess_data(data):\n",
    "    \"\"\"Preprocess the data: split into features and target.\"\"\"\n",
    "    X = data.drop(columns=['output'])\n",
    "    y = data['output']\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "def define_models():\n",
    "    \"\"\"Define regression models.\"\"\"\n",
    "    return {\n",
    "        'Linear Regression': LinearRegression(),\n",
    "        'Polynomial Regression': Pipeline([\n",
    "            ('poly', PolynomialFeatures(degree=2)),\n",
    "            ('linear', LinearRegression())\n",
    "        ]),\n",
    "        'Lasso Regression': Lasso(),\n",
    "        'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "        'Bayesian Linear Regression': BayesianRidge(),\n",
    "        'Support Vector Regression': SVR(),\n",
    "        'Decision Tree Regression': DecisionTreeRegressor(),\n",
    "        'Gaussian Process Regression': GaussianProcessRegressor(),\n",
    "        'Random Forest Regression': RandomForestRegressor(),\n",
    "        'KNN Regression': KNeighborsRegressor()\n",
    "    }\n",
    "\n",
    "\n",
    "def define_param_grids():\n",
    "    \"\"\"Define hyperparameter grids for models.\"\"\"\n",
    "    return {\n",
    "        'Lasso Regression': {'alpha': [0.01, 0.1, 1, 10]},\n",
    "        'Support Vector Regression': {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']},\n",
    "        'Decision Tree Regression': {'max_depth': [3, 5, 10, None]},\n",
    "        'Random Forest Regression': {'n_estimators': [10, 50, 100], 'max_depth': [3, 5, 10, None]},\n",
    "        'KNN Regression': {'n_neighbors': [3, 5, 10]},\n",
    "        'Gaussian Process Regression': {'alpha': [1e-10, 1e-5, 1e-2]},\n",
    "    }\n",
    "\n",
    "\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test, param_grid=None):\n",
    "    \"\"\"Evaluate a single model with optional hyperparameter tuning.\"\"\"\n",
    "    if param_grid:\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=10, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_params = grid_search.best_params_\n",
    "    else:\n",
    "        best_model = model\n",
    "        best_model.fit(X_train, y_train)\n",
    "        best_params = None\n",
    "\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    return best_model, best_params, rmse, r2, mae\n",
    "\n",
    "\n",
    "def evaluate_all_models(models, param_grids, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Evaluate all models in the provided dictionary.\"\"\"\n",
    "    results = []\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"Evaluating {model_name}...\")\n",
    "\n",
    "        param_grid = param_grids.get(model_name, None)\n",
    "        best_model, best_params, rmse, r2, mae = evaluate_model(model, X_train, y_train, X_test, y_test, param_grid)\n",
    "\n",
    "        results.append({\n",
    "            'Model': model_name,\n",
    "            'Best Params': best_params,\n",
    "            'RMSE': rmse,\n",
    "            'R^2': r2,\n",
    "            'MAE': mae\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "def print_model_results(results_df):\n",
    "    \"\"\"Print the evaluation results for all models.\"\"\"\n",
    "    for index, row in results_df.iterrows():\n",
    "        print(\"\\n----------------------------------------\")\n",
    "        print(f\"Model: {row['Model']}\")\n",
    "        print(f\"Best Params: {row['Best Params']}\")\n",
    "        print(f\"RMSE: {row['RMSE']:.4f}\")\n",
    "        print(f\"R^2: {row['R^2']:.4f}\")\n",
    "        print(f\"MAE: {row['MAE']:.4f}\")\n",
    "        print(\"----------------------------------------\")\n",
    "\n",
    "\n",
    "def print_summary(results_df):\n",
    "    \"\"\"Print summary statistics of the model evaluations.\"\"\"\n",
    "    print(\"\\nSummary of Metrics:\")\n",
    "    print(f\"Mean RMSE: {results_df['RMSE'].mean():.4f}\")\n",
    "    print(f\"Std Dev RMSE: {results_df['RMSE'].std():.4f}\")\n",
    "    print(f\"Mean R^2: {results_df['R^2'].mean():.4f}\")\n",
    "    print(f\"Std Dev R^2: {results_df['R^2'].std():.4f}\")\n",
    "    print(f\"Mean MAE: {results_df['MAE'].mean():.4f}\")\n",
    "    print(f\"Std Dev MAE: {results_df['MAE'].std():.4f}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to execute the pipeline.\"\"\"\n",
    "    # Load and preprocess data\n",
    "    data = load_data('chemistry_roberta.csv')\n",
    "    X_train, X_test, y_train, y_test = preprocess_data(data)\n",
    "\n",
    "    # Define models and parameters\n",
    "    models = define_models()\n",
    "    param_grids = define_param_grids()\n",
    "\n",
    "    # Evaluate all models\n",
    "    results_df = evaluate_all_models(models, param_grids, X_train, y_train, X_test, y_test)\n",
    "\n",
    "    # Print detailed results and summary\n",
    "    print_model_results(results_df)\n",
    "    print_summary(results_df)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b539f1e-175c-4804-b511-68c7c3909457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Linear Regression...\n",
      "Evaluating Polynomial Regression...\n",
      "Evaluating Lasso Regression...\n",
      "Evaluating Logistic Regression...\n",
      "Evaluating Bayesian Linear Regression...\n",
      "Evaluating Support Vector Regression...\n",
      "Evaluating Decision Tree Regression...\n",
      "Evaluating Gaussian Process Regression...\n",
      "Evaluating Random Forest Regression...\n",
      "Evaluating KNN Regression...\n",
      "\n",
      "----------------------------------------\n",
      "Model: Linear Regression\n",
      "Best Params: None\n",
      "RMSE: 1.3554\n",
      "R^2: 0.7060\n",
      "MAE: 1.0210\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Polynomial Regression\n",
      "Best Params: None\n",
      "RMSE: 1.2640\n",
      "R^2: 0.7444\n",
      "MAE: 1.0696\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Lasso Regression\n",
      "Best Params: {'alpha': 0.1}\n",
      "RMSE: 2.1307\n",
      "R^2: 0.2736\n",
      "MAE: 1.8064\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Logistic Regression\n",
      "Best Params: None\n",
      "RMSE: 2.5000\n",
      "R^2: 0.0000\n",
      "MAE: 1.2500\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Bayesian Linear Regression\n",
      "Best Params: None\n",
      "RMSE: 1.8893\n",
      "R^2: 0.4289\n",
      "MAE: 1.5497\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Support Vector Regression\n",
      "Best Params: {'C': 1, 'kernel': 'linear'}\n",
      "RMSE: 1.9477\n",
      "R^2: 0.3930\n",
      "MAE: 1.3780\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Decision Tree Regression\n",
      "Best Params: {'max_depth': 3}\n",
      "RMSE: 2.5000\n",
      "R^2: 0.0000\n",
      "MAE: 1.2500\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Gaussian Process Regression\n",
      "Best Params: {'alpha': 1e-10}\n",
      "RMSE: 1.9690\n",
      "R^2: 0.3797\n",
      "MAE: 1.2618\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Random Forest Regression\n",
      "Best Params: {'max_depth': None, 'n_estimators': 10}\n",
      "RMSE: 2.3759\n",
      "R^2: 0.0968\n",
      "MAE: 2.2500\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: KNN Regression\n",
      "Best Params: {'n_neighbors': 3}\n",
      "RMSE: 2.1016\n",
      "R^2: 0.2933\n",
      "MAE: 1.9167\n",
      "----------------------------------------\n",
      "\n",
      "Summary of Metrics:\n",
      "Mean RMSE: 2.0034\n",
      "Std Dev RMSE: 0.4271\n",
      "Mean R^2: 0.3316\n",
      "Std Dev R^2: 0.2595\n",
      "Mean MAE: 1.4753\n",
      "Std Dev MAE: 0.3997\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Lasso, BayesianRidge, LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def load_data(file_path):\n",
    "    \"\"\"Load dataset from a CSV file.\"\"\"\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "def preprocess_data(data):\n",
    "    \"\"\"Preprocess data: split into features and target.\"\"\"\n",
    "    X = data.drop(columns=['output'])\n",
    "    y = data['output']\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "def define_models():\n",
    "    \"\"\"Define regression models.\"\"\"\n",
    "    return {\n",
    "        'Linear Regression': LinearRegression(),\n",
    "        'Polynomial Regression': Pipeline([\n",
    "            ('poly', PolynomialFeatures(degree=2)),\n",
    "            ('linear', LinearRegression())\n",
    "        ]),\n",
    "        'Lasso Regression': Lasso(),\n",
    "        'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "        'Bayesian Linear Regression': BayesianRidge(),\n",
    "        'Support Vector Regression': SVR(),\n",
    "        'Decision Tree Regression': DecisionTreeRegressor(),\n",
    "        'Gaussian Process Regression': GaussianProcessRegressor(),\n",
    "        'Random Forest Regression': RandomForestRegressor(),\n",
    "        'KNN Regression': KNeighborsRegressor()\n",
    "    }\n",
    "\n",
    "def define_param_grids():\n",
    "    \"\"\"Define hyperparameter grids for models.\"\"\"\n",
    "    return {\n",
    "        'Lasso Regression': {'alpha': [0.01, 0.1, 1, 10]},\n",
    "        'Support Vector Regression': {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']},\n",
    "        'Decision Tree Regression': {'max_depth': [3, 5, 10, None]},\n",
    "        'Random Forest Regression': {'n_estimators': [10, 50, 100], 'max_depth': [3, 5, 10, None]},\n",
    "        'KNN Regression': {'n_neighbors': [3, 5, 10]},\n",
    "        'Gaussian Process Regression': {'alpha': [1e-10, 1e-5, 1e-2]},\n",
    "    }\n",
    "\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test, param_grid=None):\n",
    "    \"\"\"Evaluate a single model with optional hyperparameter tuning.\"\"\"\n",
    "    if param_grid:\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=10, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_params = grid_search.best_params_\n",
    "    else:\n",
    "        best_model = model\n",
    "        best_model.fit(X_train, y_train)\n",
    "        best_params = None\n",
    "\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    return best_model, best_params, rmse, r2, mae\n",
    "\n",
    "def evaluate_all_models(models, param_grids, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Evaluate all models in the provided dictionary.\"\"\"\n",
    "    results = []\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"Evaluating {model_name}...\")\n",
    "\n",
    "        param_grid = param_grids.get(model_name, None)\n",
    "        best_model, best_params, rmse, r2, mae = evaluate_model(model, X_train, y_train, X_test, y_test, param_grid)\n",
    "\n",
    "        results.append({\n",
    "            'Model': model_name,\n",
    "            'Best Params': best_params,\n",
    "            'RMSE': rmse,\n",
    "            'R^2': r2,\n",
    "            'MAE': mae\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def print_model_results(results_df):\n",
    "    \"\"\"Print the evaluation results for all models.\"\"\"\n",
    "    for index, row in results_df.iterrows():\n",
    "        print(\"\\n----------------------------------------\")\n",
    "        print(f\"Model: {row['Model']}\")\n",
    "        print(f\"Best Params: {row['Best Params']}\")\n",
    "        print(f\"RMSE: {row['RMSE']:.4f}\")\n",
    "        print(f\"R^2: {row['R^2']:.4f}\")\n",
    "        print(f\"MAE: {row['MAE']:.4f}\")\n",
    "        print(\"----------------------------------------\")\n",
    "\n",
    "def print_summary(results_df):\n",
    "    \"\"\"Print summary statistics of the model evaluations.\"\"\"\n",
    "    print(\"\\nSummary of Metrics:\")\n",
    "    print(f\"Mean RMSE: {results_df['RMSE'].mean():.4f}\")\n",
    "    print(f\"Std Dev RMSE: {results_df['RMSE'].std():.4f}\")\n",
    "    print(f\"Mean R^2: {results_df['R^2'].mean():.4f}\")\n",
    "    print(f\"Std Dev R^2: {results_df['R^2'].std():.4f}\")\n",
    "    print(f\"Mean MAE: {results_df['MAE'].mean():.4f}\")\n",
    "    print(f\"Std Dev MAE: {results_df['MAE'].std():.4f}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to execute the pipeline.\"\"\"\n",
    "    # Load and preprocess data\n",
    "    data = load_data('civics_roberta.csv')\n",
    "    X_train, X_test, y_train, y_test = preprocess_data(data)\n",
    "\n",
    "    # Define models and parameters\n",
    "    models = define_models()\n",
    "    param_grids = define_param_grids()\n",
    "\n",
    "    # Evaluate all models\n",
    "    results_df = evaluate_all_models(models, param_grids, X_train, y_train, X_test, y_test)\n",
    "\n",
    "    # Print detailed results and summary\n",
    "    print_model_results(results_df)\n",
    "    print_summary(results_df)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a60aa12-bec5-43f9-9fed-7f5373d496ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Linear Regression...\n",
      "Evaluating Polynomial Regression...\n",
      "Evaluating Lasso Regression...\n",
      "Evaluating Logistic Regression...\n",
      "Evaluating Bayesian Linear Regression...\n",
      "Evaluating Support Vector Regression...\n",
      "Evaluating Decision Tree Regression...\n",
      "Evaluating Gaussian Process Regression...\n",
      "Evaluating Random Forest Regression...\n",
      "Evaluating KNN Regression...\n",
      "\n",
      "----------------------------------------\n",
      "Model: Linear Regression\n",
      "Best Params: None\n",
      "RMSE: 0.2820\n",
      "R^2: 0.9810\n",
      "MAE: 0.2122\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Polynomial Regression\n",
      "Best Params: None\n",
      "RMSE: 0.2887\n",
      "R^2: 0.9801\n",
      "MAE: 0.2078\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Lasso Regression\n",
      "Best Params: {'alpha': 0.01}\n",
      "RMSE: 0.5023\n",
      "R^2: 0.9397\n",
      "MAE: 0.4373\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Logistic Regression\n",
      "Best Params: None\n",
      "RMSE: 1.0000\n",
      "R^2: 0.7612\n",
      "MAE: 0.5000\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Bayesian Linear Regression\n",
      "Best Params: None\n",
      "RMSE: 0.2782\n",
      "R^2: 0.9815\n",
      "MAE: 0.2001\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Support Vector Regression\n",
      "Best Params: {'C': 1, 'kernel': 'linear'}\n",
      "RMSE: 0.3133\n",
      "R^2: 0.9766\n",
      "MAE: 0.2677\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Decision Tree Regression\n",
      "Best Params: {'max_depth': 10}\n",
      "RMSE: 1.0000\n",
      "R^2: 0.7612\n",
      "MAE: 0.5000\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Gaussian Process Regression\n",
      "Best Params: {'alpha': 1e-05}\n",
      "RMSE: 0.9834\n",
      "R^2: 0.7690\n",
      "MAE: 0.5025\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Random Forest Regression\n",
      "Best Params: {'max_depth': 5, 'n_estimators': 50}\n",
      "RMSE: 0.5972\n",
      "R^2: 0.9148\n",
      "MAE: 0.4700\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: KNN Regression\n",
      "Best Params: {'n_neighbors': 3}\n",
      "RMSE: 0.8333\n",
      "R^2: 0.8342\n",
      "MAE: 0.4167\n",
      "----------------------------------------\n",
      "\n",
      "Summary of Metrics:\n",
      "Mean RMSE: 0.6078\n",
      "Std Dev RMSE: 0.3187\n",
      "Mean R^2: 0.8899\n",
      "Std Dev R^2: 0.0979\n",
      "Mean MAE: 0.3714\n",
      "Std Dev MAE: 0.1328\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Lasso, BayesianRidge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Function to load dataset\n",
    "def load_data(filepath):\n",
    "    data = pd.read_csv(filepath)\n",
    "    X = data.drop(columns=['output'])\n",
    "    y = data['output']\n",
    "    return X, y\n",
    "\n",
    "# Function to split data into training and test sets\n",
    "def split_data(X, y, test_size=0.2, random_state=42):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Function to define models and hyperparameters\n",
    "def define_models():\n",
    "    models = {\n",
    "        'Linear Regression': LinearRegression(),\n",
    "        'Polynomial Regression': Pipeline([('poly', PolynomialFeatures(degree=2)), ('linear', LinearRegression())]),\n",
    "        'Lasso Regression': Lasso(),\n",
    "        'Bayesian Linear Regression': BayesianRidge(),\n",
    "        'Support Vector Regression': SVR(),\n",
    "        'Decision Tree Regression': DecisionTreeRegressor(),\n",
    "        'Gaussian Process Regression': GaussianProcessRegressor(),\n",
    "        'Random Forest Regression': RandomForestRegressor(),\n",
    "        'KNN Regression': KNeighborsRegressor()\n",
    "    }\n",
    "    \n",
    "    param_grids = {\n",
    "        'Lasso Regression': {'alpha': [0.01, 0.1, 1, 10]},\n",
    "        'Support Vector Regression': {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']},\n",
    "        'Decision Tree Regression': {'max_depth': [3, 5, 10, None]},\n",
    "        'Random Forest Regression': {'n_estimators': [10, 50, 100], 'max_depth': [3, 5, 10, None]},\n",
    "        'KNN Regression': {'n_neighbors': [3, 5, 10]},\n",
    "        'Gaussian Process Regression': {'alpha': [1e-10, 1e-5, 1e-2]},\n",
    "    }\n",
    "    \n",
    "    return models, param_grids\n",
    "\n",
    "# Function to perform grid search and model fitting\n",
    "def evaluate_model(model, model_name, X_train, y_train, X_test, y_test, param_grid=None):\n",
    "    if param_grid:\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=10, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_params = grid_search.best_params_\n",
    "    else:\n",
    "        best_model = model\n",
    "        best_model.fit(X_train, y_train)\n",
    "        best_params = None\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    return best_model, best_params, rmse, r2, mae\n",
    "\n",
    "# Function to evaluate and store results for all models\n",
    "def evaluate_models(models, param_grids, X_train, y_train, X_test, y_test):\n",
    "    results = []\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"Evaluating {model_name}...\")\n",
    "        \n",
    "        param_grid = param_grids.get(model_name, None)\n",
    "        best_model, best_params, rmse, r2, mae = evaluate_model(model, model_name, X_train, y_train, X_test, y_test, param_grid)\n",
    "\n",
    "        # Store results\n",
    "        results.append({\n",
    "            'Model': model_name,\n",
    "            'Best Params': best_params,\n",
    "            'RMSE': rmse,\n",
    "            'R^2': r2,\n",
    "            'MAE': mae\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Function to summarize results\n",
    "def summarize_results(results):\n",
    "    results_df = pd.DataFrame(results)\n",
    "    # Print metrics for each model\n",
    "    for index, row in results_df.iterrows():\n",
    "        print(\"\\n----------------------------------------\")\n",
    "        print(f\"Model: {row['Model']}\")\n",
    "        print(f\"Best Params: {row['Best Params']}\")\n",
    "        print(f\"RMSE: {row['RMSE']:.4f}\")\n",
    "        print(f\"R^2: {row['R^2']:.4f}\")\n",
    "        print(f\"MAE: {row['MAE']:.4f}\")\n",
    "        print(\"----------------------------------------\")\n",
    "\n",
    "    # Print summary of metrics\n",
    "    print(\"\\nSummary of Metrics:\")\n",
    "    print(f\"Mean RMSE: {results_df['RMSE'].mean():.4f}\")\n",
    "    print(f\"Std Dev RMSE: {results_df['RMSE'].std():.4f}\")\n",
    "    print(f\"Mean R^2: {results_df['R^2'].mean():.4f}\")\n",
    "    print(f\"Std Dev R^2: {results_df['R^2'].std():.4f}\")\n",
    "    print(f\"Mean MAE: {results_df['MAE'].mean():.4f}\")\n",
    "    print(f\"Std Dev MAE: {results_df['MAE'].std():.4f}\")\n",
    "\n",
    "# Main function to execute the workflow\n",
    "def main():\n",
    "    # Load data\n",
    "    X, y = load_data('comp_roberta.csv')\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = split_data(X, y)\n",
    "\n",
    "    # Define models and parameters\n",
    "    models, param_grids = define_models()\n",
    "\n",
    "    # Evaluate models\n",
    "    results = evaluate_models(models, param_grids, X_train, y_train, X_test, y_test)\n",
    "\n",
    "    # Summarize results\n",
    "    summarize_results(results)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1587a3-ff4a-4dd4-aaf6-a38d61804186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Linear Regression...\n",
      "Evaluating Polynomial Regression...\n",
      "Evaluating Lasso Regression...\n",
      "Evaluating Logistic Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Bayesian Linear Regression...\n",
      "Evaluating Support Vector Regression...\n",
      "Evaluating Decision Tree Regression...\n",
      "Evaluating Gaussian Process Regression...\n",
      "Evaluating Random Forest Regression...\n",
      "Evaluating KNN Regression...\n",
      "\n",
      "----------------------------------------\n",
      "Model: Linear Regression\n",
      "Best Params: None\n",
      "RMSE: 14695204319.3341\n",
      "R^2: -62193320636248539136.0000\n",
      "MAE: 10383136626.0581\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Polynomial Regression\n",
      "Best Params: None\n",
      "RMSE: 4133128005916.6470\n",
      "R^2: -4919831168628244390871040.0000\n",
      "MAE: 3286727818770.4727\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Lasso Regression\n",
      "Best Params: {'alpha': 0.1}\n",
      "RMSE: 1.1726\n",
      "R^2: 0.6040\n",
      "MAE: 1.1345\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Logistic Regression\n",
      "Best Params: None\n",
      "RMSE: 1.7795\n",
      "R^2: 0.0880\n",
      "MAE: 1.1667\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Bayesian Linear Regression\n",
      "Best Params: None\n",
      "RMSE: 1.3760\n",
      "R^2: 0.4547\n",
      "MAE: 1.3256\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Support Vector Regression\n",
      "Best Params: {'C': 10, 'kernel': 'rbf'}\n",
      "RMSE: 1.5738\n",
      "R^2: 0.2867\n",
      "MAE: 1.4715\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Decision Tree Regression\n",
      "Best Params: {'max_depth': 10}\n",
      "RMSE: 2.9155\n",
      "R^2: -1.4480\n",
      "MAE: 2.5000\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Gaussian Process Regression\n",
      "Best Params: {'alpha': 1e-10}\n",
      "RMSE: 2.3644\n",
      "R^2: -0.6100\n",
      "MAE: 1.9110\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Random Forest Regression\n",
      "Best Params: {'max_depth': 10, 'n_estimators': 10}\n",
      "RMSE: 1.3260\n",
      "R^2: 0.4936\n",
      "MAE: 1.1833\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: KNN Regression\n",
      "Best Params: {'n_neighbors': 10}\n",
      "RMSE: 1.4537\n",
      "R^2: 0.3914\n",
      "MAE: 1.3333\n",
      "----------------------------------------\n",
      "\n",
      "Summary of Metrics:\n",
      "Mean RMSE: 414782321024.9943\n",
      "Std Dev RMSE: 1306501661519.2773\n",
      "Mean R^2: -491989336194888054603776.0000\n",
      "Std Dev R^2: 1555785034507555849633792.0000\n",
      "Mean MAE: 329711095540.8557\n",
      "Std Dev MAE: 1038994893527.0939\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Lasso, BayesianRidge, LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Function to load the dataset\n",
    "def load_data(filepath):\n",
    "    data = pd.read_csv(filepath)\n",
    "    X = data.drop(columns=['output'])\n",
    "    y = data['output']\n",
    "    return X, y\n",
    "\n",
    "# Function to split data into training and test sets\n",
    "def split_data(X, y, test_size=0.2, random_state=42):\n",
    "    return train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "# Function to define models and their respective hyperparameters\n",
    "def define_models():\n",
    "    models = {\n",
    "        'Linear Regression': LinearRegression(),\n",
    "        'Polynomial Regression': Pipeline([('poly', PolynomialFeatures(degree=2)), ('linear', LinearRegression())]),\n",
    "        'Lasso Regression': Lasso(),\n",
    "        'Logistic Regression': LogisticRegression(),\n",
    "        'Bayesian Linear Regression': BayesianRidge(),\n",
    "        'Support Vector Regression': SVR(),\n",
    "        'Decision Tree Regression': DecisionTreeRegressor(),\n",
    "        'Gaussian Process Regression': GaussianProcessRegressor(),\n",
    "        'Random Forest Regression': RandomForestRegressor(),\n",
    "        'KNN Regression': KNeighborsRegressor()\n",
    "    }\n",
    "    \n",
    "    param_grids = {\n",
    "        'Lasso Regression': {'alpha': [0.01, 0.1, 1, 10]},\n",
    "        'Support Vector Regression': {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']},\n",
    "        'Decision Tree Regression': {'max_depth': [3, 5, 10, None]},\n",
    "        'Random Forest Regression': {'n_estimators': [10, 50, 100], 'max_depth': [3, 5, 10, None]},\n",
    "        'KNN Regression': {'n_neighbors': [3, 5, 10]},\n",
    "        'Gaussian Process Regression': {'alpha': [1e-10, 1e-5, 1e-2]},\n",
    "    }\n",
    "    \n",
    "    return models, param_grids\n",
    "\n",
    "# Function to evaluate a model and return its best estimator and metrics\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test, param_grid=None):\n",
    "    if param_grid:\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=10, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_params = grid_search.best_params_\n",
    "    else:\n",
    "        best_model = model\n",
    "        best_model.fit(X_train, y_train)\n",
    "        best_params = None\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    return best_model, best_params, rmse, r2, mae\n",
    "\n",
    "# Function to evaluate all models and collect results\n",
    "def evaluate_models(models, param_grids, X_train, y_train, X_test, y_test):\n",
    "    results = []\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"Evaluating {model_name}...\")\n",
    "        \n",
    "        param_grid = param_grids.get(model_name, None)\n",
    "        best_model, best_params, rmse, r2, mae = evaluate_model(model, X_train, y_train, X_test, y_test, param_grid)\n",
    "\n",
    "        # Store results\n",
    "        results.append({\n",
    "            'Model': model_name,\n",
    "            'Best Params': best_params,\n",
    "            'RMSE': rmse,\n",
    "            'R^2': r2,\n",
    "            'MAE': mae\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Function to summarize and print the results\n",
    "def summarize_results(results):\n",
    "    results_df = pd.DataFrame(results)\n",
    "    # Print metrics for each model\n",
    "    for index, row in results_df.iterrows():\n",
    "        print(\"\\n----------------------------------------\")\n",
    "        print(f\"Model: {row['Model']}\")\n",
    "        print(f\"Best Params: {row['Best Params']}\")\n",
    "        print(f\"RMSE: {row['RMSE']:.4f}\")\n",
    "        print(f\"R^2: {row['R^2']:.4f}\")\n",
    "        print(f\"MAE: {row['MAE']:.4f}\")\n",
    "        print(\"----------------------------------------\")\n",
    "\n",
    "    # Print summary of metrics\n",
    "    print(\"\\nSummary of Metrics:\")\n",
    "    print(f\"Mean RMSE: {results_df['RMSE'].mean():.4f}\")\n",
    "    print(f\"Std Dev RMSE: {results_df['RMSE'].std():.4f}\")\n",
    "    print(f\"Mean R^2: {results_df['R^2'].mean():.4f}\")\n",
    "    print(f\"Std Dev R^2: {results_df['R^2'].std():.4f}\")\n",
    "    print(f\"Mean MAE: {results_df['MAE'].mean():.4f}\")\n",
    "    print(f\"Std Dev MAE: {results_df['MAE'].std():.4f}\")\n",
    "\n",
    "# Main function to execute the workflow\n",
    "def main():\n",
    "    # Load data\n",
    "    X, y = load_data('english_roberta.csv')\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = split_data(X, y)\n",
    "\n",
    "    # Define models and parameters\n",
    "    models, param_grids = define_models()\n",
    "\n",
    "    # Evaluate models\n",
    "    results = evaluate_models(models, param_grids, X_train, y_train, X_test, y_test)\n",
    "\n",
    "    # Summarize results\n",
    "    summarize_results(results)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f951ec-3ae8-4744-aa94-d47fd5b3c4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Linear Regression...\n",
      "Evaluating Polynomial Regression...\n",
      "Evaluating Lasso Regression...\n",
      "Evaluating Logistic Regression...\n",
      "Evaluating Bayesian Linear Regression...\n",
      "Evaluating Support Vector Regression...\n",
      "Evaluating Decision Tree Regression...\n",
      "Evaluating Gaussian Process Regression...\n",
      "Evaluating Random Forest Regression...\n",
      "Evaluating KNN Regression...\n",
      "\n",
      "----------------------------------------\n",
      "Model: Linear Regression\n",
      "Best Params: None\n",
      "RMSE: 451119938494.8196\n",
      "R^2: -46252090660811328978944.0000\n",
      "MAE: 336609131456.5133\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Polynomial Regression\n",
      "Best Params: None\n",
      "RMSE: 216014295918.0266\n",
      "R^2: -10605040009309270835200.0000\n",
      "MAE: 188686538045.5258\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Lasso Regression\n",
      "Best Params: {'alpha': 0.01}\n",
      "RMSE: 2.1603\n",
      "R^2: -0.0607\n",
      "MAE: 1.7963\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Logistic Regression\n",
      "Best Params: None\n",
      "RMSE: 2.6077\n",
      "R^2: -0.5455\n",
      "MAE: 2.0000\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Bayesian Linear Regression\n",
      "Best Params: None\n",
      "RMSE: 1.6830\n",
      "R^2: 0.3562\n",
      "MAE: 1.3406\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Support Vector Regression\n",
      "Best Params: {'C': 10, 'kernel': 'linear'}\n",
      "RMSE: 1.7020\n",
      "R^2: 0.3417\n",
      "MAE: 1.2381\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Decision Tree Regression\n",
      "Best Params: {'max_depth': 3}\n",
      "RMSE: 3.3166\n",
      "R^2: -1.5000\n",
      "MAE: 2.6000\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Gaussian Process Regression\n",
      "Best Params: {'alpha': 0.01}\n",
      "RMSE: 2.9849\n",
      "R^2: -1.0249\n",
      "MAE: 2.3253\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Random Forest Regression\n",
      "Best Params: {'max_depth': 10, 'n_estimators': 10}\n",
      "RMSE: 1.7390\n",
      "R^2: 0.3127\n",
      "MAE: 1.4400\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: KNN Regression\n",
      "Best Params: {'n_neighbors': 3}\n",
      "RMSE: 2.3805\n",
      "R^2: -0.2879\n",
      "MAE: 1.6667\n",
      "----------------------------------------\n",
      "\n",
      "Summary of Metrics:\n",
      "Mean RMSE: 66713423443.1420\n",
      "Std Dev RMSE: 151167517922.4436\n",
      "Mean R^2: -5685713067012060610560.0000\n",
      "Std Dev R^2: 14638038094449695784960.0000\n",
      "Mean MAE: 52529566951.6446\n",
      "Std Dev MAE: 116100896244.1437\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Lasso, BayesianRidge, LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Function to load the dataset\n",
    "def load_data(filepath):\n",
    "    data = pd.read_csv(filepath)\n",
    "    X = data.drop(columns=['output'])\n",
    "    y = data['output']\n",
    "    return X, y\n",
    "\n",
    "# Function to split data into training and test sets\n",
    "def split_data(X, y, test_size=0.2, random_state=42):\n",
    "    return train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "# Function to define models and their respective hyperparameters\n",
    "def define_models():\n",
    "    models = {\n",
    "        'Linear Regression': LinearRegression(),\n",
    "        'Polynomial Regression': Pipeline([('poly', PolynomialFeatures(degree=2)), ('linear', LinearRegression())]),\n",
    "        'Lasso Regression': Lasso(),\n",
    "        'Logistic Regression': LogisticRegression(),\n",
    "        'Bayesian Linear Regression': BayesianRidge(),\n",
    "        'Support Vector Regression': SVR(),\n",
    "        'Decision Tree Regression': DecisionTreeRegressor(),\n",
    "        'Gaussian Process Regression': GaussianProcessRegressor(),\n",
    "        'Random Forest Regression': RandomForestRegressor(),\n",
    "        'KNN Regression': KNeighborsRegressor()\n",
    "    }\n",
    "\n",
    "    param_grids = {\n",
    "        'Lasso Regression': {'alpha': [0.01, 0.1, 1, 10]},\n",
    "        'Support Vector Regression': {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']},\n",
    "        'Decision Tree Regression': {'max_depth': [3, 5, 10, None]},\n",
    "        'Random Forest Regression': {'n_estimators': [10, 50, 100], 'max_depth': [3, 5, 10, None]},\n",
    "        'KNN Regression': {'n_neighbors': [3, 5, 10]},\n",
    "        'Gaussian Process Regression': {'alpha': [1e-10, 1e-5, 1e-2]},\n",
    "    }\n",
    "\n",
    "    return models, param_grids\n",
    "\n",
    "# Function to evaluate a model and return its best estimator and metrics\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test, param_grid=None):\n",
    "    if param_grid:\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=10, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_params = grid_search.best_params_\n",
    "    else:\n",
    "        best_model = model\n",
    "        best_model.fit(X_train, y_train)\n",
    "        best_params = None\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    return best_model, best_params, rmse, r2, mae\n",
    "\n",
    "# Function to evaluate all models and collect results\n",
    "def evaluate_models(models, param_grids, X_train, y_train, X_test, y_test):\n",
    "    results = []\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"Evaluating {model_name}...\")\n",
    "        \n",
    "        param_grid = param_grids.get(model_name, None)\n",
    "        best_model, best_params, rmse, r2, mae = evaluate_model(model, X_train, y_train, X_test, y_test, param_grid)\n",
    "\n",
    "        # Store results\n",
    "        results.append({\n",
    "            'Model': model_name,\n",
    "            'Best Params': best_params,\n",
    "            'RMSE': rmse,\n",
    "            'R^2': r2,\n",
    "            'MAE': mae\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Function to summarize and print the results\n",
    "def summarize_results(results):\n",
    "    results_df = pd.DataFrame(results)\n",
    "    # Print metrics for each model\n",
    "    for index, row in results_df.iterrows():\n",
    "        print(\"\\n----------------------------------------\")\n",
    "        print(f\"Model: {row['Model']}\")\n",
    "        print(f\"Best Params: {row['Best Params']}\")\n",
    "        print(f\"RMSE: {row['RMSE']:.4f}\")\n",
    "        print(f\"R^2: {row['R^2']:.4f}\")\n",
    "        print(f\"MAE: {row['MAE']:.4f}\")\n",
    "        print(\"----------------------------------------\")\n",
    "\n",
    "    # Print summary of metrics\n",
    "    print(\"\\nSummary of Metrics:\")\n",
    "    print(f\"Mean RMSE: {results_df['RMSE'].mean():.4f}\")\n",
    "    print(f\"Std Dev RMSE: {results_df['RMSE'].std():.4f}\")\n",
    "    print(f\"Mean R^2: {results_df['R^2'].mean():.4f}\")\n",
    "    print(f\"Std Dev R^2: {results_df['R^2'].std():.4f}\")\n",
    "    print(f\"Mean MAE: {results_df['MAE'].mean():.4f}\")\n",
    "    print(f\"Std Dev MAE: {results_df['MAE'].std():.4f}\")\n",
    "\n",
    "# Main function to execute the workflow\n",
    "def main():\n",
    "    # Load data\n",
    "    X, y = load_data('geo_roberta.csv')\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = split_data(X, y)\n",
    "\n",
    "    # Define models and parameters\n",
    "    models, param_grids = define_models()\n",
    "\n",
    "    # Evaluate models\n",
    "    results = evaluate_models(models, param_grids, X_train, y_train, X_test, y_test)\n",
    "\n",
    "    # Summarize results\n",
    "    summarize_results(results)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7133be0d-2e86-4ff1-83ef-53de08ca8d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Linear Regression...\n",
      "Evaluating Polynomial Regression...\n",
      "Evaluating Lasso Regression...\n",
      "Evaluating Logistic Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Bayesian Linear Regression...\n",
      "Evaluating Support Vector Regression...\n",
      "Evaluating Decision Tree Regression...\n",
      "Evaluating Gaussian Process Regression...\n",
      "Evaluating Random Forest Regression...\n",
      "Evaluating KNN Regression...\n",
      "\n",
      "----------------------------------------\n",
      "Model: Linear Regression\n",
      "Best Params: None\n",
      "RMSE: 15278220200.7725\n",
      "R^2: -86855446512853368832.0000\n",
      "MAE: 10158646861.3898\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Polynomial Regression\n",
      "Best Params: None\n",
      "RMSE: 2368598497769.4995\n",
      "R^2: -2087538174376159653920768.0000\n",
      "MAE: 1688828727306.1777\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Lasso Regression\n",
      "Best Params: {'alpha': 0.01}\n",
      "RMSE: 2.1645\n",
      "R^2: -0.7433\n",
      "MAE: 1.2459\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Logistic Regression\n",
      "Best Params: None\n",
      "RMSE: 2.2638\n",
      "R^2: -0.9070\n",
      "MAE: 1.1250\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Bayesian Linear Regression\n",
      "Best Params: None\n",
      "RMSE: 1.7633\n",
      "R^2: -0.1569\n",
      "MAE: 1.2798\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Support Vector Regression\n",
      "Best Params: {'C': 1, 'kernel': 'linear'}\n",
      "RMSE: 1.6663\n",
      "R^2: -0.0331\n",
      "MAE: 1.0657\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Decision Tree Regression\n",
      "Best Params: {'max_depth': 3}\n",
      "RMSE: 1.9080\n",
      "R^2: -0.3545\n",
      "MAE: 0.9812\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Gaussian Process Regression\n",
      "Best Params: {'alpha': 1e-10}\n",
      "RMSE: 0.5112\n",
      "R^2: 0.9028\n",
      "MAE: 0.3703\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Random Forest Regression\n",
      "Best Params: {'max_depth': 10, 'n_estimators': 50}\n",
      "RMSE: 1.9009\n",
      "R^2: -0.3445\n",
      "MAE: 1.6305\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: KNN Regression\n",
      "Best Params: {'n_neighbors': 5}\n",
      "RMSE: 2.1107\n",
      "R^2: -0.6577\n",
      "MAE: 1.5250\n",
      "----------------------------------------\n",
      "\n",
      "Summary of Metrics:\n",
      "Mean RMSE: 238387671798.4561\n",
      "Std Dev RMSE: 748495190142.1611\n",
      "Mean R^2: -208762502982267259846656.0000\n",
      "Std Dev R^2: 660134482132862521835520.0000\n",
      "Mean MAE: 169898737417.6791\n",
      "Std Dev MAE: 533707145926.7447\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Lasso, BayesianRidge, LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Function to load the dataset\n",
    "def load_data(filepath):\n",
    "    data = pd.read_csv(filepath)\n",
    "    X = data.drop(columns=['output'])\n",
    "    y = data['output']\n",
    "    return X, y\n",
    "\n",
    "# Function to split data into training and test sets\n",
    "def split_data(X, y, test_size=0.2, random_state=42):\n",
    "    return train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "# Function to define models and hyperparameters\n",
    "def define_models():\n",
    "    models = {\n",
    "        'Linear Regression': LinearRegression(),\n",
    "        'Polynomial Regression': Pipeline([('poly', PolynomialFeatures(degree=2)), ('linear', LinearRegression())]),\n",
    "        'Lasso Regression': Lasso(),\n",
    "        'Logistic Regression': LogisticRegression(),\n",
    "        'Bayesian Linear Regression': BayesianRidge(),\n",
    "        'Support Vector Regression': SVR(),\n",
    "        'Decision Tree Regression': DecisionTreeRegressor(),\n",
    "        'Gaussian Process Regression': GaussianProcessRegressor(),\n",
    "        'Random Forest Regression': RandomForestRegressor(),\n",
    "        'KNN Regression': KNeighborsRegressor()\n",
    "    }\n",
    "\n",
    "    param_grids = {\n",
    "        'Lasso Regression': {'alpha': [0.01, 0.1, 1, 10]},\n",
    "        'Support Vector Regression': {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']},\n",
    "        'Decision Tree Regression': {'max_depth': [3, 5, 10, None]},\n",
    "        'Random Forest Regression': {'n_estimators': [10, 50, 100], 'max_depth': [3, 5, 10, None]},\n",
    "        'KNN Regression': {'n_neighbors': [3, 5, 10]},\n",
    "        'Gaussian Process Regression': {'alpha': [1e-10, 1e-5, 1e-2]},\n",
    "    }\n",
    "\n",
    "    return models, param_grids\n",
    "\n",
    "# Function to evaluate a model and return its best estimator and metrics\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test, param_grid=None):\n",
    "    if param_grid:\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=10, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_params = grid_search.best_params_\n",
    "    else:\n",
    "        best_model = model\n",
    "        best_model.fit(X_train, y_train)\n",
    "        best_params = None\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    return best_model, best_params, rmse, r2, mae\n",
    "\n",
    "# Function to evaluate all models and collect results\n",
    "def evaluate_models(models, param_grids, X_train, y_train, X_test, y_test):\n",
    "    results = []\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"Evaluating {model_name}...\")\n",
    "        \n",
    "        param_grid = param_grids.get(model_name, None)\n",
    "        best_model, best_params, rmse, r2, mae = evaluate_model(model, X_train, y_train, X_test, y_test, param_grid)\n",
    "\n",
    "        # Store results\n",
    "        results.append({\n",
    "            'Model': model_name,\n",
    "            'Best Params': best_params,\n",
    "            'RMSE': rmse,\n",
    "            'R^2': r2,\n",
    "            'MAE': mae\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Function to summarize and print the results\n",
    "def summarize_results(results):\n",
    "    results_df = pd.DataFrame(results)\n",
    "    # Print metrics for each model\n",
    "    for index, row in results_df.iterrows():\n",
    "        print(\"\\n----------------------------------------\")\n",
    "        print(f\"Model: {row['Model']}\")\n",
    "        print(f\"Best Params: {row['Best Params']}\")\n",
    "        print(f\"RMSE: {row['RMSE']:.4f}\")\n",
    "        print(f\"R^2: {row['R^2']:.4f}\")\n",
    "        print(f\"MAE: {row['MAE']:.4f}\")\n",
    "        print(\"----------------------------------------\")\n",
    "\n",
    "    # Print summary of metrics\n",
    "    print(\"\\nSummary of Metrics:\")\n",
    "    print(f\"Mean RMSE: {results_df['RMSE'].mean():.4f}\")\n",
    "    print(f\"Std Dev RMSE: {results_df['RMSE'].std():.4f}\")\n",
    "    print(f\"Mean R^2: {results_df['R^2'].mean():.4f}\")\n",
    "    print(f\"Std Dev R^2: {results_df['R^2'].std():.4f}\")\n",
    "    print(f\"Mean MAE: {results_df['MAE'].mean():.4f}\")\n",
    "    print(f\"Std Dev MAE: {results_df['MAE'].std():.4f}\")\n",
    "\n",
    "# Main function to execute the workflow\n",
    "def main():\n",
    "    # Load data\n",
    "    X, y = load_data('geo_roberta.csv')\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = split_data(X, y)\n",
    "\n",
    "    # Define models and parameters\n",
    "    models, param_grids = define_models()\n",
    "\n",
    "    # Evaluate models\n",
    "    results = evaluate_models(models, param_grids, X_train, y_train, X_test, y_test)\n",
    "\n",
    "    # Summarize results\n",
    "    summarize_results(results)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2494a7e-c2cb-4c8a-9d6c-2dbcfde40a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Linear Regression...\n",
      "Evaluating Polynomial Regression...\n",
      "Evaluating Lasso Regression...\n",
      "Evaluating Logistic Regression...\n",
      "Evaluating Bayesian Linear Regression...\n",
      "Evaluating Support Vector Regression...\n",
      "Evaluating Decision Tree Regression...\n",
      "Evaluating Gaussian Process Regression...\n",
      "Evaluating Random Forest Regression...\n",
      "Evaluating KNN Regression...\n",
      "\n",
      "----------------------------------------\n",
      "Model: Linear Regression\n",
      "Best Params: None\n",
      "RMSE: 0.7770\n",
      "R^2: 0.1217\n",
      "MAE: 0.3885\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Polynomial Regression\n",
      "Best Params: None\n",
      "RMSE: 0.7082\n",
      "R^2: 0.2704\n",
      "MAE: 0.3541\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Lasso Regression\n",
      "Best Params: {'alpha': 0.1}\n",
      "RMSE: 1.4327\n",
      "R^2: -1.9858\n",
      "MAE: 1.3654\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Logistic Regression\n",
      "Best Params: None\n",
      "RMSE: 1.5000\n",
      "R^2: -2.2727\n",
      "MAE: 0.7500\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Bayesian Linear Regression\n",
      "Best Params: None\n",
      "RMSE: 0.7470\n",
      "R^2: 0.1883\n",
      "MAE: 0.3735\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Support Vector Regression\n",
      "Best Params: {'C': 1, 'kernel': 'linear'}\n",
      "RMSE: 0.7704\n",
      "R^2: 0.1367\n",
      "MAE: 0.4580\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Decision Tree Regression\n",
      "Best Params: {'max_depth': 3}\n",
      "RMSE: 0.0000\n",
      "R^2: 1.0000\n",
      "MAE: 0.0000\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Gaussian Process Regression\n",
      "Best Params: {'alpha': 1e-10}\n",
      "RMSE: 1.2643\n",
      "R^2: -1.3249\n",
      "MAE: 0.6321\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Random Forest Regression\n",
      "Best Params: {'max_depth': 3, 'n_estimators': 50}\n",
      "RMSE: 0.5699\n",
      "R^2: 0.5276\n",
      "MAE: 0.5200\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: KNN Regression\n",
      "Best Params: {'n_neighbors': 10}\n",
      "RMSE: 1.7088\n",
      "R^2: -3.2473\n",
      "MAE: 1.5000\n",
      "----------------------------------------\n",
      "\n",
      "Summary of Metrics:\n",
      "Mean RMSE: 0.9478\n",
      "Std Dev RMSE: 0.5184\n",
      "Mean R^2: -0.6586\n",
      "Std Dev R^2: 1.4334\n",
      "Mean MAE: 0.6342\n",
      "Std Dev MAE: 0.4656\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Lasso, BayesianRidge, LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Function to load the dataset\n",
    "def load_data(filepath):\n",
    "    data = pd.read_csv(filepath)\n",
    "    X = data.drop(columns=['output'])\n",
    "    y = data['output']\n",
    "    return X, y\n",
    "\n",
    "# Function to split data into training and test sets\n",
    "def split_data(X, y, test_size=0.2, random_state=42):\n",
    "    return train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "# Function to define models and hyperparameters\n",
    "def define_models():\n",
    "    models = {\n",
    "        'Linear Regression': LinearRegression(),\n",
    "        'Polynomial Regression': Pipeline([('poly', PolynomialFeatures(degree=2)), ('linear', LinearRegression())]),\n",
    "        'Lasso Regression': Lasso(),\n",
    "        'Logistic Regression': LogisticRegression(),\n",
    "        'Bayesian Linear Regression': BayesianRidge(),\n",
    "        'Support Vector Regression': SVR(),\n",
    "        'Decision Tree Regression': DecisionTreeRegressor(),\n",
    "        'Gaussian Process Regression': GaussianProcessRegressor(),\n",
    "        'Random Forest Regression': RandomForestRegressor(),\n",
    "        'KNN Regression': KNeighborsRegressor()\n",
    "    }\n",
    "\n",
    "    param_grids = {\n",
    "        'Lasso Regression': {'alpha': [0.01, 0.1, 1, 10]},\n",
    "        'Support Vector Regression': {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']},\n",
    "        'Decision Tree Regression': {'max_depth': [3, 5, 10, None]},\n",
    "        'Random Forest Regression': {'n_estimators': [10, 50, 100], 'max_depth': [3, 5, 10, None]},\n",
    "        'KNN Regression': {'n_neighbors': [3, 5, 10]},\n",
    "        'Gaussian Process Regression': {'alpha': [1e-10, 1e-5, 1e-2]},\n",
    "    }\n",
    "\n",
    "    return models, param_grids\n",
    "\n",
    "# Function to evaluate a model and return its best estimator and metrics\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test, param_grid=None):\n",
    "    if param_grid:\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=10, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_params = grid_search.best_params_\n",
    "    else:\n",
    "        best_model = model\n",
    "        best_model.fit(X_train, y_train)\n",
    "        best_params = None\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    return best_model, best_params, rmse, r2, mae\n",
    "\n",
    "# Function to evaluate all models and collect results\n",
    "def evaluate_models(models, param_grids, X_train, y_train, X_test, y_test):\n",
    "    results = []\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"Evaluating {model_name}...\")\n",
    "        \n",
    "        param_grid = param_grids.get(model_name, None)\n",
    "        best_model, best_params, rmse, r2, mae = evaluate_model(model, X_train, y_train, X_test, y_test, param_grid)\n",
    "\n",
    "        # Store results\n",
    "        results.append({\n",
    "            'Model': model_name,\n",
    "            'Best Params': best_params,\n",
    "            'RMSE': rmse,\n",
    "            'R^2': r2,\n",
    "            'MAE': mae\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Function to summarize and print the results\n",
    "def summarize_results(results):\n",
    "    results_df = pd.DataFrame(results)\n",
    "    # Print metrics for each model\n",
    "    for index, row in results_df.iterrows():\n",
    "        print(\"\\n----------------------------------------\")\n",
    "        print(f\"Model: {row['Model']}\")\n",
    "        print(f\"Best Params: {row['Best Params']}\")\n",
    "        print(f\"RMSE: {row['RMSE']:.4f}\")\n",
    "        print(f\"R^2: {row['R^2']:.4f}\")\n",
    "        print(f\"MAE: {row['MAE']:.4f}\")\n",
    "        print(\"----------------------------------------\")\n",
    "\n",
    "    # Print summary of metrics\n",
    "    print(\"\\nSummary of Metrics:\")\n",
    "    print(f\"Mean RMSE: {results_df['RMSE'].mean():.4f}\")\n",
    "    print(f\"Std Dev RMSE: {results_df['RMSE'].std():.4f}\")\n",
    "    print(f\"Mean R^2: {results_df['R^2'].mean():.4f}\")\n",
    "    print(f\"Std Dev R^2: {results_df['R^2'].std():.4f}\")\n",
    "    print(f\"Mean MAE: {results_df['MAE'].mean():.4f}\")\n",
    "    print(f\"Std Dev MAE: {results_df['MAE'].std():.4f}\")\n",
    "\n",
    "# Main function to execute the workflow\n",
    "def main():\n",
    "    # Load data\n",
    "    X, y = load_data('history_roberta.csv')\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = split_data(X, y)\n",
    "\n",
    "    # Define models and parameters\n",
    "    models, param_grids = define_models()\n",
    "\n",
    "    # Evaluate models\n",
    "    results = evaluate_models(models, param_grids, X_train, y_train, X_test, y_test)\n",
    "\n",
    "    # Summarize results\n",
    "    summarize_results(results)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9d6f9e-eacd-4832-ae04-3c46b201032d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Linear Regression...\n",
      "Evaluating Polynomial Regression...\n",
      "Evaluating Lasso Regression...\n",
      "Evaluating Logistic Regression...\n",
      "Evaluating Bayesian Linear Regression...\n",
      "Evaluating Support Vector Regression...\n",
      "Evaluating Decision Tree Regression...\n",
      "Evaluating Gaussian Process Regression...\n",
      "Evaluating Random Forest Regression...\n",
      "Evaluating KNN Regression...\n",
      "\n",
      "----------------------------------------\n",
      "Model: Linear Regression\n",
      "Best Params: None\n",
      "RMSE: 1.3757\n",
      "R^2: 0.6972\n",
      "MAE: 1.1928\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Polynomial Regression\n",
      "Best Params: None\n",
      "RMSE: 1.5498\n",
      "R^2: 0.6157\n",
      "MAE: 1.3559\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Lasso Regression\n",
      "Best Params: {'alpha': 0.1}\n",
      "RMSE: 1.6319\n",
      "R^2: 0.5739\n",
      "MAE: 1.4316\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Logistic Regression\n",
      "Best Params: None\n",
      "RMSE: 0.0000\n",
      "R^2: 1.0000\n",
      "MAE: 0.0000\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Bayesian Linear Regression\n",
      "Best Params: None\n",
      "RMSE: 1.4613\n",
      "R^2: 0.6583\n",
      "MAE: 1.2765\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Support Vector Regression\n",
      "Best Params: {'C': 1, 'kernel': 'linear'}\n",
      "RMSE: 1.4502\n",
      "R^2: 0.6635\n",
      "MAE: 1.2435\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Decision Tree Regression\n",
      "Best Params: {'max_depth': 5}\n",
      "RMSE: 1.0000\n",
      "R^2: 0.8400\n",
      "MAE: 0.5000\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Gaussian Process Regression\n",
      "Best Params: {'alpha': 1e-10}\n",
      "RMSE: 2.6993\n",
      "R^2: -0.1658\n",
      "MAE: 1.9644\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: Random Forest Regression\n",
      "Best Params: {'max_depth': 5, 'n_estimators': 100}\n",
      "RMSE: 2.0983\n",
      "R^2: 0.2955\n",
      "MAE: 2.0300\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Model: KNN Regression\n",
      "Best Params: {'n_neighbors': 5}\n",
      "RMSE: 1.5588\n",
      "R^2: 0.6112\n",
      "MAE: 1.3500\n",
      "----------------------------------------\n",
      "\n",
      "Summary of Metrics:\n",
      "Mean RMSE: 1.4825\n",
      "Std Dev RMSE: 0.6941\n",
      "Mean R^2: 0.5790\n",
      "Std Dev R^2: 0.3180\n",
      "Mean MAE: 1.2345\n",
      "Std Dev MAE: 0.6055\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Lasso, BayesianRidge, LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Function to load the dataset\n",
    "def load_data(filepath):\n",
    "    data = pd.read_csv(filepath)\n",
    "    X = data.drop(columns=['output'])\n",
    "    y = data['output']\n",
    "    return X, y\n",
    "\n",
    "# Function to split data into training and test sets\n",
    "def split_data(X, y, test_size=0.2, random_state=42):\n",
    "    return train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "# Function to define models and their respective hyperparameters\n",
    "def define_models():\n",
    "    models = {\n",
    "        'Linear Regression': LinearRegression(),\n",
    "        'Polynomial Regression': Pipeline([('poly', PolynomialFeatures(degree=2)), ('linear', LinearRegression())]),\n",
    "        'Lasso Regression': Lasso(),\n",
    "        'Logistic Regression': LogisticRegression(),\n",
    "        'Bayesian Linear Regression': BayesianRidge(),\n",
    "        'Support Vector Regression': SVR(),\n",
    "        'Decision Tree Regression': DecisionTreeRegressor(),\n",
    "        'Gaussian Process Regression': GaussianProcessRegressor(),\n",
    "        'Random Forest Regression': RandomForestRegressor(),\n",
    "        'KNN Regression': KNeighborsRegressor()\n",
    "    }\n",
    "\n",
    "    param_grids = {\n",
    "        'Lasso Regression': {'alpha': [0.01, 0.1, 1, 10]},\n",
    "        'Support Vector Regression': {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']},\n",
    "        'Decision Tree Regression': {'max_depth': [3, 5, 10, None]},\n",
    "        'Random Forest Regression': {'n_estimators': [10, 50, 100], 'max_depth': [3, 5, 10, None]},\n",
    "        'KNN Regression': {'n_neighbors': [3, 5, 10]},\n",
    "        'Gaussian Process Regression': {'alpha': [1e-10, 1e-5, 1e-2]},\n",
    "    }\n",
    "\n",
    "    return models, param_grids\n",
    "\n",
    "# Function to evaluate each model with GridSearchCV where applicable\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test, param_grid=None):\n",
    "    if param_grid:\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=10, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_params = grid_search.best_params_\n",
    "    else:\n",
    "        best_model = model\n",
    "        best_model.fit(X_train, y_train)\n",
    "        best_params = None\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    return best_model, best_params, rmse, r2, mae\n",
    "\n",
    "# Function to evaluate all models and collect results\n",
    "def evaluate_models(models, param_grids, X_train, y_train, X_test, y_test):\n",
    "    results = []\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"Evaluating {model_name}...\")\n",
    "        \n",
    "        param_grid = param_grids.get(model_name, None)\n",
    "        best_model, best_params, rmse, r2, mae = evaluate_model(model, X_train, y_train, X_test, y_test, param_grid)\n",
    "\n",
    "        # Store results\n",
    "        results.append({\n",
    "            'Model': model_name,\n",
    "            'Best Params': best_params,\n",
    "            'RMSE': rmse,\n",
    "            'R^2': r2,\n",
    "            'MAE': mae\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Function to summarize and print the results\n",
    "def summarize_results(results):\n",
    "    results_df = pd.DataFrame(results)\n",
    "    # Print metrics for each model\n",
    "    for index, row in results_df.iterrows():\n",
    "        print(\"\\n----------------------------------------\")\n",
    "        print(f\"Model: {row['Model']}\")\n",
    "        print(f\"Best Params: {row['Best Params']}\")\n",
    "        print(f\"RMSE: {row['RMSE']:.4f}\")\n",
    "        print(f\"R^2: {row['R^2']:.4f}\")\n",
    "        print(f\"MAE: {row['MAE']:.4f}\")\n",
    "        print(\"----------------------------------------\")\n",
    "\n",
    "    # Print summary of metrics\n",
    "    print(\"\\nSummary of Metrics:\")\n",
    "    print(f\"Mean RMSE: {results_df['RMSE'].mean():.4f}\")\n",
    "    print(f\"Std Dev RMSE: {results_df['RMSE'].std():.4f}\")\n",
    "    print(f\"Mean R^2: {results_df['R^2'].mean():.4f}\")\n",
    "    print(f\"Std Dev R^2: {results_df['R^2'].std():.4f}\")\n",
    "    print(f\"Mean MAE: {results_df['MAE'].mean():.4f}\")\n",
    "    print(f\"Std Dev MAE: {results_df['MAE'].std():.4f}\")\n",
    "\n",
    "# Main function to execute the workflow\n",
    "def main():\n",
    "    # Load data\n",
    "    X, y = load_data('network_roberta.csv')\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = split_data(X, y)\n",
    "\n",
    "    # Define models and parameters\n",
    "    models, param_grids = define_models()\n",
    "\n",
    "    # Evaluate models\n",
    "    results = evaluate_models(models, param_grids, X_train, y_train, X_test, y_test)\n",
    "\n",
    "    # Summarize results\n",
    "    summarize_results(results)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28f3d32-9ecf-4ec6-b67d-7a6876a58dcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
