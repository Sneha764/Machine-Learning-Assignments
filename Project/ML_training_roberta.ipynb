{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e8dcc57-8c70-4214-a11a-03158b0db0b6",
   "metadata": {},
   "source": [
    "## Training Roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124d866f-40d2-4e3a-91ef-4d41a06131e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for Linear Regression...\n",
      "Running GridSearchCV for Polynomial Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "20 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1101, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "         ^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 163. GiB for an array with shape (288, 76088705) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1101, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "         ^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 164. GiB for an array with shape (289, 76088705) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1101, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "         ^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 30.8 TiB for an array with shape (288, 14685120065) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1101, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "         ^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 30.9 TiB for an array with shape (289, 14685120065) and data type float64\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [-2.50944101e+23             nan             nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for Lasso Regression...\n",
      "Running GridSearchCV for Logistic Regression...\n",
      "Running GridSearchCV for Bayesian Linear Regression...\n",
      "Running GridSearchCV for Support Vector Regression...\n",
      "Running GridSearchCV for Decision Tree Regression...\n",
      "Running GridSearchCV for Gaussian Process Regression...\n",
      "Running GridSearchCV for Random Forest Regression...\n",
      "Running GridSearchCV for KNN Regression...\n",
      "                         Model  \\\n",
      "6     Decision Tree Regression   \n",
      "3          Logistic Regression   \n",
      "9               KNN Regression   \n",
      "0            Linear Regression   \n",
      "7  Gaussian Process Regression   \n",
      "1        Polynomial Regression   \n",
      "8     Random Forest Regression   \n",
      "4   Bayesian Linear Regression   \n",
      "5    Support Vector Regression   \n",
      "2             Lasso Regression   \n",
      "\n",
      "                                         Best Params   Accuracy  \n",
      "6        {'max_depth': None, 'min_samples_split': 2}  99.376947  \n",
      "3                   {'C': 10, 'solver': 'liblinear'}  98.130841  \n",
      "9          {'n_neighbors': 7, 'weights': 'distance'}  86.604361  \n",
      "0                                                 {}  66.355140  \n",
      "7                                  {'alpha': 0.0001}  64.174455  \n",
      "1                                {'poly__degree': 2}  61.682243  \n",
      "8  {'max_depth': 20, 'min_samples_split': 5, 'n_e...  27.102804  \n",
      "4              {'alpha_1': 1e-06, 'alpha_2': 0.0001}  15.576324  \n",
      "5                          {'C': 10, 'epsilon': 0.5}  10.903427  \n",
      "2                                    {'alpha': 0.01}   9.345794  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Lasso, BayesianRidge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Function to load and preprocess data\n",
    "def load_and_preprocess_data(url):\n",
    "    data = pd.read_csv(url)\n",
    "    X = data.drop(columns=['output']).values\n",
    "    y = data['output'].values\n",
    "    return X, y\n",
    "\n",
    "# Function to standardize features\n",
    "def standardize_features(X):\n",
    "    scaler = StandardScaler()\n",
    "    return scaler.fit_transform(X)\n",
    "\n",
    "# Function to initialize models\n",
    "def initialize_models():\n",
    "    models = {\n",
    "        \"Linear Regression\": LinearRegression(),\n",
    "        \"Polynomial Regression\": Pipeline([('scaler', StandardScaler()), \n",
    "                                          ('poly', PolynomialFeatures(degree=2)), \n",
    "                                          ('linear', LinearRegression())]),\n",
    "        \"Lasso Regression\": Lasso(),\n",
    "        \"Bayesian Linear Regression\": BayesianRidge(),\n",
    "        \"Support Vector Regression\": SVR(),\n",
    "        \"Decision Tree Regression\": DecisionTreeRegressor(),\n",
    "        \"Gaussian Process Regression\": GaussianProcessRegressor(),\n",
    "        \"Random Forest Regression\": RandomForestRegressor(),\n",
    "        \"KNN Regression\": KNeighborsRegressor()\n",
    "    }\n",
    "    return models\n",
    "\n",
    "# Function to define hyperparameter grids for each model\n",
    "def define_param_grids():\n",
    "    param_grids = {\n",
    "        \"Linear Regression\": {},\n",
    "        \"Polynomial Regression\": {'poly__degree': [2, 3, 4]},\n",
    "        \"Lasso Regression\": {'alpha': [0.01, 0.1, 1, 10]},\n",
    "        \"Bayesian Linear Regression\": {'alpha_1': [1e-6, 1e-5, 1e-4], 'alpha_2': [1e-6, 1e-5, 1e-4]},\n",
    "        \"Support Vector Regression\": {'C': [0.1, 1, 10], 'epsilon': [0.01, 0.1, 0.5]},\n",
    "        \"Decision Tree Regression\": {'max_depth': [None, 10, 20, 30], 'min_samples_split': [2, 5, 10]},\n",
    "        \"Gaussian Process Regression\": {'alpha': [1e-2, 1e-3, 1e-4]},\n",
    "        \"Random Forest Regression\": {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20], 'min_samples_split': [2, 5, 10]},\n",
    "        \"KNN Regression\": {'n_neighbors': [3, 5, 7], 'weights': ['uniform', 'distance']}\n",
    "    }\n",
    "    return param_grids\n",
    "\n",
    "# Function to perform GridSearchCV\n",
    "def grid_search_model(model, param_grid, X_train, y_train):\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=10, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return grid_search.best_estimator_, grid_search.best_params_\n",
    "\n",
    "# Function to calculate accuracy based on threshold\n",
    "def calculate_accuracy(y_pred, y_test, threshold=0.1):\n",
    "    correct_predictions = np.abs(y_pred - y_test) <= threshold * np.abs(y_test)\n",
    "    return np.mean(correct_predictions) * 100\n",
    "\n",
    "# Main function to execute model training and evaluation\n",
    "def train_and_evaluate_models(url):\n",
    "    # Load and preprocess data\n",
    "    X, y = load_and_preprocess_data(url)\n",
    "    \n",
    "    # Split the dataset into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize models and hyperparameter grids\n",
    "    models = initialize_models()\n",
    "    param_grids = define_param_grids()\n",
    "\n",
    "    # Initialize results storage\n",
    "    results = []\n",
    "\n",
    "    # Loop through models and perform GridSearchCV\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"Running GridSearchCV for {model_name}...\")\n",
    "        \n",
    "        try:\n",
    "            # Perform grid search for hyperparameter tuning\n",
    "            best_model, best_params = grid_search_model(model, param_grids.get(model_name, {}), X_train, y_train)\n",
    "\n",
    "            # Make predictions using the best model\n",
    "            y_pred = best_model.predict(X_test)\n",
    "\n",
    "            # Calculate accuracy based on the threshold\n",
    "            accuracy = calculate_accuracy(y_pred, y_test)\n",
    "\n",
    "            # Append results\n",
    "            results.append({\n",
    "                'Model': model_name,\n",
    "                'Best Params': best_params,\n",
    "                'Accuracy': accuracy\n",
    "            })\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Model: {model_name} - Error: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    # Convert results to a DataFrame for display\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Print results sorted by accuracy\n",
    "    print(results_df.sort_values(by=\"Accuracy\", ascending=False))\n",
    "\n",
    "# Run the model training and evaluation\n",
    "train_and_evaluate_models('roberta_embeddings_input_output_custom_columns.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdfed09-7253-46be-b47d-99f1fcc2d008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Linear Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\AppData\\Local\\Temp\\ipykernel_9592\\1494525476.py:29: RuntimeWarning: divide by zero encountered in divide\n",
      "  mape = np.mean(np.abs((y - y_pred) / y)) * 100\n",
      "C:\\Users\\Jyoshitha\\AppData\\Local\\Temp\\ipykernel_9592\\1494525476.py:29: RuntimeWarning: invalid value encountered in divide\n",
      "  mape = np.mean(np.abs((y - y_pred) / y)) * 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Polynomial Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "20 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1101, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "         ^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 163. GiB for an array with shape (288, 76088705) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1101, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "         ^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 164. GiB for an array with shape (289, 76088705) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1101, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "         ^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 30.8 TiB for an array with shape (288, 14685120065) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1101, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "         ^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 30.9 TiB for an array with shape (289, 14685120065) and data type float64\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [-2.50944101e+23             nan             nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jyoshitha\\AppData\\Local\\Temp\\ipykernel_9592\\1494525476.py:29: RuntimeWarning: divide by zero encountered in divide\n",
      "  mape = np.mean(np.abs((y - y_pred) / y)) * 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Lasso Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\AppData\\Local\\Temp\\ipykernel_9592\\1494525476.py:29: RuntimeWarning: divide by zero encountered in divide\n",
      "  mape = np.mean(np.abs((y - y_pred) / y)) * 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Logistic Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\AppData\\Local\\Temp\\ipykernel_9592\\1494525476.py:29: RuntimeWarning: divide by zero encountered in divide\n",
      "  mape = np.mean(np.abs((y - y_pred) / y)) * 100\n",
      "C:\\Users\\Jyoshitha\\AppData\\Local\\Temp\\ipykernel_9592\\1494525476.py:29: RuntimeWarning: invalid value encountered in divide\n",
      "  mape = np.mean(np.abs((y - y_pred) / y)) * 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Bayesian Linear Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\AppData\\Local\\Temp\\ipykernel_9592\\1494525476.py:29: RuntimeWarning: divide by zero encountered in divide\n",
      "  mape = np.mean(np.abs((y - y_pred) / y)) * 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Support Vector Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\AppData\\Local\\Temp\\ipykernel_9592\\1494525476.py:29: RuntimeWarning: divide by zero encountered in divide\n",
      "  mape = np.mean(np.abs((y - y_pred) / y)) * 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Decision Tree Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\AppData\\Local\\Temp\\ipykernel_9592\\1494525476.py:29: RuntimeWarning: invalid value encountered in divide\n",
      "  mape = np.mean(np.abs((y - y_pred) / y)) * 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Gaussian Process Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\AppData\\Local\\Temp\\ipykernel_9592\\1494525476.py:29: RuntimeWarning: divide by zero encountered in divide\n",
      "  mape = np.mean(np.abs((y - y_pred) / y)) * 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Random Forest Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\AppData\\Local\\Temp\\ipykernel_9592\\1494525476.py:29: RuntimeWarning: divide by zero encountered in divide\n",
      "  mape = np.mean(np.abs((y - y_pred) / y)) * 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating KNN Regression...\n",
      "                         Model  \\\n",
      "6     Decision Tree Regression   \n",
      "3          Logistic Regression   \n",
      "9               KNN Regression   \n",
      "0            Linear Regression   \n",
      "7  Gaussian Process Regression   \n",
      "1        Polynomial Regression   \n",
      "8     Random Forest Regression   \n",
      "4   Bayesian Linear Regression   \n",
      "5    Support Vector Regression   \n",
      "2             Lasso Regression   \n",
      "\n",
      "                                         Best Params   Accuracy      RMSE  \\\n",
      "6          {'max_depth': 30, 'min_samples_split': 2}  99.376947  0.078934   \n",
      "3                   {'C': 10, 'solver': 'liblinear'}  98.130841  0.249610   \n",
      "9          {'n_neighbors': 7, 'weights': 'distance'}  86.604361  0.078934   \n",
      "0                                                 {}  66.355140  0.078934   \n",
      "7                                  {'alpha': 0.0001}  64.174455  0.078935   \n",
      "1                                {'poly__degree': 2}  61.682243  0.181429   \n",
      "8  {'max_depth': 10, 'min_samples_split': 5, 'n_e...  28.660436  0.658441   \n",
      "4              {'alpha_1': 1e-06, 'alpha_2': 0.0001}  15.576324  0.973599   \n",
      "5                          {'C': 10, 'epsilon': 0.5}  10.903427  1.296582   \n",
      "2                                    {'alpha': 0.01}   9.345794  1.338953   \n",
      "\n",
      "        R^2       MAE  MAPE  \n",
      "6  0.998466  0.006231   NaN  \n",
      "3  0.984664  0.031153   NaN  \n",
      "9  0.998466  0.006231   NaN  \n",
      "0  0.998466  0.006464   NaN  \n",
      "7  0.998466  0.006438   inf  \n",
      "1  0.991898  0.092150   inf  \n",
      "8  0.893286  0.523782   inf  \n",
      "4  0.766682  0.776918   inf  \n",
      "5  0.586202  0.979322   inf  \n",
      "2  0.558715  1.090376   inf  \n",
      "\n",
      "Summary of Metrics:\n",
      "Mean RMSE: 0.50143504953648\n",
      "Std Dev RMSE: 0.49609803869180064\n",
      "Mean R^2: 0.8775313099317961\n",
      "Std Dev R^2: 0.167961356725117\n",
      "Mean MAE: 0.35190644905827606\n",
      "Std Dev MAE: 0.42393191822713494\n",
      "Mean MAPE: nan\n",
      "Std Dev MAPE: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\AppData\\Local\\Temp\\ipykernel_9592\\1494525476.py:29: RuntimeWarning: divide by zero encountered in divide\n",
      "  mape = np.mean(np.abs((y - y_pred) / y)) * 100\n",
      "C:\\Users\\Jyoshitha\\AppData\\Local\\Temp\\ipykernel_9592\\1494525476.py:29: RuntimeWarning: invalid value encountered in divide\n",
      "  mape = np.mean(np.abs((y - y_pred) / y)) * 100\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Initialize results storage for additional metrics\n",
    "additional_results = []\n",
    "\n",
    "# Function to calculate RMSE\n",
    "def calculate_rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Function to calculate R^2\n",
    "def calculate_r2(y_true, y_pred):\n",
    "    return r2_score(y_true, y_pred)\n",
    "\n",
    "# Function to calculate MAE\n",
    "def calculate_mae(y_true, y_pred):\n",
    "    return mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "# Function to calculate MAPE\n",
    "def calculate_mape(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "# Function to calculate accuracy based on threshold\n",
    "def calculate_accuracy(y_true, y_pred, threshold):\n",
    "    correct_predictions = np.abs(y_pred - y_true) <= threshold * np.abs(y_true)\n",
    "    return np.mean(correct_predictions) * 100  # Percentage of correct predictions\n",
    "\n",
    "# Function to perform grid search and evaluation on models\n",
    "def evaluate_models(models, param_grids, X, y, threshold):\n",
    "    global additional_results\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"Evaluating {model_name}...\")\n",
    "\n",
    "        # Apply GridSearchCV with 10-fold cross-validation\n",
    "        grid_search = GridSearchCV(model, param_grids.get(model_name, {}), cv=10, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "        grid_search.fit(X, y)\n",
    "        \n",
    "        # Get the best model and make predictions\n",
    "        best_model = grid_search.best_estimator_\n",
    "        y_pred = best_model.predict(X)\n",
    "        \n",
    "        # Calculate evaluation metrics\n",
    "        rmse = calculate_rmse(y, y_pred)\n",
    "        r2 = calculate_r2(y, y_pred)\n",
    "        mae = calculate_mae(y, y_pred)\n",
    "        mape = calculate_mape(y, y_pred)\n",
    "        accuracy = calculate_accuracy(y, y_pred, threshold)\n",
    "\n",
    "        # Store the results\n",
    "        additional_results.append({\n",
    "            'Model': model_name,\n",
    "            'Best Params': grid_search.best_params_,\n",
    "            'Accuracy': accuracy,\n",
    "            'RMSE': rmse,\n",
    "            'R^2': r2,\n",
    "            'MAE': mae,\n",
    "            'MAPE': mape\n",
    "        })\n",
    "\n",
    "# Function to calculate summary statistics for metrics\n",
    "def calculate_metrics_summary():\n",
    "    rmse_values = [result['RMSE'] for result in additional_results]\n",
    "    r2_values = [result['R^2'] for result in additional_results]\n",
    "    mae_values = [result['MAE'] for result in additional_results]\n",
    "    mape_values = [result['MAPE'] for result in additional_results]\n",
    "    \n",
    "    return {\n",
    "        'Mean RMSE': np.mean(rmse_values),\n",
    "        'Std Dev RMSE': np.std(rmse_values),\n",
    "        'Mean R^2': np.mean(r2_values),\n",
    "        'Std Dev R^2': np.std(r2_values),\n",
    "        'Mean MAE': np.mean(mae_values),\n",
    "        'Std Dev MAE': np.std(mae_values),\n",
    "        'Mean MAPE': np.mean(mape_values),\n",
    "        'Std Dev MAPE': np.std(mape_values),\n",
    "    }\n",
    "\n",
    "# Function to print the evaluation results\n",
    "def print_results():\n",
    "    # Convert results to a DataFrame for display\n",
    "    additional_results_df = pd.DataFrame(additional_results)\n",
    "\n",
    "    # Calculate summary of metrics\n",
    "    metrics_summary = calculate_metrics_summary()\n",
    "\n",
    "    # Print individual model results sorted by accuracy\n",
    "    print(additional_results_df.sort_values(by=\"Accuracy\", ascending=False))\n",
    "\n",
    "    # Print summary of metrics\n",
    "    print(\"\\nSummary of Metrics:\")\n",
    "    for metric, value in metrics_summary.items():\n",
    "        print(f\"{metric}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e210229-3a3d-4387-b8ae-23b529163119",
   "metadata": {},
   "source": [
    "## Testing roberta Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c537af-6c9c-4a49-ac45-33a3bf67bb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Linear Regression\n",
      "Predicted Marks: [1.0289363  5.75741562 2.14466826 1.35928119 4.69795946]\n",
      "Actual Marks: [0 4 2 1 5]\n",
      "----------------------------------------\n",
      "Model: Polynomial Regression (Degree 2)\n",
      "Predicted Marks: [0.35320928 5.68454073 1.96005016 1.06915436 4.45912791]\n",
      "Actual Marks: [0 4 2 1 5]\n",
      "----------------------------------------\n",
      "Model: Lasso Regression\n",
      "Predicted Marks: [1.33864018 2.96700039 2.30919169 1.40855422 3.02428506]\n",
      "Actual Marks: [0 4 2 1 5]\n",
      "----------------------------------------\n",
      "Model: Logistic Regression (used for binary targets)\n",
      "Predicted Marks: [0 5 1 0 5]\n",
      "Actual Marks: [0 4 2 1 5]\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Bayesian Linear Regression\n",
      "Predicted Marks: [1.13523047 5.26043009 1.90027108 0.87873819 4.46230376]\n",
      "Actual Marks: [0 4 2 1 5]\n",
      "----------------------------------------\n",
      "Model: Support Vector Regression\n",
      "Predicted Marks: [0.8408823  3.14526147 1.885041   0.90686789 3.04718351]\n",
      "Actual Marks: [0 4 2 1 5]\n",
      "----------------------------------------\n",
      "Model: Decision Tree Regression\n",
      "Predicted Marks: [0. 4. 2. 0. 5.]\n",
      "Actual Marks: [0 4 2 1 5]\n",
      "----------------------------------------\n",
      "Model: Gaussian Process Regression\n",
      "Predicted Marks: [ 1.92924038e-03  3.99802120e+00  1.38951095e+00 -1.71662313e-03\n",
      "  4.37649848e+00]\n",
      "Actual Marks: [0 4 2 1 5]\n",
      "----------------------------------------\n",
      "Model: Random Forest Regression\n",
      "Predicted Marks: [1.14 4.35 1.44 1.17 4.4 ]\n",
      "Actual Marks: [0 4 2 1 5]\n",
      "----------------------------------------\n",
      "Model: KNN Regression\n",
      "Predicted Marks: [0.2 4.4 2.6 0.8 4.2]\n",
      "Actual Marks: [0 4 2 1 5]\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso, LogisticRegression, BayesianRidge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Function to load dataset\n",
    "def load_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    X = data.iloc[:, :-1]  # Features\n",
    "    y = data.iloc[:, -1]   # Target\n",
    "    return X, y\n",
    "\n",
    "# Function to split dataset\n",
    "def split_data(X, y, test_size=0.2, random_state=42):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Function to define models\n",
    "def define_models():\n",
    "    models = {\n",
    "        \"Linear Regression\": LinearRegression(),\n",
    "        \"Polynomial Regression (Degree 2)\": make_pipeline(PolynomialFeatures(degree=2), LinearRegression()),\n",
    "        \"Lasso Regression\": Lasso(),\n",
    "        \"Logistic Regression (used for binary targets)\": LogisticRegression(),\n",
    "        \"Bayesian Linear Regression\": BayesianRidge(),\n",
    "        \"Support Vector Regression\": SVR(),\n",
    "        \"Decision Tree Regression\": DecisionTreeRegressor(),\n",
    "        \"Gaussian Process Regression\": GaussianProcessRegressor(),\n",
    "        \"Random Forest Regression\": RandomForestRegressor(),\n",
    "        \"KNN Regression\": KNeighborsRegressor()\n",
    "    }\n",
    "    return models\n",
    "\n",
    "# Function to train and evaluate models\n",
    "def train_and_evaluate_models(models, X_train, y_train, X_test, y_test):\n",
    "    for model_name, model in models.items():\n",
    "        try:\n",
    "            # Fit the model\n",
    "            model.fit(X_train, y_train)\n",
    "            # Predict on the test set\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            # Print results\n",
    "            print(f\"Model: {model_name}\")\n",
    "            print(f\"Predicted Marks: {y_pred[:5]}\")  # Print first 5 predictions\n",
    "            print(f\"Actual Marks: {y_test[:5].values}\")  # Print first 5 actual values\n",
    "            print(\"-\" * 40)\n",
    "        except Exception as e:\n",
    "            print(f\"Model: {model_name} - Error: {str(e)}\")\n",
    "            print(\"-\" * 40)\n",
    "\n",
    "# Main function to execute the workflow\n",
    "def main(file_path):\n",
    "    # Load dataset\n",
    "    X, y = load_data(file_path)\n",
    "    \n",
    "    # Split dataset into train and test sets\n",
    "    X_train, X_test, y_train, y_test = split_data(X, y)\n",
    "    \n",
    "    # Define models\n",
    "    models = define_models()\n",
    "    \n",
    "    # Train and evaluate models\n",
    "    train_and_evaluate_models(models, X_train, y_train, X_test, y_test)\n",
    "\n",
    "\n",
    "main(\"Q1_roberta.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9440485-dd2a-4412-a84f-9f21727ee6a6",
   "metadata": {},
   "source": [
    "## Testing roberta Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89800c6-2b0f-4a97-8a84-e26e05b0966f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Linear Regression\n",
      "Predicted Marks: [4.41583839 0.70612459 4.41583839 0.58907309 5.        ]\n",
      "Actual Marks: [4. 0. 4. 0. 5.]\n",
      "----------------------------------------\n",
      "Model: Polynomial Regression (Degree 2)\n",
      "Predicted Marks: [4.35432203 0.65807689 4.35432203 0.62780126 5.        ]\n",
      "Actual Marks: [4. 0. 4. 0. 5.]\n",
      "----------------------------------------\n",
      "Model: Lasso Regression\n",
      "Predicted Marks: [2.38095238 2.38095238 2.38095238 2.38095238 2.38095238]\n",
      "Actual Marks: [4. 0. 4. 0. 5.]\n",
      "----------------------------------------\n",
      "Model: Logistic Regression (used for binary targets)\n",
      "Predicted Marks: [5. 0. 5. 0. 5.]\n",
      "Actual Marks: [4. 0. 4. 0. 5.]\n",
      "----------------------------------------\n",
      "Model: Bayesian Linear Regression\n",
      "Predicted Marks: [4.41856281 0.64074635 4.41856281 0.61533833 4.99999996]\n",
      "Actual Marks: [4. 0. 4. 0. 5.]\n",
      "----------------------------------------\n",
      "Model: Support Vector Regression\n",
      "Predicted Marks: [2.8728303  1.70818516 2.8728303  1.58295119 3.04024308]\n",
      "Actual Marks: [4. 0. 4. 0. 5.]\n",
      "----------------------------------------\n",
      "Model: Decision Tree Regression\n",
      "Predicted Marks: [5. 0. 5. 0. 5.]\n",
      "Actual Marks: [4. 0. 4. 0. 5.]\n",
      "----------------------------------------\n",
      "Model: Gaussian Process Regression\n",
      "Predicted Marks: [2.83637306 0.01353848 2.83637306 0.10015227 5.        ]\n",
      "Actual Marks: [4. 0. 4. 0. 5.]\n",
      "----------------------------------------\n",
      "Model: Random Forest Regression\n",
      "Predicted Marks: [3.34 1.34 3.34 0.88 5.  ]\n",
      "Actual Marks: [4. 0. 4. 0. 5.]\n",
      "----------------------------------------\n",
      "Model: KNN Regression\n",
      "Predicted Marks: [5.  0.  5.  0.6 5. ]\n",
      "Actual Marks: [4. 0. 4. 0. 5.]\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso, LogisticRegression, BayesianRidge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Function to load dataset\n",
    "def load_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    return data\n",
    "\n",
    "# Function to handle missing values\n",
    "def handle_missing_values(data):\n",
    "    # Drop rows with NaN in the target column or fill them with the mean value\n",
    "    data = data.dropna(subset=[data.columns[-1]])  # Drop rows where the target is NaN\n",
    "    # Alternatively, you can fill missing values: data[data.columns[-1]].fillna(data[data.columns[-1]].mean(), inplace=True)\n",
    "    return data\n",
    "\n",
    "# Function to split dataset into features and target\n",
    "def split_data(data):\n",
    "    X = data.iloc[:, :-1]  # Features\n",
    "    y = data.iloc[:, -1]   # Target\n",
    "    return X, y\n",
    "\n",
    "# Function to split data into training and test sets\n",
    "def train_test_split_data(X, y, test_size=0.2, random_state=42):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Function to define models\n",
    "def define_models():\n",
    "    models = {\n",
    "        \"Linear Regression\": LinearRegression(),\n",
    "        \"Polynomial Regression (Degree 2)\": make_pipeline(PolynomialFeatures(degree=2), LinearRegression()),\n",
    "        \"Lasso Regression\": Lasso(),\n",
    "        \"Logistic Regression (used for binary targets)\": LogisticRegression(),\n",
    "        \"Bayesian Linear Regression\": BayesianRidge(),\n",
    "        \"Support Vector Regression\": SVR(),\n",
    "        \"Decision Tree Regression\": DecisionTreeRegressor(),\n",
    "        \"Gaussian Process Regression\": GaussianProcessRegressor(),\n",
    "        \"Random Forest Regression\": RandomForestRegressor(),\n",
    "        \"KNN Regression\": KNeighborsRegressor()\n",
    "    }\n",
    "    return models\n",
    "\n",
    "# Function to train and evaluate models\n",
    "def train_and_evaluate_models(models, X_train, y_train, X_test, y_test):\n",
    "    for model_name, model in models.items():\n",
    "        try:\n",
    "            # Fit the model\n",
    "            model.fit(X_train, y_train)\n",
    "            # Predict on the test set\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            # Print results\n",
    "            print(f\"Model: {model_name}\")\n",
    "            print(f\"Predicted Marks: {y_pred[:5]}\")  # Print first 5 predictions\n",
    "            print(f\"Actual Marks: {y_test[:5].values}\")  # Print first 5 actual values\n",
    "            print(\"-\" * 40)\n",
    "        except Exception as e:\n",
    "            print(f\"Model: {model_name} - Error: {str(e)}\")\n",
    "            print(\"-\" * 40)\n",
    "\n",
    "# Main function to execute the workflow\n",
    "def main(file_path):\n",
    "    # Load dataset\n",
    "    data = load_data(file_path)\n",
    "    \n",
    "    # Handle missing values\n",
    "    data = handle_missing_values(data)\n",
    "    \n",
    "    # Split into features and target\n",
    "    X, y = split_data(data)\n",
    "    \n",
    "    # Split dataset into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split_data(X, y)\n",
    "    \n",
    "    # Define models\n",
    "    models = define_models()\n",
    "    \n",
    "    # Train and evaluate models\n",
    "    train_and_evaluate_models(models, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Run the workflow\n",
    "main(\"Q2_roberta.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdd7902-8242-4407-bf88-d8aaa4cf5f2e",
   "metadata": {},
   "source": [
    "## Testing roberta Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03e0c0e-4cfb-4e76-9075-7e2c4477a81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Linear Regression\n",
      "Predicted Marks: [3, 2, 0, 2, 2]\n",
      "Actual Marks: [1, 1, 1, 5, 0]\n",
      "----------------------------------------\n",
      "Model: Polynomial Regression (Degree 2)\n",
      "Predicted Marks: [3, 2, 0, 2, 2]\n",
      "Actual Marks: [1, 1, 1, 5, 0]\n",
      "----------------------------------------\n",
      "Model: Lasso Regression\n",
      "Predicted Marks: [2, 2, 1, 2, 2]\n",
      "Actual Marks: [1, 1, 1, 5, 0]\n",
      "----------------------------------------\n",
      "Model: Logistic Regression (used for binary targets)\n",
      "Predicted Marks: [4, 1, 1, 1, 3]\n",
      "Actual Marks: [1, 1, 1, 5, 0]\n",
      "----------------------------------------\n",
      "Model: Bayesian Linear Regression\n",
      "Predicted Marks: [3, 2, 0, 2, 2]\n",
      "Actual Marks: [1, 1, 1, 5, 0]\n",
      "----------------------------------------\n",
      "Model: Support Vector Regression\n",
      "Predicted Marks: [2, 2, 1, 2, 2]\n",
      "Actual Marks: [1, 1, 1, 5, 0]\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jyoshitha\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Decision Tree Regression\n",
      "Predicted Marks: [3, 4, 1, 5, 1]\n",
      "Actual Marks: [1, 1, 1, 5, 0]\n",
      "----------------------------------------\n",
      "Model: Gaussian Process Regression\n",
      "Predicted Marks: [0, 0, 0, 0, 0]\n",
      "Actual Marks: [1, 1, 1, 5, 0]\n",
      "----------------------------------------\n",
      "Model: Random Forest Regression\n",
      "Predicted Marks: [2, 2, 1, 2, 2]\n",
      "Actual Marks: [1, 1, 1, 5, 0]\n",
      "----------------------------------------\n",
      "Model: KNN Regression\n",
      "Predicted Marks: [1, 1, 0, 1, 1]\n",
      "Actual Marks: [1, 1, 1, 5, 0]\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso, LogisticRegression, BayesianRidge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Function to load dataset\n",
    "def load_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    return data\n",
    "\n",
    "# Function to handle missing values\n",
    "def handle_missing_values(data):\n",
    "    # Drop rows with NaN in the target column or fill them with the mean value\n",
    "    data = data.dropna(subset=[data.columns[-1]])  # Drop rows where the target is NaN\n",
    "    # Alternatively: data[data.columns[-1]].fillna(data[data.columns[-1]].mean(), inplace=True)\n",
    "    return data\n",
    "\n",
    "# Function to split dataset into features and target\n",
    "def split_data(data):\n",
    "    X = data.iloc[:, :-1]  # Features\n",
    "    y = data.iloc[:, -1]   # Target\n",
    "    return X, y\n",
    "\n",
    "# Function to split data into training and test sets\n",
    "def train_test_split_data(X, y, test_size=0.2, random_state=42):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Function to define models\n",
    "def define_models():\n",
    "    models = {\n",
    "        \"Linear Regression\": LinearRegression(),\n",
    "        \"Polynomial Regression (Degree 2)\": make_pipeline(PolynomialFeatures(degree=2), LinearRegression()),\n",
    "        \"Lasso Regression\": Lasso(),\n",
    "        \"Logistic Regression (used for binary targets)\": LogisticRegression(),\n",
    "        \"Bayesian Linear Regression\": BayesianRidge(),\n",
    "        \"Support Vector Regression\": SVR(),\n",
    "        \"Decision Tree Regression\": DecisionTreeRegressor(),\n",
    "        \"Gaussian Process Regression\": GaussianProcessRegressor(),\n",
    "        \"Random Forest Regression\": RandomForestRegressor(),\n",
    "        \"KNN Regression\": KNeighborsRegressor()\n",
    "    }\n",
    "    return models\n",
    "\n",
    "# Function to train and evaluate models\n",
    "def train_and_evaluate_models(models, X_train, y_train, X_test, y_test):\n",
    "    for model_name, model in models.items():\n",
    "        try:\n",
    "            # Fit the model\n",
    "            model.fit(X_train, y_train)\n",
    "            # Predict on the test set\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            # Convert predictions and actual values to integers\n",
    "            y_pred_int = y_pred.astype(int)\n",
    "            y_test_int = y_test.astype(int)\n",
    "\n",
    "            # Print results\n",
    "            print(f\"Model: {model_name}\")\n",
    "            print(f\"Predicted Marks: {list(y_pred_int[:5])}\")  # Print first 5 predictions as integers\n",
    "            print(f\"Actual Marks: {list(y_test_int[:5].values)}\")  # Print first 5 actual values as integers\n",
    "            print(\"-\" * 40)\n",
    "        except Exception as e:\n",
    "            print(f\"Model: {model_name} - Error: {str(e)}\")\n",
    "            print(\"-\" * 40)\n",
    "\n",
    "# Main function to execute the workflow\n",
    "def main(file_path):\n",
    "    # Load dataset\n",
    "    data = load_data(file_path)\n",
    "    \n",
    "    # Handle missing values\n",
    "    data = handle_missing_values(data)\n",
    "    \n",
    "    # Split into features and target\n",
    "    X, y = split_data(data)\n",
    "    \n",
    "    # Split dataset into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split_data(X, y)\n",
    "    \n",
    "    # Define models\n",
    "    models = define_models()\n",
    "    \n",
    "    # Train and evaluate models\n",
    "    train_and_evaluate_models(models, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Run the workflow\n",
    "main(\"Q3_roberta.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063e1a3e-bd98-4557-8d4d-782b3bbda79d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
